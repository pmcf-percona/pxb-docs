{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Percona XtraBackup Documentation","text":"<p>This documentation is for the latest release: Percona XtraBackup release notes. This is an Innovation release. This type of release is only supported for a short time and is designed to be used in an environment with fast upgrade cycles. Developers and DBAs are exposed to the latest features and improvements.</p> <p>Percona XtraBackup is an open source hot backup utility for MySQL-based servers that keep your database fully available during planned maintenance windows.</p> <p>Whether it is a 24x7 highly loaded server or a low-transaction-volume Percona XtraBackup is designed to make backups seamless without disrupting the performance of the server in a production environment. Percona XtraBackup (PXB) is a 100% open source backup solution with commercial support available for organizations who want to benefit from comprehensive, responsive, and cost-flexible database support for MySQL.</p> <p>This is an Innovation release. This type of release is only supported for a short time and is designed to be used in an environment with fast upgrade cycles. Developers and DBAs are exposed to the latest features and improvements.</p> <p>Taking your backup with Percona XtraBackup is easy. Follow our documentation guides, and you\u2019ll be set up in quickly.</p>"},{"location":"index.html#quickstart-guide","title":"Quickstart guide","text":"<p>Get started quickly with our Quickstart guide.</p> <p>Quickstart guide </p>"},{"location":"index.html#installation-guides","title":"Installation guides","text":"<p>Find the best installation solution with our step-by-step installation instructions.</p> <p>Installation instructions </p>"},{"location":"index.html#binaries","title":"Binaries","text":"<p>Learn about the Percona XtraBackup binaries: xtrabackup, xbcloud, xbcrypt, and xbstream.</p> <p>Binaries </p>"},{"location":"index.html#backup-management","title":"Backup management","text":"<p>Learn about the different types of backups and how to take them.</p> <p>Backup management </p>"},{"location":"index.html#supported-storage-engines","title":"Supported storage engines","text":"<p>Percona XtraBackup can back up data from InnoDB, XtraDB, MyISAM, MyRocks tables on MySQL servers and Percona Server for MySQL with XtraDB, Percona Server for MySQL, and Percona XtraDB Cluster.</p> <p>Percona XtraBackup supports the MyRocks storage engine. An incremental backup on the MyRocks storage engine does not determine if an earlier full or incremental backup contains duplicate files. Percona XtraBackup copies all MyRocks files each time it takes a backup.</p>"},{"location":"index.html#limitations","title":"Limitations","text":"<p>Percona XtraBackup does not support making backups of databases created in versions before of MySQL, Percona Server for MySQL or Percona XtraDB Cluster.</p>"},{"location":"index.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"404.html","title":"404 - Not Found","text":"<p>We can\u2019t find the page you are looking for. Try using the Search or return to the homepage.</p>"},{"location":"404.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"about-xtrabackup.html","title":"About Percona XtraBackup","text":"<p>Percona XtraBackup is the world\u2019s only open source, free MySQL hot backup software that performs non-blocking backups for InnoDB and XtraDB databases. </p> <p>Percona XtraBackup has the following benefits:</p> <ul> <li> <p>Complete a backup quickly and reliably</p> </li> <li> <p>Process transactions uninterrupted during a backup</p> </li> <li> <p>Save on disk space and network bandwidth</p> </li> <li> <p>Verify backup automatically</p> </li> </ul> <p>Percona XtraBackup makes hot backups for Percona Server for MySQL and MySQL-compatible servers. XtraBackup takes streaming, compressed, and incremental server backups, and supports encryption.</p> <p>Percona\u2019s enterprise-grade commercial MySQL Support contracts include support for Percona XtraBackup. We recommend support for critical production deployments.</p>"},{"location":"about-xtrabackup.html#supported-storage-engines","title":"Supported storage engines","text":"<p>Percona XtraBackup can back up data from InnoDB, XtraDB, MyISAM, and MyRocks tables on MySQL {{vers}} servers as well as Percona Server for MySQL {{vers}}.</p> <p>Percona XtraBackup supports the MyRocks storage engine. Percona XtraBackup copies all MyRocks files each time it takes a backup. An incremental backup on the MyRocks storage engine does not determine if an earlier full or incremental backup contains the same files.</p>"},{"location":"about-xtrabackup.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"accelerate-backup-process.html","title":"Accelerate backup process","text":""},{"location":"accelerate-backup-process.html#accelerate-the-backup-process","title":"Accelerate the backup process","text":""},{"location":"accelerate-backup-process.html#copy-with-the-parallel-and-compress-threads-options","title":"Copy with the <code>--parallel</code> and <code>--compress-threads</code> options","text":"<p>When making a local or streaming backup with xbstream binary, multiple files can be copied at the same time when using the <code>--parallel</code> option. This option specifies the number of threads created by xtrabackup to copy data files.</p> <p>To take advantage of this option either the multiple tablespaces option must be enabled (innodb_file_per_table) or the shared tablespace must be stored in multiple ibdata files with the innodb_data_file_path option. Having multiple files for the database (or splitting one into many) doesn\u2019t have a measurable impact on performance.</p> <p>As this feature is implemented at the file level, concurrent file transfer can sometimes increase I/O throughput when doing a backup on highly fragmented data files, due to the overlap of a greater number of random read requests. You should consider tuning the filesystem also to obtain the maximum performance (e.g. checking fragmentation).</p> <p>If the data is stored on a single file, this option has no effect.</p> <p>To use this feature, simply add the option to a local backup, for example:</p> <pre><code>$ xtrabackup --backup --parallel=4 --target-dir=/path/to/backup\n</code></pre> <p>By using the xbstream in streaming backups, you can additionally speed up the compression process with the <code>--compress-threads</code> option. This option specifies the number of threads created by xtrabackup for for parallel data compression. The default value for this option is 1.</p> <p>To use this feature, simply add the option to a local backup, for example:</p> <pre><code>$ xtrabackup --backup --stream=xbstream --compress --compress-threads=4 --target-dir=./ &gt; backup.xbstream\n</code></pre> <p>Before applying logs, compressed files will need to be uncompressed.</p>"},{"location":"accelerate-backup-process.html#the-rsync-option","title":"The <code>--rsync</code> option","text":"<p>In order to speed up the backup process and to minimize the time <code>FLUSH TABLES WITH READ LOCK</code> is blocking the writes, the option <code>--rsync</code> should be used. When this option is specified, xtrabackup uses <code>rsync</code> to copy all non-InnoDB files instead of spawning a separate <code>cp</code> for each file, which can be much faster for servers with a large number of databases or tables. xtrabackup will call the <code>rsync</code> twice, once before the <code>FLUSH TABLES WITH READ LOCK</code> and once during to minimize the time the read lock is being held. During the second <code>rsync</code> call, it will only synchronize the changes to non-transactional data (if any) since the first call performed before the <code>FLUSH TABLES WITH READ LOCK</code>. Note that Percona XtraBackup will use Backup locks where available as a lightweight alternative to <code>FLUSH TABLES WITH READ LOCK</code>.</p> <p>Percona XtraBackup uses these locks automatically to copy non-InnoDB data to avoid blocking Data manipulation language (DML) queries that modify InnoDB tables.</p> <p>Note</p> <p>This option cannot be used together with the <code>--stream</code> option.</p>"},{"location":"accelerate-backup-process.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"apt-download-deb.html","title":"Install using downloaded DEB packages","text":"<p>Download <code>DEB</code> packages of the desired series for your architecture from Percona Product Downloads. This method requires you to resolve all dependencies and install any missing packages.</p> <p>The following example downloads Percona XtraBackup {{release}} release package for Ubuntu 20.04:</p> <pre><code>$ wget https://downloads.percona.com/downloads/Percona-XtraBackup-LATEST/Percona-XtraBackup-{{release}}/binary/debian/focal/x86_64/percona-xtrabackup-{{pkg}}_{{release}}.focal_amd64.deb\n</code></pre> <p>Install Percona XtraBackup by using <code>dpkg</code>. Run this command as root or use the sudo command:</p> <pre><code>$ sudo dpkg -i percona-xtrabackup-{{pkg}}_{{release}}.focal_amd64.deb\n</code></pre>"},{"location":"apt-download-deb.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"apt-files.html","title":"Files in the DEB package","text":"<p>The following tables show what data each <code>DEB</code> package contains.</p> Package Contains percona-xtrabackup-{{pkg}} The latest Percona XtraBackup GA binaries and associated files percona-xtrabackup-dbg-{{pkg}} The debug symbols for binaries in <code>percona-xtrabackup-{{pkg}}</code> percona-xtrabackup-test-{{pkg}} The test suite for Percona XtraBackup percona-xtrabackup The older version of the Percona XtraBackup"},{"location":"apt-files.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"apt-pinning.html","title":"Apt pinning packages","text":"<p>In some cases you might need to <code>pin</code> the selected packages to avoid the upgrades from the distribution repositories. </p> <p>The pinning takes place in the <code>preference</code> file. To pin a package, set the <code>Pin-Priority</code> to higher numbers.</p> <p>Make a new file <code>/etc/apt/preferences.d/00percona.pref</code>. For example, add the following to the preference file:</p> <pre><code>Package:\nPin: release o=Percona Development Team\nPin-Priority: 1001\n</code></pre> <p>For more information about the pinning, check the official debian wiki.</p>"},{"location":"apt-pinning.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"apt-repo.html","title":"Install with an APT repository","text":"<p>Ready-to-use packages are available from the Percona XtraBackup software repositories and the download page.</p> <p>Specific information on the supported platforms, products, and versions is described in Percona Release Lifecycle Overview.</p>"},{"location":"apt-repo.html#install-percona-xtrabackup-through-percona-release","title":"Install Percona XtraBackup through percona-release","text":"<p>Percona XtraBackup, like many other Percona products, is installed with the percona-release package configuration tool.</p> <ol> <li> <p>Download a <code>DEB</code> package for percona-release the repository packages from Percona web:</p> <pre><code>$ wget https://repo.percona.com/apt/percona-release_latest.$(lsb_release -sc)_all.deb\n</code></pre> </li> <li> <p>Install the downloaded package with dpkg. To do that, run the following commands as root or with sudo: <code>dpkg -i percona-release_latest.$(lsb_release -sc)_all.deb</code></p> <p>Once you install this package the Percona repositories should be added. You can check the repository setup in the <code>/etc/apt/sources.list.d/percona-release.list</code> file.</p> </li> <li> <p>Enable the repository: <code>percona-release enable-only tools release</code></p> <p>If Percona XtraBackup is intended to be used in combination with the upstream MySQL Server, you only need to enable the <code>tools</code> repository: <code>percona-release enable-only tools</code>.</p> </li> <li> <p>Refresh the local cache to update the package information:</p> <pre><code>$ sudo apt update\n</code></pre> </li> <li> <p>Install the <code>percona-xtrabackup-{{pkg}}</code> package:</p> <pre><code>$ sudo apt install percona-xtrabackup-{{pkg}}\n</code></pre> </li> <li> <p>To decompress backups made using <code>LZ4</code> or <code>ZSTD</code> compression algorithm, install the corresponding package:</p> Install the <code>lz4</code> packageInstall the <code>zstd</code> package <pre><code>$ sudo apt install lz4\n</code></pre> <pre><code>$ sudo apt install zstd\n</code></pre> </li> </ol> <p>Note</p> <p>For AppArmor profile information, see Working with AppArmor.</p> <p>See also</p> <p>To install Percona XtraBackup using downloaded deb packages, see Install Percona XtraBackup {{vers}}.</p> <p>To uninstall Percona XtraBackup, see Uninstall Percona XtraBackup {{vers}}</p>"},{"location":"apt-repo.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"apt-uninstall-xtrabackup.html","title":"Uninstall Percona XtraBackup {{vers}} on Debian and Ubuntu","text":"<p>To completely uninstall Percona XtraBackup, remove all the installed packages:</p> <pre><code>$ sudo apt remove percona-xtrabackup-{{pkg}}\n</code></pre>"},{"location":"apt-uninstall-xtrabackup.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"backup-overview.html","title":"Backup process overview","text":"<p>Percona Xtrabackup is a tool that allows you to create backups of MySQL or MariaDB databases. It works by copying the data files and the binary log files of the server, while ensuring that the data is consistent and not corrupted by ongoing transactions. Percona Xtrabackup can also prepare the backup files for restoration, apply incremental backups, and stream the backup files to another server or storage device.</p>"},{"location":"backup-overview.html#backup-types","title":"Backup types","text":"<p>You can take and prepare the following types of backups:</p> <ul> <li> <p>Full backup - a backup of all the contents of the database</p> </li> <li> <p>Incremental backup - a backup of only the files that have changed since the last full backup</p> </li> <li> <p>Compressed backup - a backup of all the contents of the database with applying a compression algorithm that reduces the size of the data to be stored</p> </li> <li> <p>Partial backup - a backup of only the files that have changed in a specific folder or a set of folders, rather than the entire database</p> </li> <li> <p>Individual partitions backup - a backup of an individual partition</p> </li> </ul>"},{"location":"backup-overview.html#backup-restoration","title":"Backup restoration","text":"<ul> <li> <p>Restore full, incremental, compressed backups</p> </li> <li> <p>Restore a partial backup</p> </li> <li> <p>Restore an individual partitions backup</p> </li> <li> <p>Restore individual tables</p> </li> </ul>"},{"location":"backup-overview.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"binaries-overview.html","title":"Percona XtraBackup binaries overview","text":"<p>Percona XtraBackup contains a set of the following binaries:</p> <ul> <li> <p>xtrabackup - a compiled C binary that provides functionality to backup a whole MySQL database instance with MyISAM, InnoDB, and XtraDB tables.</p> </li> <li> <p>xbcrypt - a utility used for encrypting and decrypting backup files.</p> </li> <li> <p>xbstream - a utility that allows streaming and extracting files to or from the xbstream format.</p> </li> <li> <p>xbcloud - a utility used for downloading and uploading full or part of xbstream archive from or to cloud.</p> </li> </ul> <p>The recommended way to take the backup is by using the xtrabackup script. For more information on script options, see xtrabackup.</p>"},{"location":"binaries-overview.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"binary-tarball-names.html","title":"Binary tarball file names available","text":"<p>Download the binary tarballs from Percona Product Downloads.</p> <p>The following table lists the tarball types available in <code>Linux - Generic</code>. Select the Percona XtraBackup {{vers}} version, the software or the operating system, and the type of tarball for your installation. Binary tarballs support all distributions.</p> <p>After you have downloaded the binary tarballs, extract the tarball in the file location of your choice.</p> Type Name Operating systems Description Full percona-xtrabackup-{{release}}-Linux.x86_64.glibc2.12.tar.gz Built for CentOS 6 Contains binary files, libraries, test files, and debug symbols Minimal percona-xtrabackup-{{release}}-Linux.x86_64.glibc2.12-minimal.tar.gz Built for CentOS 6 Contains binary files, and libraries but does not include test files, or debug symbols Full percona-xtrabackup-{{release}}-Linux.x86_64.glibc2.17.tar.gz Compatible with any operating system except for CentOS 6 Contains binary files, libraries, test files, and debug symbols Minimal percona-xtrabackup-{{release}}-Linux.x86_64.glibc2.17-minimal.tar.gz Compatible with any operating system except for CentOS 6 Contains binary files, and libraries but does not include test files, or debug symbols <p>Select a different software, such as Ubuntu 20.04 (Focal Fossa), for a  tarball for that operating system. You can download the packages together or separately.</p>"},{"location":"binary-tarball-names.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"binary-tarball.html","title":"Install from a binary tarball","text":"<p>Binary tarballs contain precompiled executable files, libraries, and other dependencies and are compressed <code>tar</code> archives. Extract the binary tarballs to any path.</p> <p>Download the binary tarballs from the <code>Linux - Generic</code> section on Percona Product Downloads.</p> <p>The following example downloads the a tarball:</p> <pre><code>$ wget https://downloads.percona.com/downloads/Percona-XtraBackup-{{vers}}/Percona-XtraBackup-{{release}}/binary/tarball/percona-xtrabackup-{{release}}-Linux-x86_64.glibc2.17.tar.gz\n</code></pre> <p>The output displays the following information:</p> Expected output <pre><code>--2023-10-20 05:56:30--  https://downloads.percona.com/downloads/Percona-XtraBackup-{{vers}}/Percona-XtraBackup-{{release}}/binary/tarball/percona-xtrabackup-{{release}}-Linux-x86_64.glibc2.17.tar.gz\nResolving downloads.percona.com (downloads.percona.com)... 2604:2dc0:200:69f::2, 147.135.54.159\nConnecting to downloads.percona.com (downloads.percona.com)|2604:2dc0:200:69f::2|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 470358258 (449M) [application/gzip]\nSaving to: \u2018percona-xtrabackup-{{release}}-Linux-x86_64.glibc2.17.tar.gz\u2019\n\npercona-xtrabackup   0%[                       ]   3.17M  1.54MB/s\n</code></pre>"},{"location":"binary-tarball.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"compile-xtrabackup.html","title":"Compile xtrabackup","text":""},{"location":"compile-xtrabackup.html#compile-and-install-from-source","title":"Compile and install from source","text":"<p>The following instructions install Percona XtraBackup {{vers}}.</p>"},{"location":"compile-xtrabackup.html#1-install-percona-xtrabackup-from-the-git-source-tree","title":"1. Install Percona XtraBackup from the Git Source Tree","text":"<p>Percona uses the Github revision control system for development. To build the latest Percona Server for MySQL from the source tree, you will need <code>git</code> installed on your system.</p> <p>You can now fetch the latest Percona XtraBackup {{vers}} sources:</p> <pre><code>$ git clone https://github.com/percona/percona-xtrabackup.git\n$ cd percona-xtrabackup\n$ git checkout trunk\n$ git submodule update --init --recursive\n</code></pre>"},{"location":"compile-xtrabackup.html#2-installation-prerequisites","title":"2. Installation prerequisites","text":"<p>The following packages and tools must be installed to compile Percona XtraBackup from source. These might vary from system to system.</p> <p>Important</p> <p>To build **Percona XtraBackup {{vers}} from source, you must use <code>cmake</code>  version 3. To check which version is  currently installed, run <code>cmake --version</code> at a command prompt. If the  version is not <code>3</code>, install <code>cmake3</code>.</p> <p>This <code>cmake</code> version may be available  in your distribution as a separate package <code>cmake3</code>. For more information, see cmake.org.</p> Debian or Ubuntu using <code>apt</code>CentOS or Red Hat using <code>yum</code> <pre><code>sudo apt install bison pkg-config cmake devscripts debconf \\\ndebhelper automake bison ca-certificates libprocps-dev \\\nlibcurl4-openssl-dev cmake debhelper libaio-dev \\\nlibncurses-dev libssl-dev libtool libz-dev libgcrypt-dev libev-dev libprocps-dev \\\nlsb-release build-essential rsync libdbd-mysql-perl \\\nlibnuma1 socat librtmp-dev libtinfo5 vim-common \\\nliblz4-tool liblz4-1 liblz4-dev zstd python-docutils\n</code></pre> <p>To install the man pages, install the python3-sphinx package first:</p> <pre><code>$ sudo apt install python3-sphinx\n</code></pre> <p>Percona Xtrabackup requires GCC version 5.3 or higher. If the version of GCC installed on your system is lower then you may need to install and enable the Developer Toolset on <code>RPM</code>-based distributions to make sure that you use the latest GCC compiler and development tools.  Then, install <code>cmake</code> and other dependencies:</p> <pre><code>$ sudo yum install cmake openssl-devel libaio libaio-devel automake autoconf \\\nbison libtool ncurses-devel libgcrypt-devel libev-devel libcurl-devel zlib-devel \\\nzstd vim-common procps-ng-devel\n</code></pre> <p>To install the man pages, install the python3-sphinx package first:</p> <pre><code>$ sudo yum install python3-sphinx\n</code></pre>"},{"location":"compile-xtrabackup.html#3-generate-the-build-pipeline","title":"3. Generate the build pipeline","text":"<p>At this step, you have <code>cmake</code> run the commands in the <code>CMakeList.txt</code> file to generate the build pipeline, i.e., a native build environment that will be used to compile the source code).</p> <ol> <li> <p>Change to the directory where you cloned the Percona XtraBackup repository</p> <pre><code>$ cd percona-xtrabackup\n</code></pre> </li> <li> <p>Create a directory to store the compiled files and then change to that directory:</p> <pre><code>$ mkdir build\n$ cd build\n</code></pre> </li> <li> <p>Run cmake or cmake3. In either case, the options you need to use are the same.</p> </li> </ol> <p>Note</p> <p>You can build Percona XtraBackup with man pages but this requires <code>python-sphinx</code> package which isn\u2019t available from that main repositories for every distribution. If you installed the <code>python-sphinx</code> package you need to remove the <code>-DWITH_MAN_PAGES=OFF</code> from previous command.</p> <pre><code>$ cmake -DWITH_BOOST=PATH-TO-BOOST-LIBRARY -DDOWNLOAD_BOOST=ON \\\n-DBUILD_CONFIG=xtrabackup_release -DWITH_MAN_PAGES=OFF -B ..\n</code></pre>"},{"location":"compile-xtrabackup.html#parameter-information","title":"Parameter Information","text":"Parameter Description <code>-DWITH_BOOST</code> For the <code>-DWITH_BOOST</code> parameter, specify the name of a directory to download the boost library to. This directory is created automatically in your current directory. <code>-DWITH_MAN_PAGES</code> To build Percona XtraBackup man pages, use <code>ON</code> or remove this parameter from the command line (it is <code>ON</code> by default). To install the man pages, install the python3-sphinx package first. <code>-B</code> (\u2013build) Percona XtraBackup is configured to forbid generating the build    pipeline for make in the same directory where you store your sources. The <code>-B</code> parameter refers to the directory that contains the source code. In this example, we use the relative path to the parent directory (..). <p>Important</p> <p>CMake Error at CMakeLists.txt:367 (MESSAGE): Please do not build in-source. Out-of source builds are highly recommended: you can have multiple builds for the same source, and there is an easy way to do cleanup, simply remove the build directory (note that \u2018make clean\u2019 or \u2018make distclean\u2019 does <code>not</code> work)</p> <p>You <code>can</code> force in-source build by invoking cmake with <code>-DFORCE_INSOURCE_BUILD=1</code>.</p>"},{"location":"compile-xtrabackup.html#4-compile-the-source-code","title":"4. Compile the source code","text":"<p>To compile the source code in your <code>build</code> directory, use the <code>make</code> command.</p> <ol> <li> <p>Change to the <code>build</code> directory (created at Step 2: Generating the build pipeline).</p> </li> <li> <p>Run the <code>make</code> command. This command may take a long time to complete.</p> <pre><code>$ make\n</code></pre> <p>To use all CPU threads and make compilation faster please use:</p> <pre><code>$ make -j$(nproc --all)\n</code></pre> </li> </ol>"},{"location":"compile-xtrabackup.html#5-install-on-the-target-system","title":"5. Install on the target system","text":"<p>The following command installs all Percona XtraBackup binaries xtrabackup and tests to default location on the target system: <code>/usr/local/xtrabackup</code>.</p> <p>Run <code>make install</code> to install Percona XtraBackup to the default location.</p> <pre><code>$ sudo make install\n</code></pre>"},{"location":"compile-xtrabackup.html#install-to-a-non-default-location","title":"Install to a non-default location","text":"<p>You may use the <code>DESTDIR</code> parameter with <code>make install</code> to install Percona XtraBackup to another location. Make sure that the effective user is able to write to the destination you choose.</p> <pre><code>$ sudo make DESTDIR=&lt;DIR_NAME&gt; install\n</code></pre> <p>In fact, the destination directory is determined by the installation layout (<code>-DINSTALL_LAYOUT</code>) that <code>cmake</code> applies (see Step 2: Generating the build pipeline). In addition to the installation directory, this parameter controls a number of other destinations that you can adjust for your system.</p> <p>By default, this parameter is set to <code>STANDALONE</code>, which implies the installation directory to be <code>/usr/local/xtrabackup</code>.</p> <p>See also</p> <p>MySQL Documentation: -DINSTALL_LAYOUT</p>"},{"location":"compile-xtrabackup.html#6-run-percona-xtrabackup","title":"6. Run Percona XtraBackup","text":"<p>After Percona XtraBackup is installed on your system, you may run it by using the full path to the <code>xtrabackup</code> command:</p> <pre><code>$ /usr/local/xtrabackup/bin/xtrabackup\n</code></pre> <p>Update your PATH environment variable if you would like to use the command on the command line directly.</p> <pre><code>$# Setting $PATH on the command line\n$ PATH=$PATH:/usr/local/xtrabackup/bin/xtrabackup\n\n$# Run xtrabackup directly\n$ xtrabackup\n</code></pre> <p>Alternatively, you may consider placing a soft link (using <code>ln -s</code>) to one of the locations listed in your <code>PATH</code> environment variable.</p> <p>To view the documentation with <code>man</code>, update the <code>MANPATH</code> variable.</p>"},{"location":"compile-xtrabackup.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"configure-xtrabackup.html","title":"Configure xtrabackup","text":"<p>All the xtrabackup configuration is done through options, which behave exactly like standard MySQL program options: they can be specified either at the command-line, or through a file such as <code>/etc/my.cnf</code>.</p> <p>The xtrabackup binary reads the <code>[mysqld]</code> and <code>[xtrabackup]</code> sections from any configuration files, in that order. That is so that it can read its options from your existing MySQL installation, such as the datadir or some of the InnoDB options. If you want to override these, just specify them in the <code>[xtrabackup]</code> section, and because it is read later, it will take precedence.</p> <p>You don\u2019t need to put any configuration in your <code>my.cnf</code>. You can specify the options on the command-line. Normally, the only thing you may find convenient to place in the <code>[xtrabackup]</code> section of your <code>my.cnf</code> file is the <code>target_dir</code> option. This options adds a default path to the directory for backups.</p> <p>The following is an example:</p> <pre><code>[xtrabackup]\ntarget_dir = /data/backups/\n</code></pre> <p>This manual assumes you do not have any file-based configuration for xtrabackup and shows the command-line options.</p> <p>Please see the option and variable reference for details on all the configuration options.</p> <p>The xtrabackup binary does not accept exactly the same syntax in the <code>my.cnf</code> file as the mysqld server binary does. For historical reasons, the mysqld server binary accepts parameters with a <code>--set-variable=&lt;variable&gt;=&lt;value&gt;</code> syntax, which xtrabackup does not understand. If your <code>my.cnf</code> file has such configuration directives, you should rewrite them in the <code>--variable=value</code> syntax.</p>"},{"location":"configure-xtrabackup.html#system-configuration-and-nfs-volumes","title":"System configuration and NFS volumes","text":"<p>The xtrabackup tool requires no special configuration on most systems. However, the storage where the <code>--target-dir</code> is located must behave properly when <code>fsync()</code> is called. In particular, we have noticed that if you mount the NFS volume without the <code>sync</code> option the NFS  volume does not sync the data. As a result, if you back up to an NFS  volume mounted with the async option, and then try to prepare the backup from a different server that also mounts that volume, the data might appear to be corrupt. Use the <code>sync</code> mount option to avoid this issue.</p>"},{"location":"configure-xtrabackup.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"copyright-and-licensing-information.html","title":"Copyright and licensing information","text":""},{"location":"copyright-and-licensing-information.html#documentation-licensing","title":"Documentation licensing","text":"<p>Percona XtraBackup documentation is (C)2009-2023 Percona LLC and/or its affiliates and is distributed under the Creative Commons Attribution 4.0 International License.</p>"},{"location":"copyright-and-licensing-information.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"create-compressed-backup.html","title":"Create a compressed backup","text":"<p>Percona XtraBackup supports compressed backups. To make a compressed backup, use the <code>--compress</code> option along with the <code>--backup</code> and <code>--target-dir</code> options. A local or streaming backup can be compressed or decompressed with xbstream.</p> <p>By default, the <code>--compress</code> option uses the <code>zstandard</code> tool that you can install with the <code>percona-release</code> package configuration tool as follows:</p> <pre><code>$ sudo percona-release enable tools\n$ sudo apt update\n$ sudo apt install zstandard\n</code></pre> <p>Note</p> <p>Enable the repository: <code>percona-release enable-only tools release</code>.</p> <p>If Percona XtraBackup is intended to be used in combination with the upstream MySQL Server, you only need to enable the <code>tools</code> repository: <code>percona-release enable-only tools</code>.</p> <p>Percona XtraBackup supports the following compression algorithms:</p>"},{"location":"create-compressed-backup.html#zstandard-zstd","title":"Zstandard (ZSTD)","text":"<p>The Zstandard (ZSTD) is a fast lossless compression algorithm that targets real-time compression scenarios and better compression ratios. <code>ZSTD</code> is the default compression algorithm for the <code>--compress</code> option.</p> <p>To compress files using the <code>ZSTD</code> compression algorithm, use the <code>--compress</code> option:</p> <pre><code>$ xtrabackup --backup --compress --target-dir=/data/backup\n</code></pre> <p>The resulting files have the <code>\\*.zst</code> format.</p> <p>You can specify <code>ZSTD</code> compression level with the <code>--compress-zstd-level(=#)</code> option. The default value is <code>1</code>.</p> <pre><code>$ xtrabackup \u2013backup \u2013compress \u2013compress-zstd-level=1 \u2013target-dir=/data/backup\n</code></pre>"},{"location":"create-compressed-backup.html#lz4","title":"lz4","text":"<p>To compress files using the <code>lz4</code> compression algorithm, set the <code>--compress</code> option to <code>lz4</code>:</p> <pre><code>$ xtrabackup --backup --compress=lz4 --target-dir=/data/backup\n</code></pre> <p>The resulting files have the <code>\\*.lz4</code> format. </p> <p>If you want to speed up the compression you can use the parallel compression, which can be enabled with <code>--compress-threads</code> option. Following example will use four threads for compression:</p> <pre><code>$ xtrabackup --backup --compress --compress-threads=4 \\\n--target-dir=/data/compressed/\n</code></pre> Expected output <pre><code>...\n170223 13:00:38 [01] Compressing ./test/sbtest1.frm to /tmp/compressed/test/sbtest1.frm.qp\n170223 13:00:38 [01]        ...done\n170223 13:00:38 [01] Compressing ./test/sbtest2.frm to /tmp/compressed/test/sbtest2.frm.qp\n170223 13:00:38 [01]        ...done\n...\n170223 13:00:39 [00] Compressing xtrabackup_info\n170223 13:00:39 [00]        ...done\nxtrabackup: Transaction log of lsn (9291934) to (9291934) was copied.\n170223 13:00:39 completed OK!\n</code></pre>"},{"location":"create-compressed-backup.html#next-step","title":"Next step","text":"<p>Prepare the backup </p>"},{"location":"create-compressed-backup.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"create-full-backup.html","title":"Create a full backup","text":"<p>To create a backup, run xtrabackup with the <code>--backup</code> option. You also must specify the <code>--target-dir</code> option, which is where the backup is stored. If the InnoDB data or log files are not stored in the same directory, you must specify their location. If the target directory does not exist, xtrabackup creates it. If the directory does exist and is empty, xtrabackup succeeds.</p> <p>xtrabackup does not overwrite existing files. It will fail with operating system error 17, <code>file exists</code>.</p> <p>The following command starts the process:</p> <pre><code>$ xtrabackup --backup --target-dir=/data/backups/\n</code></pre> <p>This operation stores the backup at <code>/data/backups/</code>. If you specify a relative path, the target directory is relative to the current directory.</p> <p>During the backup process, the output shows the copied data files, and a log file thread that scans and copies from the log files.</p> <p>The following is an example of the output:</p> Expected output <pre><code>160906 10:19:17 Finished backing up non-InnoDB tables and files\n160906 10:19:17 Executing FLUSH NO_WRITE_TO_BINLOG ENGINE LOGS...\nxtrabackup: The latest check point (for incremental): '62988944'\nxtrabackup: Stopping log copying thread.\n.160906 10:19:18 &gt;&gt; log scanned up to (137343534)\n160906 10:19:18 Executing UNLOCK TABLES\n160906 10:19:18 All tables unlocked\n160906 10:19:18 Backup created in directory '/data/backups/'\n160906 10:19:18 [00] Writing backup-my.cnf\n160906 10:19:18 [00]        ...done\n160906 10:19:18 [00] Writing xtrabackup_info\n160906 10:19:18 [00]        ...done\nxtrabackup: Transaction log of lsn (26970807) to (137343534) was copied.\n160906 10:19:18 completed OK!\n</code></pre> <p>The process ends with the following statement; the value of the <code>&lt;LSN&gt;</code> depends on your system:</p> <pre><code>$ xtrabackup: Transaction log of lsn (&lt;LSN&gt;) to (&lt;LSN&gt;) was copied.\n</code></pre> <p>Note</p> <p>Log copying thread checks the transactional log every second to see if there were any new log records written that need to be copied, but there is a chance that the log copying thread might not be able to keep up with the amount of writes that go to the transactional logs, and will hit an error when the log records are overwritten before they could be read.</p> <p>After the backup is finished, the target directory will contain files such as the following, assuming you have a single InnoDB table <code>test.tbl1</code> and you are using MySQL\u2019s innodb_file_per_table option:</p> <pre><code>$ ls -lh /data/backups/\n</code></pre> <p>The result should look like this:</p> Expected output <pre><code>total 182M\ndrwx------  7 root root 4.0K Sep  6 10:19 .\ndrwxrwxrwt 11 root root 4.0K Sep  6 11:05 ..\n-rw-r-----  1 root root  387 Sep  6 10:19 backup-my.cnf\n-rw-r-----  1 root root  76M Sep  6 10:19 ibdata1\ndrwx------  2 root root 4.0K Sep  6 10:19 mysql\ndrwx------  2 root root 4.0K Sep  6 10:19 performance_schema\ndrwx------  2 root root 4.0K Sep  6 10:19 sbtest\ndrwx------  2 root root 4.0K Sep  6 10:19 test\ndrwx------  2 root root 4.0K Sep  6 10:19 world2\n-rw-r-----  1 root root  116 Sep  6 10:19 xtrabackup_checkpoints\n-rw-r-----  1 root root  433 Sep  6 10:19 xtrabackup_info\n-rw-r-----  1 root root 106M Sep  6 10:19 xtrabackup_logfile\n</code></pre> <p>The backup can take a long time, depending on how large the database is. It is safe to cancel at any time, because xtrabackup does not modify the database.</p>"},{"location":"create-full-backup.html#next-step","title":"Next step","text":"<p>Prepare the backup </p>"},{"location":"create-full-backup.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"create-gtid-replica.html","title":"How to create a new (or repair a broken) GTID-based replica","text":"<p>Percona XtraBackup automatically stores the <code>GTID</code> value in the <code>xtrabackup_binlog_info</code> when doing the backup of MySQL and Percona Server for MySQL {{vers}} with the <code>GTID</code> mode enabled. This information can be used to create a new (or repair a broken) <code>GTID</code>-based replica.</p>"},{"location":"create-gtid-replica.html#1-take-a-backup-from-any-server-on-the-replication-environment-source-or-replica","title":"1. Take a backup from any server on the replication environment, source or replica","text":"<p>The following command takes a backup and saves it in the <code>/data/backups/$TIMESTAMP</code> folder:</p> <pre><code>$ xtrabackup --backup --target-dir=/data/backups/\n</code></pre> <p>In the destination folder, there will be a file with the name <code>xtrabackup_binlog_info</code>. This file contains both binary log coordinates and the <code>GTID</code> information.</p> <p><pre><code>$ cat xtrabackup_binlog_info\n</code></pre> The result could look like this:</p> Expected output <pre><code>mysql-bin.000002    1232        c777888a-b6df-11e2-a604-080027635ef5:1-4\n</code></pre> <p>That information is also printed by xtrabackup after taking the backup:</p> Expected output <pre><code>xtrabackup: MySQL binlog position: filename 'mysql-bin.000002', position 1232, GTID of the last change 'c777888a-b6df-11e2-a604-080027635ef5:1-4'\n</code></pre>"},{"location":"create-gtid-replica.html#2-prepare-the-backup","title":"2. Prepare the backup","text":"<p>The backup will be prepared with the following command on the Source:</p> <pre><code>$ xtrabackup --prepare --target-dir=/data/backup\n</code></pre> <p>You need to select the path where your snapshot has been taken, for example <code>/data/backups/2023-05-07_08-33-33</code>. If everything is ok you should get the same OK message. Now, the transaction logs are applied to the data files, and new ones are created: your data files are ready to be used by the MySQL server.</p>"},{"location":"create-gtid-replica.html#3-move-the-backup-to-the-destination-server","title":"3. Move the backup to the destination server","text":"<p>Use rsync or scp to copy the data to the destination server. If you are synchronizing the data directly to the already running replica\u2019s data directory it is advised to stop the MySQL server there.</p> <pre><code>$ rsync -avprP -e ssh /path/to/backupdir/$TIMESTAMP NewSlave:/path/to/mysql/\n</code></pre> <p>After you copy the data over, make sure MySQL has proper permissions to access them.</p> <pre><code>$ chown mysql:mysql /path/to/mysql/datadir\n</code></pre>"},{"location":"create-gtid-replica.html#4-configure-and-start-replication","title":"4. Configure and start replication","text":"<p>Set the <code>gtid_purged</code> variable to the <code>GTID</code> from <code>xtrabackup_binlog_info</code>. Then, update the information about the source node and, finally, start the replica.</p> <p>Note</p> <p>The example above is applicable to Percona XtraDB Cluster. The <code>wsrep_on</code> variable is set to 0 before resetting the source (<code>RESET MASTER</code>). The reason is that Percona XtraDB Cluster will not allow resetting the source if <code>wsrep_on=1</code>.</p> <pre><code># Using the mysql shell\n &gt; SET SESSION wsrep_on = 0;\n &gt; RESET MASTER;\n &gt; SET SESSION wsrep_on = 1;\n &gt; SET GLOBAL gtid_purged='&lt;gtid_string_found_in_xtrabackup_binlog_info&gt;';\n &gt; CHANGE REPLICATION SOURCE TO\n             SOURCE_HOST=\"$masterip\",\n             SOURCE_USER=\"repl\",\n             SOURCE_PASSWORD=\"$slavepass\",\n             SOURCE_AUTO_POSITION = 1;\n &gt; START REPLICA;\n</code></pre>"},{"location":"create-gtid-replica.html#5-check-the-replication-status","title":"5. Check the replication status","text":"<p>The following command returns the replica status:</p> <p><pre><code>mysql&gt; SHOW REPLICA STATUS\\G\n</code></pre> The results should be similar to the following:</p> Expected output <pre><code>[..]\nSlave_IO_Running: Yes\nSlave_SQL_Running: Yes\n[...]\nRetrieved_Gtid_Set: c777888a-b6df-11e2-a604-080027635ef5:5\nExecuted_Gtid_Set: c777888a-b6df-11e2-a604-080027635ef5:1-5\n</code></pre> <p>We can see that the replica has retrieved a new transaction with step 5, so transactions from 1 to 5 are already on the replica.</p> <p>We have created a new replica in our <code>GTID</code> based replication environment.</p>"},{"location":"create-gtid-replica.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"create-incremental-backup.html","title":"Create an incremental backup","text":"<p>xtrabackup supports incremental backups, which means that they can copy only all the data that has changed since the last backup.</p> <p>Note</p> <p>Incremental backups on the MyRocks storage engine do not determine if an earlier full backup or incremental backup contains the same files. Percona XtraBackup copies all the MyRocks files each time it takes a backup.</p> <p>You can perform many incremental backups between each full backup, so you can set up a backup process such as a full backup once a week and an incremental backup every day, or full backups every day and incremental backups every hour.</p> <p>Incremental backups work because each InnoDB page contains a log sequence number, or LSN. The LSN is the system version number for the entire database. Each page\u2019s LSN shows how recently it was changed.</p> <p>An incremental backup copies each page which LSN is newer than the previous incremental or full backup\u2019s LSN. An algorithm finds the pages that match the criteria. The algorithm reads the data pages and checks the page LSN.</p>"},{"location":"create-incremental-backup.html#create-an-incremental-backup_1","title":"Create an incremental backup","text":"<p>To make an incremental backup, begin with a full backup as usual. The xtrabackup binary writes a file called <code>xtrabackup_checkpoints</code> into the backup\u2019s target directory. This file contains a line showing the <code>to_lsn</code>, which is the database\u2019s LSN at the end of the backup. Create the full backup with a following command:</p> <pre><code>$ xtrabackup --backup --target-dir=/data/backups/base\n</code></pre> <p>If you look at the <code>xtrabackup_checkpoints</code> file, you should see similar content depending on your LSN nuber:</p> Expected output <pre><code>backup_type = full-backuped\nfrom_lsn = 0\nto_lsn = 1626007\nlast_lsn = 1626007\ncompact = 0\nrecover_binlog_info = 1\n</code></pre> <p>Now that you have a full backup, you can make an incremental backup based on it. Use the following command:</p> <pre><code>$ xtrabackup --backup --target-dir=/data/backups/inc1 \\\n--incremental-basedir=/data/backups/base\n</code></pre> <p>The <code>/data/backups/inc1/</code> directory should now contain delta files, such as <code>ibdata1.delta</code> and <code>test/table1.ibd.delta</code>. These represent the changes since the <code>LSN 1626007</code>. If you examine the <code>xtrabackup_checkpoints</code> file in this directory, you should see similar content to the following:</p> Expected output <pre><code>backup_type = incremental\nfrom_lsn = 1626007\nto_lsn = 4124244\nlast_lsn = 4124244\ncompact = 0\nrecover_binlog_info = 1\n</code></pre> <p><code>from_lsn</code> is the starting LSN of the backup and for incremental it has to be the same as <code>to_lsn</code> (if it is the last checkpoint) of the previous/base backup.</p> <p>It\u2019s now possible to use this directory as the base for yet another incremental backup:</p> <pre><code>$ xtrabackup --backup --target-dir=/data/backups/inc2 \\\n--incremental-basedir=/data/backups/inc1\n</code></pre> <p>This folder also contains the <code>xtrabackup_checkpoints</code>:</p> Expected output <pre><code>backup_type = incremental\nfrom_lsn = 4124244\nto_lsn = 6938371\nlast_lsn = 7110572\ncompact = 0\nrecover_binlog_info = 1\n</code></pre> <p>Note</p> <p>In this case you can see that there is a difference between the <code>to_lsn</code> (last checkpoint LSN) and <code>last_lsn</code> (last copied LSN), this means that there was some traffic on the server during the backup process.</p>"},{"location":"create-incremental-backup.html#next-step","title":"Next step","text":"<p>Prepare the backup </p>"},{"location":"create-incremental-backup.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"create-individual-partition-backup.html","title":"Create an individual partitions backup","text":"<p>Percona XtraBackup lets you back up individual partitions because partitions are regular tables with specially formatted names. The only requirement for this feature is to enable the <code>innodb_file_per_table</code> option on the server.</p> <p>There is one caveat about using this kind of backup: you can not copy back the prepared backup. Restoring partial backups should be done by importing the tables.</p> <p>There are three ways of specifying which part of the whole data will be backed up: regular expressions ( \u2013tables), enumerating the tables in a file (\u2013tables) or providing a list of databases (\u2013databases).</p> <p>The regular expression provided to this option will be matched against the fully qualified database name and table name, in the form of <code>database-name.table-name</code>.</p> <p>If the partition 0 is not backed up, Percona XtraBackup cannot generate a .cfg file. MySQL 8.0 stores the table metadata in partition 0.</p> <p>For example, this operation takes a back-up of the partition <code>p4</code> from  the table <code>name</code> located in the database <code>imdb</code>:</p> <pre><code>$ xtrabackup --tables=^imdb[.]name#p#p4 --backup\n</code></pre> <p>If partition 0 is not backed up, the following errors may occur:</p> The error message <pre><code>xtrabackup: export option not specified\nxtrabackup: error: cannot find dictionary record of table imdb/name#p#p4\n</code></pre> <p>Note that this option is passed to <code>xtrabackup --tables</code> and is matched against each table of each database, the directories of each database will be created even if they are empty.</p>"},{"location":"create-individual-partition-backup.html#next-step","title":"Next step","text":"<p>Prepare an individual partitions backup </p>"},{"location":"create-individual-partition-backup.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"create-partial-backup.html","title":"Create a partial backup","text":"<p>xtrabackup supports taking partial backups when the <code>innodb_file_per_table</code> option is enabled.</p> <p>Warning</p> <p>Do not copy back the prepared backup.</p> <p>Restoring partial backups should be done by importing the tables. We do not by using the <code>\u2013copy-back</code> option. This operation may lead to database inconsistencies.</p> <p>We do not recommend running incremental backups after taking a partial backup.</p> <p>The xtrabackup binary fails if you delete any of the matched or listed tables during the backup.</p> <p>There are multiple ways of specifying which part of the whole data is backed up:</p> <ul> <li> <p>Use the <code>--tables</code> option to list the table names</p> </li> <li> <p>Use the <code>--tables-file</code> option to list the tables in a file</p> </li> <li> <p>Use the <code>--databases</code> option to list the databases</p> </li> <li> <p>Use the <code>--databases-file</code> option to list the databases</p> </li> </ul> <p>The following examples assume a database named <code>test</code> that contains tables named <code>t1</code> and <code>t2</code>.</p> <code>\u2013-tables</code> option<code>-\u2013tables-file</code> option<code>--databases</code> option<code>--databases-file</code> option <p>The first method involves the xtrabackup <code>\u2013tables</code> option. The option\u2019s value is a regular expression that is matched against the fully-qualified database name and table name using the <code>databasename.tablename</code> format.</p> <p>To back up only tables in the <code>test</code> database, use the following command:</p> <pre><code>$ xtrabackup --backup --datadir=/var/lib/mysql --target-dir=/data/backups/ \\\n--tables=\"^test[.].*\"\n</code></pre> <p>To back up only the <code>test.t1</code> table, use the following command:</p> <pre><code>$ xtrabackup --backup --datadir=/var/lib/mysql --target-dir=/data/backups/ \\\n--tables=\"^test[.]t1\"\n</code></pre> <p>The <code>--tables-file</code> option specifies a file that can contain multiple table names, one table name per line in the file. Only the tables named in the file will be backed up. Names are matched exactly, case-sensitive, with no pattern or regular expression matching. The table names must be fully-qualified in <code>databasename.tablename</code> format.</p> <pre><code>$ echo \"mydatabase.mytable\" &gt; /tmp/tables.txt\n$ xtrabackup --backup --tables-file=/tmp/tables.txt\n</code></pre> <p>The ` \u2013databases` option accepts a space-separated list of the databases and tables to backup in the <code>databasename[.tablename]</code> format. In addition to this list, make sure to specify the <code>mysql</code>, <code>sys</code>, and</p> <p><code>performance_schema</code> databases. These databases are required when restoring the databases using xtrabackup \u2013copy-back.</p> <p>Note</p> <p>Tables processed during the \u2013prepare step may also be added to the backup even if they are not explicitly listed by the parameter if they were created after the backup started.</p> <pre><code>$ xtrabackup --databases='mysql sys performance_schema test ...'\n</code></pre> <p>The \u2013databases-file option specifies a file that can contain multiple databases and tables in the <code>databasename[.tablename]</code> format, one element name per line in the file. Names are matched exactly, case-sensitive, with no pattern or regular expression matching.</p> <p>Note</p> <p>Tables processed during the \u2013prepare step may also be added to the backup even if they are not explicitly listed by the parameter if they were created after the backup started.</p>"},{"location":"create-partial-backup.html#next-step","title":"Next step","text":"<p>Prepare the backup </p>"},{"location":"create-partial-backup.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"dictionary-cache.html","title":"Dictionary cache","text":"<p>Percona XtraBackup is based on how [<code>crash recovery</code>] works. Percona XtraBackup copies the InnoDB data files, which results in data that is internally inconsistent; then the <code>prepare</code> phase performs crash recovery on the files to make a consistent, usable database again.</p> <p>The <code>--prepare</code> phase has the following operations:</p> <ul> <li>Applies the redo log</li> <li>Applies the undo log</li> </ul> <p>As a physical operation, the changes from the redo log modifications are applied to a page. In the redo log operation, there is no concept of row or transaction. The redo apply operation does not make the database consistent with a transaction. An uncommitted transaction can be flushed or written to the redo log by the server. Percona XtraBackup applies changes recorded in the redo log.</p> <p>Percona XtraBackup physically modifies a specific offset of a page within a tablespace (IBD file) when applying a redo log. </p> <p>As a logical operation, Percona XtraBackup applies the undo log on a specific row. When the redo log completes, XtraBackup uses the undo log to roll back changes from uncommitted transactions during the backup.</p>"},{"location":"dictionary-cache.html#undo-log","title":"Undo log","text":"<p>There are two types of undo log records:</p> <ul> <li>INSERT</li> <li>UPDATE</li> </ul> <p>An undo log record contains a <code>table_id</code>. Percona XtraBackup uses this <code>table_id</code> to find the table definition, and then uses that information to parse the records on an index page. The transaction rollback reads the undo log records and applies the changes. </p> <p>After initializing the data dictionary engine and the data dictionary cache, the storage engine can request the <code>table_id</code> and uses this ID to fetch the table schema. An index search tuple (key) is created from the table schema and key fields from the undo log record. The server finds the record using the search tuple (key) and performs the undo operation.</p> <p>For example, InnoDB uses the <code>table_id</code> (also known as the <code>se_private_id</code>) for a table definition. Percona XtraBackup does not behave like a server and does not have access to the data dictionary. XtraBackup initializes the InnoDB engine and uses the <code>InnoDB table object</code> (<code>dict_table_t</code>) when needed. XtraBackup relies on Serialized Dictionary Information (SDI) that is stored in the tablespace. SDI is a JSON representation of a table.</p> <p>In Percona XtraBackup {{release}}, tables are loaded as <code>evictable</code>. XtraBackup scans the B-tree index of the data dictionary tables <code>mysql.indexes</code> and <code>mysql.index_partitions</code> to establish a relationship between the <code>table_id</code> and the <code>tablespace(space_id)</code>. XtraBackup uses this relationship during transaction rollback. XtraBackup does not load user tables unless there is a transaction rollback on them.</p> <p>A background thread or a Percona XtraBackup main thread handles the cache eviction when the cache size limit is reached.</p> <p>This  design provides the following benefits during the <code>--prepare</code> phase:</p> <ul> <li>Uses less memory</li> <li>Uses less IO</li> <li>Improves the time taken in the <code>--prepare</code> phase</li> <li>Completes successfully, even if the <code>--prepare</code> phase has a huge number of tables</li> <li>Completes the Percona XtraDB Cluster SST process faster</li> </ul>"},{"location":"dictionary-cache.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"docker.html","title":"Run a Docker container","text":"<p>Docker allows you to run applications in a lightweight unit called a container.</p> <p>You can run Percona XtraBackup in a Docker container without installing the product. All required libraries are available in the container. Being a lightweight execution environment, Docker containers enable creating configurations where each program runs in a separate container. You may run Percona Server for MySQL in one container and Percona XtraBackup in another. Docker images offer a range of options.</p> <p>Create a Docker container based on a Docker image. Docker images for Percona XtraBackup are hosted publicly on Docker Hub.</p> <pre><code>$ sudo docker create ... percona/percona-xtrabackup --name xtrabackup ...\n</code></pre>"},{"location":"docker.html#scope-of-this-section","title":"Scope of this section","text":"<p>This section demonstrates how to back up data on a Percona Server for MySQL running in another Dockers container.</p>"},{"location":"docker.html#1-install-docker","title":"1. Install Docker","text":"<p>Your operating system may already provide a package for docker. However, the versions of Docker provided by your operating system are likely to be outdated.</p> <p>Use the installation instructions for your operating system available from the Docker site to set up the latest version of docker.</p>"},{"location":"docker.html#2-connect-to-a-percona-server-for-mysql-container","title":"2. Connect to a Percona Server for MySQL container","text":"<p>Percona XtraBackup works in combination with a database server. When running a Docker container for Percona XtraBackup, you can make backups for a database server either installed on the host machine or running in a separate Docker container.</p> <p>To set up a database server on a host machine or in Docker container, follow the documentation of the supported product that you intend to use with Percona XtraBackup.</p> <p>See also</p> <p>Docker volumes as container persistent data storage</p> <p>More information about containers</p> <pre><code>$ sudo docker run -d --name percona-server-mysql \\\n-e MYSQL_ROOT_PASSWORD=root percona/percona-server:{{vers}}\n</code></pre> <p>As soon as Percona Server for MySQL runs, add some data to it. Now, you are ready to make backups with Percona XtraBackup.</p> <p>Important</p> <p>When running Percona XtraBackup from a container and connecting to a  MySQLserver container, we recommend using the \u2013user root option in the  Docker command.</p>"},{"location":"docker.html#3-create-a-docker-container-from-percona-xtrabackup-image","title":"3. Create a Docker container from Percona XtraBackup image","text":"<p>You can create a Docker container based on Percona XtraBackup image with either <code>docker create</code> or the <code>docker run</code> command. <code>docker create</code> creates a Docker container and makes it available for starting later.</p> <p>Docker downloads the Percona XtraBackup image from the Docker Hub. If it is not the first time you use the selected image, Docker uses the image available locally.</p> <pre><code>$ sudo docker create --name percona-xtrabackup --volumes-from percona-server-mysql \\\npercona/percona-xtrabackup  \\\nxtrabackup --backup --datadir=/var/lib/mysql/ --target-dir=/backup \\\n--user=root --password=mysql\n</code></pre> <p>With parameter name you give a meaningful name to your new Docker container so that you could easily locate it among your other containers.</p> <p>The <code>volumes-from</code> flag refers to Percona Server for MySQL and indicates that you intend to use the same data as the Percona Server for MySQL container.</p> <p>Run the container with exactly the same parameters that were used when the container was created:</p> <pre><code>$ sudo docker start -ai percona-xtrabackup\n</code></pre> <p>This command starts the percona-xtrabackup container, attaches to its input/output streams, and opens an interactive shell.</p> <p>The <code>docker run</code> is a shortcut command that creates a Docker container and then immediately runs it.</p> <pre><code>$ sudo docker run --name percona-xtrabackup --volumes-from percona-server-mysql \\\npercona/percona-xtrabackup\nxtrabackup --backup --data-dir=/var/lib/mysql --target-dir=/backup --user=root --password=mysql\n</code></pre>"},{"location":"docker.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"encrypt-backups.html","title":"Encrypt backups","text":""},{"location":"encrypt-backups.html#encrypt-backups_1","title":"Encrypt backups","text":"<p>Percona XtraBackup supports encrypting and decrypting local and streaming backups with the upstream option, adding another protection layer. The encryption is implemented using the <code>libgcrypt</code> library from GnuPG.</p>"},{"location":"encrypt-backups.html#create-encrypted-backups","title":"Create encrypted backups","text":"<p>The following options create encrypted backups. The <code>--encrypt-key</code> and <code>--encrypt-key-file</code> options specify the encryption key and are mutually exclusive. You should select one or the other.</p> <ul> <li> <p><code>--encrypt</code></p> </li> <li> <p><code>--encrypt-key</code></p> </li> <li> <p><code>--encrypt-key-file</code></p> </li> </ul> <p>For an encryption key, use a command, such as <code>openssl rand -base64 24</code>, to generate a random alphanumeric string.</p>"},{"location":"encrypt-backups.html#the-encrypt-key-option","title":"The <code>--encrypt-key</code> option","text":"<p>An example of the xtrabackup command using the <code>--encrypt-key</code>:</p> <pre><code>$  xtrabackup --backup --encrypt=AES256 --encrypt-key=\"{randomly-generated-alphanumeric-string}\" --target-dir=/data/backup\n</code></pre>"},{"location":"encrypt-backups.html#the-encrypt-key-file-option","title":"The <code>--encrypt-key-file</code> option","text":"<p>The recommended method uses the command line: <code>echo -n \u201c{randomly-generated-alphanumeric-string}\u201d &gt; /data/backups/keyfile</code> to create the file. Remember that using the\u2013 encrypt-key-file option, your text editor can automatically insert a CRLF (end of line) character in the <code>KEYFILE</code>. This inserted character invalidates the key because the size is wrong. </p> <p>An example of using the <code>--encrypt-key-file</code> option:</p> <pre><code>$ xtrabackup --backup --encrypt=AES256 --encrypt-key-file=/data/backups/keyfile --target-dir=/data/backup\n</code></pre>"},{"location":"encrypt-backups.html#optimize-the-encryption-process","title":"Optimize the encryption process","text":"<p>Additional encrypted backup options, <code>--encrypt-threads</code> and <code>--encrypt-chunk-size</code>, can speed up the encryption process. </p> <p>Use the <code>--encrypt-threads</code> option to enable parallel encryption with multiple threads. </p> <p>The <code>--encrypt-chunk-size</code> option specifies the size, in bytes, of the working encryption buffer for each encryption thread. The default size is 64K.</p>"},{"location":"encrypt-backups.html#decrypt-encrypted-backups","title":"Decrypt encrypted backups","text":"<p>You can decrypt backups with the <code>xbcrypt</code> binary. The following example encrypts a backup.</p> <p>You can use the <code>--parallel</code> option and the <code>--decrypt</code> option to decrypt multiple files simultaneously.</p> <pre><code>$ for i in `find . -iname \"*\\.xbcrypt\"`; do xbcrypt -d --encrypt-key-file=/root/secret_key --encrypt-algo=AES256 &lt; $i &gt; $(dirname $i)/$(basename $i .xbcrypt) &amp;&amp; rm $i; done\n</code></pre> <p>The following example shows a decryption process.</p> <pre><code>$ xtrabackup --decrypt=AES256 --encrypt-key=\"{randomly-generated-alphanumeric-string}\" --target-dir=/data/backup/\n</code></pre> <p>Percona XtraBackup doesn\u2019t automatically remove the encrypted files. You must remove the <code>\\*.xbcrypt</code> files manually.</p>"},{"location":"encrypt-backups.html#prepare-encrypted-backups","title":"Prepare encrypted backups","text":"<p>After decrypting the backups, prepare the backups with the <code>--prepare</code> option:</p> <pre><code>$ xtrabackup --prepare --target-dir=/data/backup/\n</code></pre>"},{"location":"encrypt-backups.html#restore-encrypted-backups","title":"Restore encrypted backups","text":"<p>xtrabackup offers the <code>--copy-back</code> option to restore a backup to the server\u2019s datadir:</p> <pre><code>$ xtrabackup --copy-back --target-dir=/data/backup/\n</code></pre> <p>The option copies all the data-related files to the server\u2019s datadir. The server\u2019s <code>my.cnf</code> configuration file determines the location. </p> <p>You should check the last line of the output for a success message:</p> Expected output <pre><code>150318 11:08:13  xtrabackup: completed OK!\n</code></pre>"},{"location":"encrypt-backups.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"encrypted-innodb-tablespace-backups.html","title":"Encrypted InnoDB tablespace backups","text":"<p>InnoDB supports data encryption for InnoDB tables stored in file-per-table tablespaces. This feature provides an at-rest encryption for physical tablespace data files.</p> <p>For an authenticated user or an application to access an encrypted F tablespace, InnoDB uses the master encryption key to decrypt the tablespace key. The master encryption key is stored in a keyring. </p> <p>Percona XtraBackup supports the following keyring components and plugins: </p> <ul> <li> <p>keyring_vault component</p> </li> <li> <p>keyring_file plugin</p> </li> <li> <p>keyring_file component</p> </li> <li> <p>Key Management Interoperability Protocol (KMIP)</p> </li> <li> <p>Amazon Key Management Service (AWS KMS)</p> </li> </ul> <p>These components are stored in the <code>plugin</code> directory.</p> <p>Note</p> <p>Enable only one keyring plugin or one keyring component simultaneously for each server instance. Enabling multiple keyring plugins or keyring components or mixing keyring plugins or keyring components is not supported and may result in data loss.</p>"},{"location":"encrypted-innodb-tablespace-backups.html#use-the-keyring-vault-component","title":"Use the keyring vault component","text":"<p>The <code>keyring_vault</code> component extends the server capabilities. The server uses a manifest to load the component and the component has its own configuration file.</p> <p>The following example is a global manifest file that does not use local manifests:</p> <pre><code>{\n \"read_local_manifest\": false,\n \"components\": \"file://component_keyring_vault\"\n}\n</code></pre> <p>The following example of a global manifest file that points to a local manifest file:</p> <pre><code>{\n \"read_local_manifest\": true\n}\n</code></pre> <p>The following example of a local manifest file:</p> <pre><code>{\n \"components\": \"file://component_keyring_vault\"\n}\n</code></pre> <p>The configuration settings can be in either a global or a local configuration file.</p> Example of a configuration file in JSON format <pre><code>{\n \"timeout\": 15,\n \"vault_url\": \"https://vault.public.com:8202\",\n \"secret_mount_point\": \"secret\",\n \"secret_mount_point_version\": \"AUTO\",\n \"token\": \"58a20c08-8001-fd5f-5192-7498a48eaf20\",\n \"vault_ca\": \"/data/keyring_vault_confs/vault_ca.crt\"\n}\n</code></pre> <p>Find more information on configuring the <code>keyring_vault</code> component in Use the keyring vault component.</p> <p>The component has no special requirements for backing up a database that contains encrypted InnoDB tablespaces.</p> <p>The following command creates a backup in the <code>/data/backup</code> directory:</p> <pre><code>$ xtrabackup --backup --target-dir=/data/backup --user=root\n</code></pre> <p>After xtrabackup completes the action, the following message confirms the action:</p> Confirmation message <pre><code>xtrabackup: Transaction log of lsn (5696709) to (5696718) was copied.\n160401 10:25:51 completed OK!\n</code></pre>"},{"location":"encrypted-innodb-tablespace-backups.html#prepare-the-backup-with-the-keyring-vault-component","title":"Prepare the backup with the keyring vault component","text":"<p>To prepare the backup, the xtrabackup binary must access the keyring. The xtrabackup binary does not communicate with the MySQL server or read the default <code>my.cnf</code> configuration file. Specify the keyring settings in the command line:</p> <pre><code>$ xtrabackup --prepare --target-dir=/data/backup --component-keyring-config==/etc/vault.cnf\n</code></pre> <p>The following message confirms that the xtrabackup binary completed the action:</p> Confirmation message <pre><code>InnoDB: Shutdown completed; log sequence number 5697064\n160401 10:34:28 completed OK!\n</code></pre>"},{"location":"encrypted-innodb-tablespace-backups.html#restore-the-backup","title":"Restore the backup","text":"<p>As soon as the backup is prepared, you can restore it with the <code>--copy-back</code> option:</p> <pre><code>$ xtrabackup --copy-back --target-dir=/data/backup --datadir=/data/mysql \\\n--transition-key=MySecretKey --generate-new-master-key \\\n--component-keyring-config=/etc/vault.cnf\n</code></pre>"},{"location":"encrypted-innodb-tablespace-backups.html#use-the-keyring-file-plugin","title":"Use the keyring file plugin","text":"<p>Warning</p> <p>The <code>keyring_file</code> plugin should not be used for regulatory compliance.</p> <p>In order to back up and prepare a database containing encrypted InnoDB tablespaces, specify the path to a keyring file as the value of the <code>--keyring-file-data</code> option.</p> <pre><code>$ xtrabackup --backup --target-dir=/data/backup/ --user=root \\\n--keyring-file-data=/var/lib/mysql-keyring/keyring\n</code></pre> <p>The following message confirms that the xtrabackup binary completed the action:</p> Confirmation message <pre><code>xtrabackup: Transaction log of lsn (5696709) to (5696718) was copied.\n160401 10:25:51 completed OK!\n</code></pre> <p>Warning</p> <p>xtrabackup does not copy the keyring file into the backup directory. To prepare the backup, you must copy the keyring file manually.</p>"},{"location":"encrypted-innodb-tablespace-backups.html#prepare-the-backup-with-the-keyring-file-plugin","title":"Prepare the backup with the keyring file plugin","text":"<p>To prepare the backup, specify the keyring-file-data.</p> <pre><code>$ xtrabackup --prepare --target-dir=/data/backup \\\n--keyring-file-data=/var/lib/mysql-keyring/keyring\n</code></pre> <p>The following message confirms that the xtrabackup binary completed the action:</p> Confirmation message <pre><code>InnoDB: Shutdown completed; log sequence number 5697064\n160401 10:34:28 completed OK!\n</code></pre> <p>The backup is now prepared and can be restored with the <code>--copy-back</code> option. You must restore the keyring used with the backup and prepare phases if the keyring has been rotated.</p>"},{"location":"encrypted-innodb-tablespace-backups.html#use-the-keyring-file-component","title":"Use the keyring file component","text":"<p>The <code>keyring_file</code> component is part of the component-based MySQL infrastructure which extends the server capabilities.</p> <p>The server uses a manifest to load the component, and the component has its own configuration file. See the MySQL documentation on the component  installation for more information.</p> <p>An example of a manifest and a configuration file follows:</p> <p>An example of <code>./bin/mysqld.my</code>:</p> <pre><code>{\n   \"components\": \"file://component_keyring_file\"\n}\n</code></pre> <p>An example of <code>/lib/plugin/component_keyring_file.cnf</code>:</p> <pre><code>{\n   \"path\": \"/var/lib/mysql-keyring/keyring_file\", \"read_only\": false\n}\n</code></pre> <p>For more information, see Keyring Component Installation and Using the keyring_file File-Based Keyring Plugin.</p> <p>With the appropriate privilege, you can <code>SELECT</code> on the performance_schema.keyring_component_status table to view the attributes and status of the installed keyring component  when in use.</p> <p>The component has no special requirements for backing up a database that contains encrypted InnoDB tablespaces.</p> <pre><code>$ xtrabackup --backup --target-dir=/data/backup --user=root\n</code></pre> <p>The following message confirms that the xtrabackup binary completed the action:</p> Confirmation message <pre><code>xtrabackup: Transaction log of lsn (5696709) to (5696718) was copied.\n160401 10:25:51 completed OK!\n</code></pre> <p>Warning</p> <p>xtrabackup does not copy the keyring file into the backup directory. To prepare the backup, you must copy the keyring file manually.</p>"},{"location":"encrypted-innodb-tablespace-backups.html#prepare-the-backup-with-the-keyring_file-component","title":"Prepare the backup with the keyring_file component","text":"<p>xtrabackup reads the <code>keyring_file</code> component configuration from <code>xtrabackup_component_keyring_file.cnf</code>. You must specify the keyring_file data path if the <code>--component-keyring-config</code> is not located in the attribute <code>PATH</code> from the <code>xtrabackup_component_keyring_file.cnf</code>.</p> <p>The following is an example of adding the location for the \u2013component-keyring-config:</p> <pre><code>$ xtrabackup --prepare --target-dir=/data/backup \\\n--component-keyring-config=/var/lib/mysql-keyring/keyring\n</code></pre> <p>xtrabackup attempts to read <code>xtrabackup_component_keyring_file.cnf</code>. You can assign another keyring file component configuration by passing the <code>--component-keyring-config</code> option.</p> <p>The following message confirms that the xtrabackup binary completed the action:</p> Confirmation message <pre><code>InnoDB: Shutdown completed; log sequence number 5697064\n160401 10:34:28 completed OK!\n</code></pre> <p>The backup is prepared. To restore the backup use the <code>--copy-back</code> option. If the keyring has been rotated, you must restore the specific keyring used to take and prepare the backup.</p>"},{"location":"encrypted-innodb-tablespace-backups.html#incremental-encrypted-innodb-tablespace-backups-with-keyring-file-plugin","title":"Incremental encrypted InnoDB tablespace backups with keyring file plugin","text":"<p>The process of taking incremental backups with InnoDB tablespace encryption is similar to taking incremental backups with unencrypted tablespace. </p>"},{"location":"encrypted-innodb-tablespace-backups.html#create-an-incremental-backup","title":"Create an incremental backup","text":"<p>To make an incremental backup, begin with a full backup. The xtrabackup binary writes <code>xtrabackup_checkpoints</code> into the backup\u2019s target directory. This file contains a line showing the <code>to_lsn</code>, which is the LSN of the database at the end of the backup. First, you need to create a full backup with the following command:</p> <pre><code>$ xtrabackup --backup --target-dir=/data/backups/base \\\n--keyring-file-data=/var/lib/mysql-keyring/keyring\n</code></pre> <p>To prepare the backup, you must make a copy of the keyring file yourself. The xtrabackup binary does not copy the keyring file into the backup directory. Restoring the backup after the keyring has been changed causes errors like <code>ERROR 3185 (HY000): Can't find master key from keyring, please check keyring plugin is loaded.</code> when the restore process tries accessing an encrypted table.</p> <p>If you look at the <code>xtrabackup_checkpoints</code> file, you should see the output similar to the following:</p> Expected output <pre><code>backup_type = full-backuped\nfrom_lsn = 0\nto_lsn = 7666625\nlast_lsn = 7666634\ncompact = 0\nrecover_binlog_info = 1\n</code></pre> <p>Now that you have a full backup, you can make an incremental backup based on it. Use a command such as the following:</p> <pre><code>$ xtrabackup --backup --target-dir=/data/backups/inc1 \\\n--incremental-basedir=/data/backups/base \\\n--keyring-file-data=/var/lib/mysql-keyring/keyring\n</code></pre> <p>To prepare the backup, you must copy the keyring file manually. The xtrabackup binary does not copy the keyring file into the backup directory. </p> <p>If the keyring has not been rotated you can use the same one you\u2019ve backed-up with the base backup. If the keyring has been rotated, or you have  upgraded the plugin to a component, you must back up the keyring file.  Otherwise, you cannot prepare the backup.</p> <p>The <code>/data/backups/inc1/</code> directory should now contain delta files, such as <code>ibdata1.delta</code> and <code>test/table1.ibd.delta</code>. These represent the changes since the <code>LSN 7666625</code>. If you examine the <code>xtrabackup_checkpoints</code> file in this directory, you should see  the output similar to the following:</p> Expected output <pre><code>backup_type = incremental\nfrom_lsn = 7666625\nto_lsn = 8873920\nlast_lsn = 8873929\ncompact = 0\nrecover_binlog_info = 1\n</code></pre> <p>Use this directory as the base for yet another incremental backup:</p> <pre><code>$ xtrabackup --backup --target-dir=/data/backups/inc2 \\\n--incremental-basedir=/data/backups/inc1 \\\n--keyring-file-data=/var/lib/mysql-keyring/keyring\n</code></pre>"},{"location":"encrypted-innodb-tablespace-backups.html#prepare-incremental-backups","title":"Prepare incremental backups","text":"<p>The <code>--prepare</code> step for incremental backups is not the same as for normal backups. In normal backups, two types of operations are performed to make the database consistent: </p> <ul> <li> <p>Committed transactions are replayed from the log file against the data files</p> </li> <li> <p>Uncommitted transactions are rolled back</p> </li> </ul> <p>You must skip the rollback of uncommitted transactions when preparing a backup because transactions that were uncommitted at the time of your backup may be in progress, and they will likely be committed in the next incremental backup. Use the <code>-</code>-apply-log-only<code>option to prevent the rollback phase. Your incremental backups are useless if you do not use the</code>\u2013apply-log-only` option to prevent the rollback phase. After transactions have been rolled back, further incremental backups cannot be applied.</p> <p>Beginning with the full backup you created, you can prepare it and then apply the incremental differences. Recall that you have the following backups:</p> <pre><code>/data/backups/base\n/data/backups/inc1\n/data/backups/inc2\n</code></pre> <p>To prepare the base backup, you need to run <code>--prepare</code> as usual, but prevent the rollback phase:</p> <pre><code>$ xtrabackup --prepare --apply-log-only --target-dir=/data/backups/base \\\n--keyring-file-data=/var/lib/mysql-keyring/keyring\n</code></pre> Expected output <pre><code>InnoDB: Shutdown completed; log sequence number 7666643\nInnoDB: Number of pools: 1\n160401 12:31:11 completed OK!\n</code></pre> <p>To apply the first incremental backup to the full backup, you should use the following command:</p> <pre><code>$ xtrabackup --prepare --apply-log-only --target-dir=/data/backups/base \\\n--incremental-dir=/data/backups/inc1 \\\n--keyring-file-data=/var/lib/mysql-keyring/keyring\n</code></pre> <p>The backup should be prepared with the keyring file and type that was used when the backup was being taken. This means that if the keyring has been rotated, or you have upgraded from a plugin to a component between the base and incremental backup, you must use the keyring used when the first incremental backup was taken.</p> <p>Preparing the second incremental backup is a similar process: apply the deltas to the (modified) base backup, and you will roll its data forward in  time to the point of the second incremental backup:</p> <p><pre><code>$ xtrabackup --prepare --target-dir=/data/backups/base \\\n--incremental-dir=/data/backups/inc2 \\\n--keyring-file-data=/var/lib/mysql-keyring/keyring\n</code></pre> Use <code>--apply-log-only</code> when merging all incremental backups except the last one. The previous line does not contain the <code>--apply-log-only</code> option. Even if the <code>--apply-log-only</code> option was used on the last step, the backup would still be consistent, but in that case, the server would perform the rollback phase.</p> <p>The backup is now prepared and can be restored with <code>--copy-back</code> option. In case the keyring has been rotated you\u2019ll need to restore the keyring which was used to take and prepare the backup.</p>"},{"location":"encrypted-innodb-tablespace-backups.html#restore-a-backup-when-the-keyring-is-not-available","title":"Restore a backup when the keyring is not available","text":"<p>While this works, the method requires access to the same keyring that the server is using. It may not be possible if the backup is prepared on a different server or at a much later time, when keys in the keyring are purged, or, in the case of a malfunction, when the keyring vault server is unavailable.</p> <p>The <code>--transition-key=&lt;passphrase&gt;</code> option should be used to make it possible for the xtrabackup binary to process the backup without access to the keyring vault server. In this case, the binary derives the AES encryption key from the specified passphrase and will use it to encrypt tablespace keys of tablespaces being backed up.</p>"},{"location":"encrypted-innodb-tablespace-backups.html#create-a-backup-with-a-passphrase","title":"Create a backup with a passphrase","text":"<p>The following example illustrates how the backup can be created in this case:</p> <pre><code>$ xtrabackup --backup --user=root -p --target-dir=/data/backup \\\n--transition-key=MySecretKey\n</code></pre> <p>If <code>--transition-key</code> is specified without a value, xtrabackup will ask for it.</p> <p>xtrabackup scrapes <code>--transition-key</code> so that its value is not visible in the <code>ps</code> command output.</p>"},{"location":"encrypted-innodb-tablespace-backups.html#prepare-a-backup-with-a-passphrase","title":"Prepare a backup with a passphrase","text":"<p>The same passphrase should be specified for the prepare command:</p> <pre><code>$ xtrabackup --prepare --target-dir=/data/backup \\\n--transition-key=MySecretKey\n</code></pre> <p>There are no <code>--keyring-vault...</code>,``\u2013keyring-file\u2026``, or <code>--component-keyring-config</code> options here, because xtrabackup does not talk to the keyring in this case.</p>"},{"location":"encrypted-innodb-tablespace-backups.html#restore-a-backup-with-a-generated-key","title":"Restore a backup with a generated key","text":"<p>When restoring a backup you need to generate a new master key. </p> <p>The example for <code>keyring_file</code> plugin:</p> <pre><code>$ xtrabackup --copy-back --target-dir=/data/backup --datadir=/data/mysql \\\n--transition-key=MySecretKey --generate-new-master-key \\\n--keyring-file-data=/var/lib/mysql-keyring/keyring\n</code></pre> <p>The example for <code>keyring_file</code> component:</p> <pre><code>$ xtrabackup --copy-back --target-dir=/data/backup --datadir=/data/mysql \\\n--transition-key=MySecretKey --generate-new-master-key \\\n--component-keyring-config=/var/lib/mysql-keyring/keyring\n</code></pre> <p>The example for <code>keyring_vault</code> component:</p> <pre><code>$ xtrabackup --copy-back --target-dir=/data/backup --datadir=/data/mysql \\\n--transition-key=MySecretKey --generate-new-master-key \\\n--component-keyring-config=/etc/vault.cnf\n</code></pre> <p>xtrabackup generates a new master key, stores it in the target keyring vault server, and re-encrypts the tablespace keys using this key.</p>"},{"location":"encrypted-innodb-tablespace-backups.html#make-a-backup-with-a-stored-transition-key","title":"Make a backup with a stored transition key","text":"<p>Finally, there is an option to store a transition key in the keyring. In this case, xtrabackup must access the same keyring file or vault server during prepare and copy-back steps, but does not depend on whether the server keys have been purged.</p> <p>In this scenario, the three stages of the backup process look as follows.</p> <ul> <li>Back up</li> </ul> <pre><code>$ xtrabackup --backup --user=root -p --target-dir=/data/backup \\\n--generate-transition-key\n</code></pre> <ul> <li> <p>Prepare</p> <ul> <li><code>keyring_file</code> plugin variant:</li> </ul> <pre><code>$ xtrabackup --prepare --target-dir=/data/backup \\\n--keyring-file-data=/var/lib/mysql-keyring/keyring\n</code></pre> <ul> <li><code>keyring_file</code> component variant:</li> </ul> <pre><code>$ xtrabackup --prepare --target-dir=/data/backup \\\n--component-keyring-config=/var/lib/mysql-keyring/keyring\n</code></pre> <ul> <li><code>keyring_vault</code> component variant:</li> </ul> <pre><code>$ xtrabackup --prepare --target-dir=/data/backup \\\n--component-keyring-config=/etc/vault.cnf\n</code></pre> </li> <li> <p>Copy-back</p> <ul> <li><code>keyring_file</code> plugin variant:</li> </ul> <pre><code>$ xtrabackup --copy-back --target-dir=/data/backup --datadir=/data/mysql \\\n--generate-new-master-key --keyring-file-data=/var/lib/mysql-keyring/keyring\n</code></pre> <ul> <li><code>keyring_file</code> component variant:</li> </ul> <pre><code>$ xtrabackup --copy-back --target-dir=/data/backup --datadir=/data/mysql \\\n--generate-new-master-key --component-keyring-config=/var/lib/mysql-keyring/keyring\n</code></pre> <ul> <li><code>keyring_vault</code> component variant:</li> </ul> <pre><code>$ xtrabackup --copy-back --target-dir=/data/backup --datadir=/data/mysql \\\n--generate-new-master-key --component-keyring-config=/etc/vault.cnf\n</code></pre> </li> </ul>"},{"location":"encrypted-innodb-tablespace-backups.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"faq.html","title":"Faq","text":""},{"location":"faq.html#frequently-asked-questions","title":"Frequently asked questions","text":""},{"location":"faq.html#does-percona-xtrabackup-vers-support-making-backups-of-databases-in-versions-prior-to-vers","title":"Does Percona XtraBackup {{vers}} support making backups of databases in versions prior to {{vers}}?","text":"<p>Percona XtraBackup {{vers}} does not support making backups of databases created in versions prior to {{vers}} of MySQL, Percona Server for MySQL or Percona XtraDB Cluster. </p>"},{"location":"faq.html#are-you-aware-of-any-web-based-backup-management-tools-commercial-or-not-built-around-percona-xtrabackup","title":"Are you aware of any web-based backup management tools (commercial or not) built around Percona XtraBackup*?","text":"<p>ZRM Community is a community tool that uses Percona XtraBackup for Non-Blocking Backups:</p> <p>\u201cZRM provides support for non-blocking backups of MySQL using Percona XtraBackup. ZRM with \\Percona XtraBackup provides resource utilization management by providing throttling based on the number of IO operations per second. Percona XtraBackup based backups also allow for table level recovery even though the backup was done at the database level (needs the recovery database server to be Percona Server for MySQL with XtraDB).\u201d*</p>"},{"location":"faq.html#xtrabackup-binary-fails-with-a-floating-point-exception","title":"xtrabackup binary fails with a floating point exception","text":"<p>In most of the cases this is due to not having installed the required libraries (and version) by xtrabackup. Installing the GCC suite with the supporting libraries and recompiling xtrabackup solves the issue. See Compiling and Installing from Source Code for instructions on the procedure.</p>"},{"location":"faq.html#how-xtrabackup-handles-the-ibdataib_log-files-on-restore-if-they-arent-in-mysql-datadir","title":"How xtrabackup handles the ibdata/ib_log files on restore if they aren\u2019t in mysql datadir?","text":"<p>In case the <code>ibdata</code> and <code>ib_log</code> files are located in different directories outside the datadir, you will have to put them in their proper place after the logs have been applied.</p>"},{"location":"faq.html#backup-fails-with-error-24-too-many-open-files","title":"Backup fails with Error 24: \u2018Too many open files\u2019","text":"<p>This usually happens when database being backed up contains large amount of files and Percona XtraBackup can\u2019t open all of them to create a successful backup. In order to avoid this error the operating system should be configured appropriately so that Percona XtraBackup can open all its files. On Linux, this can be done with the <code>ulimit</code> command for specific backup session or by editing the <code>/etc/security/limits.conf</code> to change it globally (NOTE: the maximum possible value that can be set up is <code>1048576</code> which is a hard-coded constant in the Linux kernel).</p>"},{"location":"faq.html#how-to-deal-with-skipping-of-redo-logs-for-ddl-operations","title":"How to deal with skipping of redo logs for DDL operations?","text":"<p>To prevent creating corrupted backups when running DDL operations, Percona XtraBackup aborts if it detects that redo logging is disabled. In this case, the following error is printed:</p> <pre><code>[FATAL] InnoDB: An optimized (without redo logging) DDL operation has been performed. All modified pages may not have been flushed to the disk yet.\nPercona XtraBackup will not be able to take a consistent backup. Retry the backup operation.\n</code></pre> <p>Note</p> <ul> <li> <p>Redo logging is disabled during a sorted index build. To avoid this error, Percona XtraBackup can use metadata locks on tables while they are copied:</p> </li> <li> <p>To block all DDL operations, use the <code>--lock-ddl</code> option that issues <code>LOCK TABLES FOR BACKUP</code>.</p> </li> </ul>"},{"location":"faq.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"features.html","title":"Percona XtraBackup features","text":"<p>The following is a short list of the Percona XtraBackup features:</p> <ul> <li> <p>Creates hot InnoDB backups without pausing your database</p> </li> <li> <p>Makes incremental backups of MySQL</p> </li> <li> <p>Streams compressed MySQL backups to another server</p> </li> <li> <p>Moves tables between MySQL servers on-line</p> </li> <li> <p>Creates new MySQL replication replicas easily</p> </li> <li> <p>Backs up MySQL without adding load to the server</p> </li> <li> <p>Performs throttling based on the number of IO operations per second</p> </li> <li> <p>Skips secondary index pages and recreates them when a compact backup is prepared</p> </li> <li> <p>Exports individual tables from a full InnoDB backup</p> </li> </ul> <p>Percona XtraBackup automatically uses backup locks, a lightweight alternative to <code>FLUSH TABLES WITH READ LOCK</code> available in Percona Server, to copy non-InnoDB data. This operation avoids blocking DML queries that modify InnoDB tables.</p> <p>See also</p> <p>How Percona XtraBackup works</p>"},{"location":"features.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"flush-tables-with-read-lock.html","title":"FLUSH TABLES WITH READ LOCK option","text":"<p>The <code>FLUSH TABLES WITH READ LOCK</code> option does the following with a global read lock:</p> <ul> <li> <p>Closes all open tables</p> </li> <li> <p>Locks all tables for all databases</p> </li> </ul> <p>Release the lock with <code>UNLOCK TABLES</code>.</p> <p>Note</p> <p><code>FLUSH TABLES WITH READ LOCK</code> does not prevent inserting rows into the log tables.</p> <p>To ensure consistent backups, use the <code>FLUSH TABLES WITH READ LOCK</code> option before taking a non-InnoDB file backup. The option does not affect long-running queries.</p> <p>Enabling <code>FLUSH TABLES WITH READ LOCK</code> when the server has long-running queries can leave the server in a read-only mode until the queries finish. If the server is in either the <code>Waiting for table flush</code> or the <code>Waiting for master to send event</code> state, stopping the <code>FLUSH TABLES WITH READ LOCK</code> operation does not help. Stop any long-running queries to return to normal operation.</p> <p>To prevent the server staying in a read-only mode until the queries finish, xtrabackup does the following:</p> <ul> <li> <p>checks if any queries run longer than specified in <code>--ftwrl-wait-threshold</code>. If xtrabackup finds such queries, xtrabackup waits for one second and checks again. If xtrabackup waits longer than specified in <code>--ftwrl-wait-timeout</code>, the backup is aborted. As soon as xtrabackup finds no queries running longer than specified in <code>--ftwrl-wait-threshold</code>, xtrabackup issues the global lock.</p> </li> <li> <p>kills all queries or only the SELECT queries which prevent the global lock from being acquired.</p> </li> </ul> <p>Note</p> <p>All operations described in this section have no effect when Backup locks are used.</p> <p>Percona XtraBackup uses Backup locks where available as a lightweight alternative to <code>FLUSH TABLES WITH READ LOCK</code>. This operation automatically copies non-InnoDB data and avoids blocking DML queries that modify InnoDB tables.</p>"},{"location":"flush-tables-with-read-lock.html#wait-for-queries-to-finish","title":"Wait for queries to finish","text":"<p>You should issue a global lock when no long queries are running. Waiting to issue the global lock for extended period of time is not a good method. The wait can extend the time needed for backup to take place. The <code>\u2013ftwrl-wait-timeout</code> option can limit the waiting time. If it cannot issue the lock during this time, xtrabackup stops the option, exits with an error message, and backup is not be taken.</p> <p>The option\u2019s default value is zero (0), which turns off the option.</p> <p>Another possibility is to specify the type of query to wait on. In this case <code>--ftwrl-wait-query-type</code>.</p> <p>The possible values are <code>all</code> and <code>update</code>. When <code>all</code> is used xtrabackup will wait for all long running queries (execution time longer than allowed by <code>--ftwrl-wait-threshold</code>) to finish before running the <code>FLUSH TABLES WITH READ LOCK</code>. When <code>update</code> is used xtrabackup will wait on <code>UPDATE/ALTER/REPLACE/INSERT</code> queries to finish.</p> <p>The time needed for a specific query to complete is hard to predict. We assume that the long-running queries will not finish in a timely manner. Other queries which run for a short time finish quickly. xtrabackup uses the value of <code>\u2013ftwrl-wait-threshold option to specify the long-running queries and will block a global lock. To use this option xtrabackup user should have</code>PROCESS<code>and</code>CONNECTION_ADMIN` privileges.</p>"},{"location":"flush-tables-with-read-lock.html#kill-the-blocking-queries","title":"Kill the blocking queries","text":"<p>The second option is to kill all the queries which prevent from acquiring the global lock. In this case, all queries which run longer than <code>FLUSH TABLES WITH READ LOCK</code> are potential blockers. Although all queries can be killed, additional time can be specified for the short running queries to finish using the <code>--kill-long-queries-timeout</code> option. This option specifies a query time limit. After the specified time is reached, the server kills the query. The default value is zero, which turns this feature off.</p> <p>The <code>--kill-long-query-type</code> option can be used to specify all or only <code>SELECT</code> queries that are preventing global lock from being acquired. To use this option xtrabackup user should have <code>PROCESS</code> and <code>CONNECTION_ADMIN</code> privileges.</p>"},{"location":"flush-tables-with-read-lock.html#options-summary","title":"Options summary","text":"<ul> <li> <p><code>--ftwrl-wait-timeout</code> (seconds) - how long to wait for a good moment. Default is 0, not to wait.</p> </li> <li> <p><code>--ftwrl-wait-query-type</code> - which long queries should be finished before <code>FLUSH TABLES WITH READ LOCK</code> is run. Default is all.</p> </li> <li> <p><code>--ftwrl-wait-threshold</code> (seconds) - how long query should be running before we consider it long running and potential blocker of global lock.</p> </li> <li> <p><code>--kill-long-queries-timeout</code> (seconds) - how many time we give for queries to complete after <code>FLUSH TABLES WITH READ LOCK</code> is issued before start to kill. Default if <code>0</code>, not to kill.</p> </li> <li> <p><code>--kill-long-query-type</code> - which queries should be killed once <code>kill-long-queries-timeout</code> has expired.</p> </li> </ul>"},{"location":"flush-tables-with-read-lock.html#example","title":"Example","text":"<p>Running the xtrabackup with the following options will cause xtrabackup to spend no longer than 3 minutes waiting for all queries older than 40 seconds to complete.</p> <pre><code>$  xtrabackup --backup --ftwrl-wait-threshold=40 \\\n--ftwrl-wait-query-type=all --ftwrl-wait-timeout=180 \\\n--kill-long-queries-timeout=20 --kill-long-query-type=all \\\n--target-dir=/data/backups/\n</code></pre> <p>After <code>FLUSH TABLES WITH READ LOCK</code> is issued, xtrabackup will wait for 20 seconds for lock to be acquired. If lock is still not acquired after 20 seconds, it will kill all queries which are running longer that the <code>FLUSH TABLES WITH READ LOCK</code>.</p>"},{"location":"flush-tables-with-read-lock.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"glossary.html","title":"Glossary","text":""},{"location":"glossary.html#csm","title":".CSM","text":"<p>Each table with the CSV Storage Engine has <code>.CSM</code> file which contains the metadata of it.</p>"},{"location":"glossary.html#csv","title":".CSV","text":"<p>Each table with the CSV Storage engine has <code>.CSV</code> file which contains the data of it (which is a standard Comma Separated Value file).</p>"},{"location":"glossary.html#exp","title":".exp","text":"<p>Files with the <code>.exp</code> extension are created by Percona XtraBackup per each InnoDB tablespace when the <code>--export</code> option is used on prepare. See restore individual tables.</p>"},{"location":"glossary.html#frm","title":".frm","text":"<p>For each table, the server will create a file with the <code>.frm</code> extension containing the table definition (for all storage engines).</p>"},{"location":"glossary.html#general-availability-ga","title":"General availability (GA)","text":"<p>A finalized version of the product which is made available to the general public. It is the final stage in the software release cycle.</p>"},{"location":"glossary.html#ibd","title":".ibd","text":"<p>On a multiple tablespace setup ([innodb_file_per_table] enabled), MySQL will store each newly created table on a file with a <code>.ibd</code> extension.</p>"},{"location":"glossary.html#mrg","title":".MRG","text":"<p>Each table using the MERGE storage engine, besides of a <code>.frm</code> file,  will have <code>.MRG</code> file containing the names of the MyISAM tables  associated with it.</p>"},{"location":"glossary.html#myd","title":".MYD","text":"<p>Each MyISAM table has <code>.MYD</code> (MYData) file which contains the data on it.</p>"},{"location":"glossary.html#myi","title":".MYI","text":"<p>Each MyISAM table has <code>.MYI</code> (MYIndex) file which contains the table\u2019s indexes.</p>"},{"location":"glossary.html#opt","title":".opt","text":"<p>MySQL stores options of a database (like charset) in a file with a <code>.opt</code> extension in the database directory.</p>"},{"location":"glossary.html#par","title":".par","text":"<p>Each partitioned table has <code>.par</code> file which contains metadata about the partitions.</p>"},{"location":"glossary.html#trg","title":".TRG","text":"<p>The file contains the triggers associated with a table, for example, <code>\\mytable.TRG</code>. With the <code>.TRN</code> file, they represent all the trigger definitions.</p>"},{"location":"glossary.html#trn","title":".TRN","text":"<p>The file contains the names of triggers that are associated with a table, for example, <code>\\mytable.TRN</code>. With the <code>.TRG</code> file, they represent all the trigger definitions.</p>"},{"location":"glossary.html#backup","title":"backup","text":"<p>The process of copying data or tables to be stored in a different location.</p>"},{"location":"glossary.html#compression","title":"compression","text":"<p>The method that produces backups in a reduced size.</p>"},{"location":"glossary.html#configuration-file","title":"configuration file","text":"<p>The file that contains the server startup options.</p>"},{"location":"glossary.html#crash","title":"crash","text":"<p>An unexpected shutdown which does not allow the normal server shutdown cleanup activities.</p>"},{"location":"glossary.html#crash-recovery","title":"crash recovery","text":"<p>The actions that occur when MySQL is restarted after a crash.</p>"},{"location":"glossary.html#data-dictionary","title":"data dictionary","text":"<p>The metadata for the tables, indexes, and table columns stored in the InnoDB system tablespace.</p>"},{"location":"glossary.html#datadir","title":"datadir","text":"<p>The directory in which the database server stores its data files. Most Linux distribution use <code>/var/lib/mysql</code> by default.</p>"},{"location":"glossary.html#full-backup","title":"full backup","text":"<p>A backup that contains the complete source data from an instance.</p>"},{"location":"glossary.html#ibdata","title":"ibdata","text":"<p>The default prefix for tablespace files. For example, <code>ibdata1</code> is a 10MB auto-extensible file that MySQL creates for a shared tablespace by default.</p>"},{"location":"glossary.html#incremental-backup","title":"incremental backup","text":"<p>A backup stores data from a specific point in time.</p>"},{"location":"glossary.html#innodb","title":"InnoDB","text":"<p>Storage engine which provides ACID-compliant transactions and foreign  key support, among others improvements over MyISAM. It is the default  engine for MySQL {{vers}}.</p>"},{"location":"glossary.html#innodb_buffer_pool_size","title":"innodb_buffer_pool_size","text":"<p>The size in bytes of the memory buffer to cache data and indexes of InnoDB\u2019s tables. This aims to reduce disk access to provide better performance. </p> <p>[mysqld] innodb_buffer_pool_size=8MB</p>"},{"location":"glossary.html#innodb_data_home_dir","title":"innodb_data_home_dir","text":"<p>The directory (relative to <code>datadir</code>) where the database server stores  the files in a shared tablespace setup. This option does not affect the location of <code>innodb\\_file\\_per\\_table</code>. For example:</p> <p>[mysqld] innodb_data_home_dir = ./</p>"},{"location":"glossary.html#innodb_data_file_path","title":"innodb_data_file_path","text":"<p>Specifies the names, sizes and location of shared tablespace files:</p> <p>[mysqld] innodb_data_file_path=ibdata1:50M;ibdata2:50M:autoextend</p>"},{"location":"glossary.html#innodb_file_per_table","title":"innodb_file_per_table","text":"<p>By default, InnoDB creates tables and indexes in a file-per-tablespace. If the <code>innodb_file_per_table</code> variable is disabled, you can enable the variable in your configuration file:</p> <p>[mysqld] innodb_file_per_table  or  start the server with <code>--innodb_file_per_table</code>.</p>"},{"location":"glossary.html#innodb_log_group_home_dir","title":"innodb_log_group_home_dir","text":"<p>Specifies the location of the InnoDB log files:</p> <p>[mysqld] innodb_log_group_home=/var/lib/mysql</p>"},{"location":"glossary.html#logical-backup","title":"logical backup","text":"<p>A backup which contains a set of SQL statements. The statements can be used to recreate the databases.</p>"},{"location":"glossary.html#lsn","title":"LSN","text":"<p>Each InnoDB page contains a log sequence number(LSN). The LSN is the system version number for the database. Each page\u2019s LSN shows how recently it was changed.</p>"},{"location":"glossary.html#mycnf","title":"my.cnf","text":"<p>The database server\u2019s main configuration file. Most Linux distributions place it as <code>/etc/mysql/my.cnf</code> or <code>/etc/my.cnf</code>, but the location and name depends on the particular installation. Note that this method is not the only way of configuring the server, some systems rely on the command options.</p>"},{"location":"glossary.html#myisam","title":"MyISAM","text":"<p>The MySQL default storage engine until version 5.5. It doesn\u2019t fully  support transactions but in some scenarios may be faster than InnoDB.  Each table is stored on disk in 3 files: <code>.frm</code>, <code>.MYD</code>, <code>.MYI</code>.</p>"},{"location":"glossary.html#physical-backup","title":"physical backup","text":"<p>A backup that copies the data files.</p>"},{"location":"glossary.html#point-in-time-recovery","title":"point in time recovery","text":"<p>This method restores the data into the state it was at any selected point of time.</p>"},{"location":"glossary.html#prepared-backup","title":"prepared backup","text":"<p>A consistent set of backup data that is ready to be restored.</p>"},{"location":"glossary.html#restore","title":"restore","text":"<p>Copies the database backups taken using the backup command to the original location or a different location. A restore returns data that has been either lost, corrupted, or stolen to the original condition at a specific point in time.</p>"},{"location":"glossary.html#tech-preview","title":"Tech preview","text":"<p>A tech preview item can be a feature, a variable, or a value within a variable. Before using this feature in production, we recommend that you test restoring production from physical backups in your environment and also use an alternative backup method for redundancy. A tech preview item is included in a release for users to provide feedback. The item is either updated and released as general availability(GA) or removed if not useful. The functionality can change from tech preview to GA.</p>"},{"location":"glossary.html#xbcrypt","title":"xbcrypt","text":"<p>To support the encryption and the decryption of the backups. This utility has been modeled after the xbstream binary to perform encryption and decryption outside Percona XtraBackup.</p>"},{"location":"glossary.html#xbstream","title":"xbstream","text":"<p>To support simultaneous compression and streaming, Percona XtraBackup uses the xbstream format. For more information see xbstream</p>"},{"location":"glossary.html#xtradb","title":"XtraDB","text":"<p>Percona XtraDB is an enhanced version of the InnoDB storage engine, designed to better scale on modern hardware. Percona XtraDB includes features which are useful in a high performance environment. It is fully backward-compatible, and is a drop-in replacement for the standard InnoDB storage engine. For more information, see The Percona XtraDB Storage Engine.</p>"},{"location":"glossary.html#zstandard-zstd","title":"Zstandard (ZSTD)","text":"<p><code>ZSTD</code> is a fast lossless compression algorithm that targets real-time compression scenarios and better compression ratios.</p>"},{"location":"glossary.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"how-xtrabackup-works.html","title":"How Percona XtraBackup works","text":"<p>Percona XtraBackup is based on InnoDB\u2019s crash-recovery functionality. It copies your InnoDB data files, which results in data that is internally inconsistent; but then it performs crash recovery on the files to make them a consistent, usable database again.</p> <p>This works because InnoDB maintains a redo log, also called the transaction log. This contains a record of every change to InnoDB data. When InnoDB starts, it inspects the data files and the transaction log, and performs two steps. It applies committed transaction log entries to the data files, and it performs an undo operation on any transactions that modified data but did not commit.</p> <p>The <code>--register-redo-log-consumer</code> parameter is disabled by default. When enabled, this parameter lets Percona XtraBackup register as a redo log consumer at the start of the backup. The server does not remove a redo log that Percona XtraBackup (the consumer) has not yet copied. The consumer reads the redo log and manually advances the log sequence number (LSN). The server blocks the writes during the process. Based on the redo log consumption, the server determines when it can purge the log.  </p> <p>Percona XtraBackup remembers the LSN when it starts, and then copies the data files. The operation takes time, and the files may change, then LSN reflects the state of the database at different points in time. Percona XtraBackup also runs a background process that watches the transaction log files, and copies any changes. Percona XtraBackup does this continually. The transaction logs are written in a round-robin fashion, and can be reused.</p> <p>Percona XtraBackup uses Backup locks</p> <p>where available as a lightweight alternative to <code>FLUSH TABLES WITH READ LOCK</code>. MySQL {{vers}} allows acquiring an instance level backup lock via the <code>LOCK INSTANCE FOR BACKUP</code> statement.</p> <p>Locking is only done for MyISAM and other non-InnoDB tables after Percona XtraBackup finishes backing up all InnoDB/XtraDB data and logs. Percona XtraBackup uses this automatically to copy non-InnoDB data to avoid blocking DML queries that modify InnoDB tables.</p> <p>Important</p> <p>The <code>BACKUP_ADMIN</code> privilege is required to query the  <code>performance_schema_log_status</code> for either <code>LOCK  INSTANCE FOR BACKUP</code> or <code>LOCK TABLES FOR BACKUP</code>.</p> <p>xtrabackup tries to avoid backup locks and <code>FLUSH TABLES WITH READ LOCK</code> when the instance contains only InnoDB tables. In this case, xtrabackup obtains binary log coordinates from <code>performance_schema.log_status</code>. <code>FLUSH TABLES WITH READ LOCK</code> is still required in MySQL {{vers}} when xtrabackup is started with the <code>--slave-info</code>. The <code>log_status</code> table in Percona Server for MySQL {{vers}} is extended to include the relay log coordinates, so no locks are needed even with the <code>--slave-info</code> option.</p> <p>See also</p> <p>MySQL Documentation: LOCK INSTANCE FOR BACKUP</p> <p>When backup locks are supported by the server, xtrabackup first copies InnoDB data, runs the <code>LOCK TABLES FOR BACKUP</code> and then copies the MyISAM tables. Once this is done, the backup of the files will begin. It will backup .frm, .MRG, .MYD, .MYI, .CSM, .CSV, <code>.sdi</code> and <code>.par</code> files.</p> <p>After that xtrabackup will use <code>LOCK BINLOG FOR BACKUP</code> to block all operations that might change either binary log position or <code>Exec_Master_Log_Pos</code> or <code>Exec_Gtid_Set</code> (i.e. source binary log coordinates corresponding to the current SQL thread state on a replication replica) as reported by <code>SHOW MASTER/SLAVE STATUS</code>. xtrabackup will then finish copying the REDO log files and fetch the binary log coordinates. After this is completed xtrabackup will unlock the binary log and tables.</p> <p>Finally, the binary log position will be printed to <code>STDERR</code> and xtrabackup will exit returning 0 if all went OK.</p> <p>Note that the <code>STDERR</code> of xtrabackup is not written in any file. You will have to redirect it to a file, for example, <code>xtrabackup OPTIONS 2&gt; backupout.log</code>.</p> <p>It will also create the following files in the directory of the backup.</p> <p>During the <code>prepare</code> phase, Percona XtraBackup performs crash recovery against the copied data files, using the copied transaction log file. After this is done, the database is ready to restore and use.</p> <p>The backed-up MyISAM and InnoDB tables will be eventually consistent with each other, because after the prepare (recovery) process, InnoDB\u2019s data is rolled forward to the point at which the backup completed, not rolled back to the point at which it started. This point in time matches where the <code>FLUSH TABLES WITH READ LOCK</code> was taken, so the MyISAM data and the prepared InnoDB data are in sync.</p> <p>The xtrabackup offers many features not mentioned in the preceding explanation. The functionality of each tool is explained in more detail further in this manual. In brief, though, the tools enable you to do operations such as streaming and incremental backups with various combinations of copying the data files, copying the log files, and applying the logs to the data.</p>"},{"location":"how-xtrabackup-works.html#restoring-a-backup","title":"Restoring a backup","text":"<p>To restore a backup with xtrabackup you can use the <code>--copy-back</code> or <code>--move-back</code> options.</p> <p>xtrabackup will read from the <code>my.cnf</code> the variables datadir, innodb_data_home_dir, innodb_data_file_path, innodb_log_group_home_dir and check that the directories exist.</p> <p>It will copy the MyISAM tables, indexes, etc. (.MRG, .MYD, .MYI, .CSM, .CSV, <code>.sdi</code>, and <code>par</code> files) first, InnoDB tables and indexes next and the log files at last. It will preserve file\u2019s attributes when copying them, you may have to change the files\u2019 ownership to <code>mysql</code> before starting the database server, as they will be owned by the user who created the backup.</p> <p>Alternatively, the <code>--move-back</code> option may be used to restore a backup. This option is similar to <code>--copy-back</code> with the only difference that instead of copying files it moves them to their target locations. As this option removes backup files, it must be used with caution. It is useful in cases when there is not enough free disk space to hold both data files and their backup copies.</p>"},{"location":"how-xtrabackup-works.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"installation.html","title":"Install overview","text":"<p>We recommend that you install Percona XtraBackup {{vers}} from the official Percona software repositories using the appropriate package manager for your system:</p> <ul> <li> <p>Use an APT repo to install Percona XtraBackup</p> </li> <li> <p>Use a YUM repo to install Percona XtraBackup</p> </li> </ul>"},{"location":"installation.html#installation-alternatives","title":"Installation alternatives","text":"<p>Percona also provides the following methods:</p> <ul> <li> <p>Use DEB downloaded packages to install Percona XtraBackup</p> </li> <li> <p>Use RPM downloaded packages to install Percona XtraBackup </p> </li> <li> <p>Install Percona XtraBackup from a Binary Tarball with all the required files and binaries for a manual installation</p> </li> <li> <p>Compile and install Percona XtraBackup from source code</p> </li> <li> <p>Run Percona XtraBackup in a Docker container</p> </li> </ul> <p>Before installing Percona XtraBackup with any of these methods, we recommend that you review the release notes and Server version and backup version comparison.</p>"},{"location":"installation.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"limitations.html","title":"Limitations","text":"<p>Percona XtraBackup {{vers}} does not support making backups of databases created in versions prior to {{vers}} of MySQL, Percona Server for MySQL or Percona XtraDB Cluster.</p>"},{"location":"limitations.html#additional-information","title":"Additional information","text":"<p>The InnoDB tables are locked while copying non-InnoDB data.</p>"},{"location":"limitations.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"lock-options.html","title":"lock-ddl-per-table option improvements","text":"<p>To block DDL statements on an instance, Percona Server implemented LOCK TABLES FOR BACKUP. Percona XtraBackup uses this lock for the duration of the backup. This lock does not affect DML statements.</p> <p>Percona XtraBackup has also implemented <code>--lock-ddl-per-table</code>, which blocks DDL statements by using metadata locks (MDL).</p> <p>The following procedures describe a simplified backup operation when using <code>--lock-ddl-per-table</code>:</p> <ol> <li> <p>Parse and copy all redo logs after the checkpoint mark</p> </li> <li> <p>Fork a dedicated thread to continue following new redo log entries</p> </li> <li> <p>List the tablespaces required to copy</p> </li> <li> <p>Iterate through the list. The following steps occur with each listed tablespace:</p> </li> <li> <p>Query INFORMATION_SCHEMA.INNODB_TABLES to find which tables belong    to the tablespace ID and take an MDL on the underlying table or tables in    case there is a shared tablespace.</p> </li> <li> <p>Copy the tablespace <code>.ibd</code> files.</p> </li> </ol> <p>The backup process may encounter a redo log event, generated by the bulk load operations, which notifies backup tools that data file changes have been omitted from the redo log. This event is an <code>MLOG_INDEX_LOAD</code>. If this event is found by the redo follow thread, the backup continues and assumes the backup is safe because the MDL protects tablespaces already copied and the MLOG_INDEX_LOAD event is for a tablespace that is not copied.</p> <p>These assumptions may not be correct and may lead to inconsistent backups.</p>"},{"location":"lock-options.html#-lock-ddl-per-table-redesign","title":"<code>--lock-ddl-per-table</code> redesign","text":"<p>The <code>--lock-ddl-per-table</code> option has been redesigned to minimize inconsistent backups.</p> <p>The following procedure reorders the steps:</p> <ul> <li> <p>The MDL lock acquired at the beginning of the backup</p> </li> <li> <p>Scan the redo logs. An <code>MLOG_INDEX_LOAD</code> event may be recorded if a <code>CREATE INDEX</code> statement has occurred before the backup starts. At this time, the backup process is safe and can parse and accept the event.</p> </li> <li> <p>After the first scan has completed, the follow redo log thread is initiated. This thread stops the backup process if an <code>MLOG_INDEX_LOAD</code> event is found.</p> </li> <li> <p>Gather the tablespace list to copy</p> </li> <li> <p>Copy the <code>.ibd</code> files.</p> </li> </ul>"},{"location":"lock-options.html#other-improvements","title":"Other improvements","text":"<p>The following improvements have been added:</p> <ul> <li> <p>If the <code>.ibd</code> file belongs to a temporary table, the <code>SELECT</code> query is skipped.</p> </li> <li> <p>For a FullText Index, an MDL is acquired on the base table.</p> </li> <li> <p>A <code>SELECT</code> query that acquires an MDL does not retrieve any data.</p> </li> </ul>"},{"location":"lock-options.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"log-enhancements.html","title":"Improved log statements","text":"<p>Percona XtraBackup is an open-source command-line utility. Command-line tools have limited interaction with the background operations and the logs provide the progress of an operation or more information about errors.</p> <p>The error logs did not have a standard structure and the log statements varied in the following ways:</p> <ul> <li>The backup log statement header has the name of the module, <code>xtrabackup</code>, which generated the statement but no timestamp:</li> </ul> <p><pre><code> $ xtrabackup: recognized client arguments: --parallel=4 --target-dir=/data/backups/ --backup=1\n</code></pre> The output should be similar to the following:</p> Expected output <pre><code>./bin/xtrabackup version {{release}} based on MySQL server {{vers}} Linux (x86_64) (revision id: b0f75188ca3)\n</code></pre> <ul> <li>The copy-back log statement has a timestamp but no module name. The   timestamp is a mix of UTC and the local timezone.</li> </ul> <pre><code>220322 19:05:13 [01] Copying undo_001 to /data/backups/undo_001\n</code></pre> <ul> <li>The following prepare log statements do not have header information,   which makes diagnosing an issue more difficult.</li> </ul> <pre><code>Completed space ID check of 1008 files.\nInitializing buffer pool, total size = 128.000000M, instances = 1, chunk size =128.000000M\nCompleted initialization of buffer pool\nIf the mysqld execution user is authorized, page cleaner thread priority can be changed. See the man page of setpriority().\n</code></pre>"},{"location":"log-enhancements.html#log-statement-structure","title":"Log statement structure","text":"<p>The improved log structure is displayed in the backup, prepare, move-back/copy-back error logs.</p> <p>Each log statement has the following attributes:</p> <ul> <li> <p>Timestamp - a timestamp for when the event occurred in a UTC format.</p> </li> <li> <p>Severity - the severity level of a statement indicates the importance of an event.</p> </li> <li> <p>ID - this identifier is currently not used but may be used in future versions.</p> </li> <li> <p>Context - the name of the module that issued the log statement, such as XtraBackup, InnoDB, or Server.</p> </li> <li> <p>Message - a description of the event generated by the module.</p> </li> </ul> <p>An example of a <code>prepare</code> log that is generated with the improved structure. The uniformity of the headers makes it easier to follow an operation\u2019s progress or review the log to diagnose issues.</p> Expected output <pre><code>2022-03-22T19:15:36.142247+05:30 0 [Note] [MY-011825] [Xtrabackup] This target seems to be not prepared yet.\n2022-03-22T19:15:36.142792+05:30 0 [Note] [MY-013251] [InnoDB] Number of pools: 1\n2022-03-22T19:15:36.149212+05:30 0 [Note] [MY-011825] [Xtrabackup] xtrabackup_logfile detected: size=8388608, start_lsn=(33311656)\n2022-03-22T19:15:36.149998+05:30 0 [Note] [MY-011825] [Xtrabackup] using the following InnoDB configuration for recovery:\n2022-03-22T19:15:36.150023+05:30 0 [Note] [MY-011825] [Xtrabackup] innodb_data_home_dir = .\n2022-03-22T19:15:36.150036+05:30 0 [Note] [MY-011825] [Xtrabackup] innodb_data_file_path = ibdata1:12M:autoextend\n2022-03-22T19:15:36.150078+05:30 0 [Note] [MY-011825] [Xtrabackup] innodb_log_group_home_dir = .\n2022-03-22T19:15:36.150095+05:30 0 [Note] [MY-011825] [Xtrabackup] innodb_log_files_in_group = 1\n2022-03-22T19:15:36.150111+05:30 0 [Note] [MY-011825] [Xtrabackup] innodb_log_file_size = 8388608\n2022-03-22T19:15:36.151667+05:30 0 [Note] [MY-011825] [Xtrabackup] inititialize_service_handles suceeded\n2022-03-22T19:15:36.151903+05:30 0 [Note] [MY-011825] [Xtrabackup] using the following InnoDB configuration for recovery:\n2022-03-22T19:15:36.151926+05:30 0 [Note] [MY-011825] [Xtrabackup] innodb_data_home_dir = .\n2022-03-22T19:15:36.151954+05:30 0 [Note] [MY-011825] [Xtrabackup] innodb_data_file_path = ibdata1:12M:autoextend\n2022-03-22T19:15:36.151976+05:30 0 [Note] [MY-011825] [Xtrabackup] innodb_log_group_home_dir = .\n2022-03-22T19:15:36.151991+05:30 0 [Note] [MY-011825] [Xtrabackup] innodb_log_files_in_group = 1\n2022-03-22T19:15:36.152004+05:30 0 [Note] [MY-011825] [Xtrabackup] innodb_log_file_size = 8388608\n2022-03-22T19:15:36.152021+05:30 0 [Note] [MY-011825] [Xtrabackup] Starting InnoDB instance for recovery.\n2022-03-22T19:15:36.152035+05:30 0 [Note] [MY-011825] [Xtrabackup] Using 104857600 bytes for buffer pool (set by --use-memory parameter)\n</code></pre>"},{"location":"log-enhancements.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"lru-dump-backup.html","title":"LRU dump backup","text":"<p>Percona XtraBackup includes a saved buffer pool dump into a backup to enable reducing the warm up time. It restores the buffer pool state from <code>ib_buffer_pool</code> file after restart. Percona XtraBackup discovers <code>ib_buffer_pool</code> and backs it up automatically.</p> <p></p> <p>If the buffer restore option is enabled in <code>my.cnf</code>, buffer pool will be in the warm state after backup is restored.</p> <p>Find the information on how to save and restore the buffer pool dump in Saving and Restoring the Buffer Pool State.</p>"},{"location":"lru-dump-backup.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"make-backup-in-replication-env.html","title":"Make backups in replication environments","text":"<p>There are options specific to back up from a replication replica.</p>"},{"location":"make-backup-in-replication-env.html#the-slave-info-option","title":"The <code>--slave-info</code> option","text":"<p>This option is useful when backing up a replication replica server. It prints the binary log position and name of the source server. It also writes this information to the <code>xtrabackup_slave_info</code> file as a <code>CHANGE MASTER</code> statement.</p> <p>This option is useful for setting up a new replica for this source. You can start a replica server with this backup and issue the statement saved in the <code>xtrabackup_slave_info</code> file. More details of this procedure can be found in How to setup a replica for replication in 6 simple steps with Percona XtraBackup.</p>"},{"location":"make-backup-in-replication-env.html#the-safe-slave-backup-option","title":"The <code>--safe-slave-backup</code> option","text":"<p>In order to assure a consistent replication state, this option stops the replication SQL thread and waits to start backing up until <code>Slave_open_temp_tables</code> in <code>SHOW STATUS</code> is zero. If there are no open temporary tables, the backup will take place, otherwise the SQL thread will be started and stopped until there are no open temporary tables. The backup will fail if <code>Slave_open_temp_tables</code> does not become zero after <code>--safe-slave-backup-timeout</code> seconds (defaults to 300 seconds). The replication SQL thread will be restarted when the backup finishes.</p> <p>Note</p> <p>Using a safe-slave-backup option stops the SQL replica thread before copying the InnoDB files.</p> <p>Using this option is always recommended when taking backups from a replica server.</p> <p>Warning</p> <p>Make sure your replica is a true replica of the source before using it as a source for backup. A good tool to validate a replica is pt-table-checksum.</p>"},{"location":"make-backup-in-replication-env.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"page-tracking.html","title":"Take an incremental backup using page tracking","text":"<p>To create an incremental backup with page tracking, Percona XtraBackup uses the MySQL <code>mysqlbackup</code> component. This component provides a list of pages modified since the last backup, and Percona XtraBackup copies only those pages. This operation removes the need to scan the pages in the database. If the majority of pages have not been modified, the page tracking feature can improve the speed of incremental backups.</p>"},{"location":"page-tracking.html#install-the-component","title":"Install the component","text":"<p>To start using the page tracking functionality, do the following:</p> <ol> <li> <p>Install the <code>mysqlbackup</code> component and enable it on the server:</p> <pre><code>$ INSTALL COMPONENT \"file://component_mysqlbackup\";\n</code></pre> </li> <li> <p>Check whether the <code>mysqlbackup</code> component is installed successfully:</p> <pre><code>$ SELECT COUNT(1) FROM mysql.component WHERE component_urn='file://component_mysqlbackup';\n</code></pre> </li> </ol>"},{"location":"page-tracking.html#use-page-tracking","title":"Use page tracking","text":"<p>You can enable the page tracking functionality for the full and incremental backups with the <code>--page-tracking</code> option.</p> <p>The option has the following benefits:</p> <ul> <li> <p>Resets page tracking to the start of the backup. This reset allows the next incremental backup to use page tracking.</p> </li> <li> <p>Allows the use of page tracking for an incremental backup if the page tracking data is available from the backup\u2019s start checkpoint LSN.</p> </li> </ul> <p>Percona XtraBackup processes a list of all the tracked pages in memory. If Percona XtraBackup does not have enough available memory to process this list, the process throws an error and exits. For example, if an incremental backup uses 200GB, Percona XtraBackup can use an additional 100MB of memory to process and store the page tracking data. </p> <p>The examples of creating full and incremental backups using the <code>--page-tracking</code> option:</p> Full backupIncremental backup <pre><code>$ xtrabackup --backup --target-dir=$FULL_BACK --page-tracking\n</code></pre> <pre><code>$ xtrabackup --backup --target-dir=$INC_BACKUP  \n--incremental-basedir=$FULL_BACKUP --page-tracking\n</code></pre> <p>After enabling the functionality, the next incremental backup finds changed pages using page tracking.</p> <p>The first full backup using page tracking, Percona XtraBackup may have a delay. The following is an example of the message:</p> Expected output <pre><code>xtrabackup: pagetracking: Sleeping for 1 second, waiting for checkpoint lsn 17852922 /\nto reach to page tracking start lsn 21353759\n</code></pre> <p>Enable page tracking before creating the first backup to avoid this delay. This method ensures that the page tracking log sequence number (LSN) is higher than the checkpoint LSN of the server.</p>"},{"location":"page-tracking.html#start-page-tracking-manually","title":"Start page tracking manually","text":"<p>After the mysqlbackup component is loaded and active on the server, you can start page tracking manually with the following option:</p> <pre><code>$ SELECT mysqlbackup_page_track_set(true);\n</code></pre>"},{"location":"page-tracking.html#check-the-lsn-value","title":"Check the LSN value","text":"<p>Check the LSN value starting from which changed pages are tracked with the following option:</p> <pre><code>$ SELECT mysqlbackup_page_track_get_start_lsn();\n</code></pre>"},{"location":"page-tracking.html#stop-page-tracking","title":"Stop page tracking","text":"<p>To stop page tracking, use the following command:</p> <pre><code>$ SELECT mysqlbackup_page_track_set(false);\n</code></pre>"},{"location":"page-tracking.html#purge-page-tracking-data","title":"Purge page tracking data","text":"<p>When you start page tracking, it creates a file under the server\u2019s datadir to collect data about changed pages. This file grows until you stop the page tracking. If you stop the server and then restart it, page tracking creates a new file but also keeps the old one. The old file continues to grow until you stop the page tracking explicitly.</p> <p>If you purge the page tracking data, you should create a full backup afterward. To purge the page tracking data, do the following steps:</p> <pre><code>$ SELECT mysqlbackup_page_track_set(false);\n$ SELECT mysqlbackup_page_track_purge_up_to(9223372036854775807);\n/* Specify the LSN up to which you want to purge page tracking data. /\n9223372036854775807 is the highest possible LSN which purges all page tracking files.*/\n$ SELECT mysqlbackup_page_track_set(true);\n</code></pre>"},{"location":"page-tracking.html#known-issue","title":"Known issue","text":"<p>If the index is built in place using an exclusive algorithm and then is added to a table after the last LSN checkpoint, you may generate a bad incremental backup using page tracking. For more details see PS-8032.</p>"},{"location":"page-tracking.html#uninstall-the-mysqlbackup-component","title":"Uninstall the mysqlbackup component","text":"<p>To uninstall the mysqlbackup component, use the following statement:</p> <pre><code>$ UNINSTALL COMPONENT \"file://component_mysqlbackup\"\n</code></pre>"},{"location":"page-tracking.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"permissions.html","title":"Permissions needed","text":"<p>We will be referring to permissions to the ability of a user to access and perform changes on the relevant parts of the host\u2019s filesystem, starting/stopping services and installing software.</p> <p>By privileges, we refer to the abilities of a database user to perform different kinds of actions on the database server.</p> <p>There are many ways for checking the permission on a file or directory. For example, <code>ls -ls /path/to/file</code> or <code>stat /path/to/file | grep Access</code> will do the job:</p> <p><pre><code>$ stat /etc/mysql | grep Access\n</code></pre> The result could look like this:</p> Expected output <pre><code>Access: (0755/drwxr-xr-x)  Uid: (    0/    root)   Gid: (    0/    root)\nAccess: 2011-05-12 21:19:07.129850437 -0300\n$ ls -ld /etc/mysql/my.cnf\n-rw-r--r-- 1 root root 4703 Apr  5 06:26 /etc/mysql/my.cnf\n</code></pre> <p>As in this example, <code>my.cnf</code> is owned by <code>root</code> and not writable for anyone else. Assuming that you do not have <code>root</code>\u2018s password, you can check what permissions you have on these types of files with <code>sudo -l</code>:</p> <p><pre><code>$ sudo -l\n</code></pre> The results could look like this:</p> Expected output <pre><code>Password:\nYou may run the following commands on this host:\n(root) /usr/bin/\n(root) NOPASSWD: /etc/init.d/mysqld\n(root) NOPASSWD: /bin/vi /etc/mysql/my.cnf\n(root) NOPASSWD: /usr/local/bin/top\n(root) NOPASSWD: /usr/bin/ls\n(root) /bin/tail\n</code></pre> <p>Being able to execute with <code>sudo</code> scripts in <code>/etc/init.d/</code>, <code>/etc/rc.d/</code> or <code>/sbin/service</code> is the ability to start and stop services.</p> <p>Also, If you can execute the package manager of your distribution, you can install or remove software with it. If not, having <code>rwx</code> permission over a directory will let you do a local installation of software by compiling it there. This is a typical situation in many hosting companies\u2019 services.</p> <p>There are other ways for managing permissions, such as using PolicyKit,  Extended ACLs or SELinux, which may be preventing or allowing your access. You should check them in that case.</p> <p>See also</p> <p>Connection and privileges needed</p>"},{"location":"permissions.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"point-in-time-recovery.html","title":"Point-in-time recovery","text":"<p>Recovering up to particular moment in database\u2019s history can be done with xtrabackup and the binary logs of the server.</p> <p>Note that the binary log contains the operations that modified the database from a point in the past. You need a full datadir as a base, and then you can apply a series of operations from the binary log to make the data match what it was at the point in time you want.</p> <pre><code>$ xtrabackup --backup --target-dir=/path/to/backup\n$ xtrabackup --prepare --target-dir=/path/to/backup\n</code></pre> <p>For more details on these procedures, see Creating a backup and Preparing a backup.</p> <p>Now, suppose that some time has passed, and you want to restore the database to a certain point in the past, having in mind that there is the constraint of the point where the snapshot was taken.</p> <p>To find out what is the situation of binary logging in the server, execute the following queries:</p> <pre><code>mysql&gt; SHOW BINARY LOGS;\n</code></pre> Expected output <pre><code>+------------------+-----------+\n| Log_name         | File_size |\n+------------------+-----------+\n| mysql-bin.000001 |       126 |\n| mysql-bin.000002 |      1306 |\n| mysql-bin.000003 |       126 |\n| mysql-bin.000004 |       497 |\n+------------------+-----------+\n</code></pre> <p>and</p> <pre><code>mysql&gt; SHOW MASTER STATUS;\n</code></pre> Expected output <pre><code>+------------------+----------+--------------+------------------+\n| File             | Position | Binlog_Do_DB | Binlog_Ignore_DB |\n+------------------+----------+--------------+------------------+\n| mysql-bin.000004 |      497 |              |                  |\n+------------------+----------+--------------+------------------+\n</code></pre> <p>The first query will tell you which files contain the binary log and the second one which file is currently being used to record changes, and the current position within it. Those files are stored usually in the datadir (unless other location is specified when the server is started with the <code>--log-bin=</code> option).</p> <p>To find out the position of the snapshot taken, see the <code>xtrabackup_binlog_info</code> at the backup\u2019s directory:</p> <pre><code>$ cat /path/to/backup/xtrabackup_binlog_info\n</code></pre> Expected output <pre><code>mysql-bin.000003      57\n</code></pre> <p>This will tell you which file was used at moment of the backup for the binary log and its position. That position will be the effective one when you restore the backup:</p> <pre><code>$ xtrabackup --copy-back --target-dir=/path/to/backup\n</code></pre> <p>As the restoration will not affect the binary log files (you may need to adjust file permissions, see Restoring a Backup), the next step is extracting the queries from the binary log with mysqlbinlog starting from the position of the snapshot and redirecting it to a file</p> <pre><code>$ mysqlbinlog /path/to/datadir/mysql-bin.000003 /path/to/datadir/mysql-bin.000004 \\\n    --start-position=57 &gt; mybinlog.sql\n</code></pre> <p>Note that if you have multiple files for the binary log, as in the example, you have to extract the queries with one process, as shown above.</p> <p>Inspect the file with the queries to determine which position or date corresponds to the point-in-time wanted. Once determined, pipe it to the server. Assuming the point is <code>11-12-25 01:00:00</code>:</p> <pre><code>$ mysqlbinlog /path/to/datadir/mysql-bin.000003 /path/to/datadir/mysql-bin.000004 \\\n    --start-position=57 --stop-datetime=\"11-12-25 01:00:00\" | mysql -u root -p\n</code></pre> <p>and the database will be rolled forward up to that Point-In-Time.</p>"},{"location":"point-in-time-recovery.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"prepare-compressed-backup.html","title":"Prepare the backup","text":"<p>Before you can prepare the backup you\u2019ll need to uncompress all the files. Percona XtraBackup has implemented <code>--decompress</code> option that can be used to decompress the backup.</p> <pre><code>$ xtrabackup --decompress --target-dir=/data/compressed/\n</code></pre> <p>Note</p> <p><code>--parallel</code> can be used with <code>--decompress</code> option to decompress multiple files simultaneously. </p> <p>Percona XtraBackup does not automatically remove the compressed files. In order to clean up the backup directory you should use <code>--remove-original</code> option. Even if they\u2019re not removed these files will not be copied/moved over to the datadir if <code>--copy-back</code> or <code>--move-back</code> are used.</p> <p>When the files are uncompressed you can prepare the backup with the <code>--prepare</code> option:</p> <pre><code>$ xtrabackup --prepare --target-dir=/data/compressed/\n</code></pre> Confirmation message <pre><code>InnoDB: Starting shutdown...\nInnoDB: Shutdown completed; log sequence number 9293846\n170223 13:39:31 completed OK!\n</code></pre> <p>Now the files in <code>/data/compressed/</code> are ready to be used by the server.</p>"},{"location":"prepare-compressed-backup.html#next-step","title":"Next step","text":"<p>Restore the backup </p>"},{"location":"prepare-compressed-backup.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"prepare-full-backup.html","title":"Prepare a full backup","text":"<p>After creating a backup with the <code>--backup</code> option, you need to prepare the backup and then restore it. Data files are not point-in-time consistent until they are prepared, because they were copied at different times as the program ran, and they might have been changed while this was happening.</p> <p>If you try to start InnoDB with these data files, it will detect corruption and stop working to avoid running on damaged data. The <code>--prepare</code> step makes the files perfectly consistent at a single instant in time, so you can run InnoDB on them.</p> <p>You can run the prepare operation on any machine; it does not need to be on the originating server or the server to which you intend to restore. You can copy the backup to a utility server and prepare it there.</p> <p>Note that Percona XtraBackup {{vers}} can only prepare backups of MySQL {{vers}} and Percona Server for MySQL {{vers}} databases. Releases prior to {{vers}} are not supported.</p> <p>During the prepare operation, xtrabackup boots up a kind of modified embedded InnoDB (the libraries xtrabackup was linked against). The modifications are necessary to disable InnoDB standard safety checks, such as complaining about the log file not being the right size. This warning is not appropriate for working with backups. These modifications are only for the xtrabackup binary; you do not need a modified InnoDB to use xtrabackup for your backups.</p> <p>The prepare step uses this \u201cembedded InnoDB\u201d to perform crash recovery on the copied data files, using the copied log file. The <code>prepare</code> step is very simple to use: you simply run xtrabackup with the <code>--prepare</code> option and tell it which directory to prepare, for example, to prepare the previously taken backup run:</p> <pre><code>$ xtrabackup --prepare --target-dir=/data/backups/\n</code></pre> <p>When this finishes, you should see an <code>InnoDB shutdown</code> with a message such as the following, where again the value of LSN will depend on your system:</p> Expected output <pre><code>InnoDB: Shutdown completed; log sequence number 137345046\n160906 11:21:01 completed OK!\n</code></pre> <p>All following prepares will not change the already prepared data files, you\u2019ll see that output says:</p> Expected output <pre><code>xtrabackup: This target seems to be already prepared.\nxtrabackup: notice: xtrabackup_logfile was already used to '--prepare'.\n</code></pre> <p>It is not recommended to interrupt xtrabackup process while preparing backup because it may cause data files corruption and backup will become unusable. Backup validity is not guaranteed if prepare process was interrupted.</p> <p>Note</p> <p>If you intend the backup to be the basis for further incremental backups, you should use the <code>--apply-log-only</code> option when preparing the backup, or you will not be able to apply incremental backups to it. See the documentation on preparing incremental backups for more details.</p>"},{"location":"prepare-full-backup.html#next-step","title":"Next step","text":"<p>Restore the backup </p>"},{"location":"prepare-full-backup.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"prepare-incremental-backup.html","title":"Prepare an incremental backup","text":"<p>The <code>--prepare</code> step for incremental backups is not the same as for full backups. In full backups, two types of operations are performed to make the database consistent: committed transactions are replayed from the log file against the data files, and uncommitted transactions are rolled back. You must skip the rollback of uncommitted transactions when preparing an incremental backup, because transactions that were uncommitted at the time of your backup may be in progress, and it\u2019s likely that they will be committed in the next incremental backup. You should use the <code>--apply-log-only</code> option to prevent the rollback phase.</p> <p>Warning</p> <p>If you do not use the <code>--apply-log-only</code> option to prevent the rollback phase, then your incremental backups will be useless. After transactions have been rolled back, further incremental backups cannot be applied.</p> <p>Beginning with the full backup you created, you can prepare it, and then apply the incremental differences to it. Recall that you have the following backups:</p> <pre><code>/data/backups/base\n/data/backups/inc1\n/data/backups/inc2\n</code></pre> <p>To prepare the base backup, you need to run <code>--prepare</code> as usual, but prevent the rollback phase:</p> <pre><code>$ xtrabackup --prepare --apply-log-only --target-dir=/data/backups/base\n</code></pre> <p>The output should end with text similar to the following:</p> Expected output <pre><code>InnoDB: Shutdown completed; log sequence number 1626007\n161011 12:41:04 completed OK!\n</code></pre> <p>The log sequence number should match the <code>to_lsn</code> of the base backup, which you saw previously.</p> <p>Warning</p> <p>This backup is actually safe to restore as-is now, even though the rollback phase has been skipped. If you restore it and start MySQL, InnoDB will detect that the rollback phase was not performed, and it will do that in the background, as it usually does for a crash recovery upon start. It will notify you that the database was not shut down normally.</p> <p>To apply the first incremental backup to the full backup, run the following command:</p> <pre><code>$ xtrabackup --prepare --apply-log-only --target-dir=/data/backups/base \\\n--incremental-dir=/data/backups/inc1\n</code></pre> <p>This applies the delta files to the files in <code>/data/backups/base</code>, which rolls them forward in time to the time of the incremental backup. It then applies the redo log as usual to the result. The final data is in <code>/data/backups/base</code>, not in the incremental directory. You should see an output similar to:</p> Expected output <pre><code>incremental backup from 1626007 is enabled.\nxtrabackup: cd to /data/backups/base\nxtrabackup: This target seems to be already prepared with --apply-log-only.\nxtrabackup: xtrabackup_logfile detected: size=2097152, start_lsn=(4124244)\n...\nxtrabackup: page size for /tmp/backups/inc1/ibdata1.delta is 16384 bytes\nApplying /tmp/backups/inc1/ibdata1.delta to ./ibdata1...\n...\n161011 12:45:56 completed OK!\n</code></pre> <p>Again, the LSN should match what you saw from your earlier inspection of the first incremental backup. If you restore the files from <code>/data/backups/base</code>, you should see the state of the database as of the first incremental backup.</p> <p>Warning</p> <p>Percona XtraBackup does not support using the same incremental backup directory to prepare two copies of backup. Do not run <code>--prepare</code> with the same incremental backup directory (the value of \u2013incremental-dir) more than once.</p> <p>Preparing the second incremental backup is a similar process: apply the deltas to the (modified) base backup, and you will roll its data forward in time to the point of the second incremental backup:</p> <pre><code>$ xtrabackup --prepare --target-dir=/data/backups/base \\\n--incremental-dir=/data/backups/inc2\n</code></pre> <p>Note</p> <p><code>--apply-log-only</code> should be used when merging the incremental backups except the last one. That\u2019s why the previous line does not contain the <code>--apply-log-only</code> option. Even if the <code>--apply-log-only</code> was used on the last step, backup would still be consistent but in that case server would perform the rollback phase.</p>"},{"location":"prepare-incremental-backup.html#next-step","title":"Next step","text":"<p>Restore the backup </p>"},{"location":"prepare-incremental-backup.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"prepare-individual-partitions-backup.html","title":"Prepare an individual partitions backup","text":"<p>For preparing partial backups, the procedure is analogous to restoring individual tables. Apply the logs and use xtrabackup \u2013export:</p> <pre><code>$ xtrabackup --apply-log --export /mnt/backup/2012-08-28_10-29-09\n</code></pre> <p>You may see warnings in the output about tables that do not exist. This happens because InnoDB-based engines stores its data dictionary inside the tablespace files. xtrabackup removes the missing tables (those that haven\u2019t been selected in the partial backup) from the data dictionary in order to avoid future warnings or errors.</p>"},{"location":"prepare-individual-partitions-backup.html#next-step","title":"Next step","text":"<p>Restore the partition from the backup </p>"},{"location":"prepare-individual-partitions-backup.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"prepare-partial-backup.html","title":"Prepare a partial backup","text":"<p>The procedure is analogous to restoring individual tables: apply the logs and use the <code>--export</code> option:</p> <pre><code>$ xtrabackup --prepare --export --target-dir=/path/to/partial/backup\n</code></pre> <p>When you use the <code>--prepare</code> option on a partial backup, you will see warnings about tables that don\u2019t exist. This is because these tables exist in the data dictionary inside InnoDB, but the corresponding .ibd files don\u2019t exist. They were not copied into the backup directory. These tables will be removed from the data dictionary, and when you restore the backup and start InnoDB, they will no longer exist and will not cause any errors or warnings to be printed to the log file.</p> <p>Could not find any file associated with the tablespace ID: 5</p> <p>Use <code>--innodb-directories</code> to find the tablespace files. If that fails then use <code>-\u2013innodb-force-recovery=1</code> to ignore this and to permanently lose all changes to the missing tablespace(s).</p>"},{"location":"prepare-partial-backup.html#next-step","title":"Next step","text":"<p>Restore the partition from the backup </p>"},{"location":"prepare-partial-backup.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"privileges.html","title":"Connection and privileges needed","text":"<p>Percona XtraBackup needs to be able to connect to the database server and perform operations on the server and the datadir when creating a backup, when preparing in some scenarios and when restoring it. In order to do so, there are privileges and permission requirements on its execution that must be fulfilled.</p> <p>Privilege refers to the operations that a system user is permitted to do in the database server. They are set at the database server and only apply to users in the database server.</p> <p>Permissions are those which permits a user to perform operations on the system, like reading, writing or executing on a certain directory or start/stop a system service. They are set at a system level and only apply to system users.</p> <p>When xtrabackup is used, there are two actors involved: the user invoking the program - a system user - and the user performing action in the database server - a database user. Note that these are different users in different places, even though they may have the same username.</p> <p>All the invocations of xtrabackup in this documentation assume that the system user has the appropriate permissions, and you are providing the relevant options for connecting the database server - besides the options for the action to be performed - and the database user has adequate privileges.</p>"},{"location":"privileges.html#connect-to-the-server","title":"Connect to the server","text":"<p>The database user used to connect to the server and its password are specified by the <code>--user</code> and <code>--password</code> option:</p> <pre><code>$ xtrabackup --user=DVADER --password=14MY0URF4TH3R --backup \\\n--target-dir=/data/bkps/\n</code></pre> <p>If you don\u2019t use the <code>--user</code> option, Percona XtraBackup will assume the database user whose name is the system user executing it.</p>"},{"location":"privileges.html#other-connection-options","title":"Other connection options","text":"<p>According to your system, you may need to specify one or more of the following options to connect to the server:</p> Option Description -port Use this port when connecting to the database with TCP/IP -socket Use this socket when connecting to the local database. -host Use this host when connecting to the database server with TCP/IP <p>These options are passed to the mysql child process without alteration, see <code>mysql --help</code> for details.</p> <p>Note</p> <p>In case of multiple server instances, the correct connection parameters (port, socket, host) must be specified in order for xtrabackup to talk to the correct server.</p>"},{"location":"privileges.html#privileges-needed","title":"Privileges needed","text":"<p>Once connected to the server, in order to perform a backup you need <code>READ</code> and <code>EXECUTE</code> permissions at a filesystem level in the server\u2019s datadir.</p> <p>The database user needs the following privileges to back up tables or databases:</p> <ul> <li> <p><code>RELOAD</code> and <code>FLUSH_TABLES</code> in order to run <code>FLUSH TABLES WITH READ LOCK</code>.</p> </li> <li> <p>The <code>BACKUP_ADMIN</code> privilege is needed to query the performance_schema.log_status table, and run <code>LOCK INSTANCE FOR BACKUP</code>, <code>LOCK BINLOG FOR BACKUP</code>, or <code>LOCK TABLES FOR BACKUP</code>. The <code>BACKUP_ADMIN</code> privilege is required to use the Page tracking feature.</p> </li> <li> <p><code>REPLICATION CLIENT</code> in order to obtain the binary log position,</p> </li> <li> <p><code>CREATE TABLESPACE</code> in order to import tables (see Restoring Individual Tables),</p> </li> <li> <p><code>PROCESS</code> in order to run <code>SHOW ENGINE INNODB STATUS</code> (which is mandatory), and optionally to see all threads which are running on the server (see FLUSH TABLES WITH READ LOCK option),</p> </li> <li> <p><code>REPLICATION_SLAVE_ADMIN</code> in order to start/stop the replication threads in a replication environment,</p> </li> <li> <p><code>CREATE</code> privilege in order to create the PERCONA_SCHEMA.xtrabackup_history database and table,</p> </li> <li> <p><code>ALTER</code> privilege in order to upgrade the PERCONA_SCHEMA.xtrabackup_history database and table,</p> </li> <li> <p><code>INSERT</code> privilege in order to add history records to the PERCONA_SCHEMA.xtrabackup_history table,</p> </li> <li> <p><code>SELECT</code> privilege in order to use <code>--incremental-history-name</code> or <code>--incremental-history-uuid</code> in order for the feature to look up the <code>innodb_to_lsn</code> values in the PERCONA_SCHEMA.xtrabackup_history table.</p> </li> <li> <p><code>SELECT</code> privilege on the keyring_component_status table to view the attributes and status of the installed keyring component when in use.</p> </li> <li> <p><code>SELECT</code> privilege on the replication_group_members table to validate if the instance is part of group replication cluster.</p> </li> </ul> <p>A SQL example of creating a database user with the minimum privileges required to take full backups would be:</p> <pre><code>mysql&gt; CREATE USER 'bkpuser'@'localhost' IDENTIFIED BY 's3cr%T';\nmysql&gt; GRANT BACKUP_ADMIN, PROCESS, RELOAD, LOCK TABLES, REPLICATION CLIENT ON *.* TO 'bkpuser'@'localhost';\nmysql&gt; GRANT SELECT ON performance_schema.log_status TO 'bkpuser'@'localhost';\nmysql&gt; GRANT SELECT ON performance_schema.keyring_component_status TO bkpuser@'localhost';\nmysql&gt; GRANT SELECT ON performance_schema.replication_group_members TO bkpuser@'localhost';\nmysql&gt; FLUSH PRIVILEGES;\n</code></pre>"},{"location":"privileges.html#query-the-privileges","title":"Query the privileges","text":"<p>To query the privileges that your database user has been granted at the console of the server execute:</p> <pre><code>mysql&gt; SHOW GRANTS;\n</code></pre> <p>or for a particular user with:</p> <pre><code>mysql&gt; SHOW GRANTS FOR 'db-user'@'host';\n</code></pre> <p>It will display the privileges using the same format as for the GRANT statement.</p> <p>Note that privileges may vary across versions of the server. To list the exact list of privileges that your server support (and a brief description of them) execute:</p> <pre><code>mysql&gt; SHOW PRIVILEGES;\n</code></pre> <p>See also</p> <p>Permissions needed</p>"},{"location":"privileges.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"quickstart-overview.html","title":"Quickstart Guide for Percona XtraBackup {{vers}}","text":"<p>Percona XtraBackup (PXB) is a 100% open source backup solution for all versions of Percona Server for MySQL and MySQL\u00ae that performs online non-blocking, tightly compressed, highly secure full backups on transactional systems. Maintain fully available applications during planned maintenance windows with Percona XtraBackup.</p>"},{"location":"quickstart-overview.html#install-percona-xtrabackup","title":"Install Percona XtraBackup:","text":"<p>You can install Percona XtraBackup using different methods:</p> <ul> <li> <p>Use the Percona Repositories</p> </li> <li> <p>Use APT</p> </li> <li> <p>Use YUM</p> </li> <li> <p>Use binary tarballs</p> </li> <li> <p>Use Docker</p> </li> </ul>"},{"location":"quickstart-overview.html#for-superior-and-optimized-performance","title":"For superior and optimized performance","text":"<p>Percona Server for MySQL (PS) is a freely available, fully compatible, enhanced, and open source drop-in replacement for any MySQL database. It provides superior and optimized performance, greater scalability and availability, enhanced backups, increased visibility, and instrumentation. Percona Server for MySQL is trusted by thousands of enterprises to provide better performance and concurrency for their most demanding workloads.</p> <p>Install Percona Server for MySQL.</p>"},{"location":"quickstart-overview.html#for-high-availability","title":"For high availability","text":"<p>Percona XtraDB Cluster (PXC) is a 100% open source, enterprise-grade, highly available clustering solution for MySQL multi-master setups based on Galera. PXC helps enterprises minimize unexpected downtime and data loss, reduce costs, and improve performance and scalability of your database environments supporting your critical business applications in the most demanding public, private, and hybrid cloud environments. </p> <p>Install Percona XtraDB Cluster.</p>"},{"location":"quickstart-overview.html#for-monitoring-and-management","title":"For Monitoring and Management","text":"<p>Percona Monitoring and Management (PMM) monitors and provides actionable performance data for MySQL variants, including Percona Server for MySQL, Percona XtraDB Cluster, Oracle MySQL Community Edition, Oracle MySQL Enterprise Edition, and MariaDB. PMM captures metrics and data for the InnoDB, XtraDB, and MyRocks storage engines, and has specialized dashboards for specific engine details.</p> <p>Install PMM and connect your MySQL instances to it.</p>"},{"location":"quickstart-overview.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"restore-a-backup.html","title":"Restore full, incremental, compressed backups","text":"<p>Warning</p> <p>Backup needs to be prepared before it can be restored.</p> <p>For convenience, xtrabackup binary has the <code>--copy-back</code> option to copy the backup to the datadir of the server:</p> <pre><code>$ xtrabackup --copy-back --target-dir=/data/backups/\n</code></pre> <p>If you don\u2019t want to save your backup, you can use the <code>--move-back</code> option which will move the backed up data to the datadir.</p> <p>If you don\u2019t want to use any of the above options, you can additionally use rsync or cp to restore the files.</p> <p>Note</p> <p>The datadir must be empty before restoring the backup. Also, it\u2019s important to note that MySQL server needs to be shut down before restore is performed. You cannot restore to a datadir of a running mysqld instance (except when importing a partial backup).</p> <p>Example of the rsync command that can be used to restore the backup can look like this:</p> <pre><code>$ rsync -avrP /data/backup/ /var/lib/mysql/\n</code></pre> <p>You should check that the restored files have the correct ownership and permissions.</p> <p>As files\u2019 attributes are preserved, in most cases you must change the files\u2019 ownership to <code>mysql</code> before starting the database server, as the files are owned by the user who created the backup:</p> <pre><code>$ chown -R mysql:mysql /var/lib/mysql\n</code></pre> <p>Data is now restored, and you can start the server.</p>"},{"location":"restore-a-backup.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"restore-individual-partitions.html","title":"Restore the partition from the backup","text":"<p>Restoring should be done by importing the tables in the partial backup to the server.</p> <p>First step is to create new table in which data will be restored.</p> <pre><code>mysql&gt; CREATE TABLE `name_p4` (\n`id` int(11) NOT NULL AUTO_INCREMENT,\n`name` text NOT NULL,\n`imdb_index` varchar(12) DEFAULT NULL,\n`imdb_id` int(11) DEFAULT NULL,\n`name_pcode_cf` varchar(5) DEFAULT NULL,\n`name_pcode_nf` varchar(5) DEFAULT NULL,\n`surname_pcode` varchar(5) DEFAULT NULL,\nPRIMARY KEY (`id`)\n) ENGINE=InnoDB AUTO_INCREMENT=2812744 DEFAULT CHARSET=utf8\n</code></pre> <p>Note</p> <p>Generate a .cfg metadata file by running <code>FLUSH TABLES ... FOR EXPORT</code>. The command can only be run on a table, not on the individual table partitions. The file is located in the table schema directory and is used for schema verification when importing the tablespace. </p> <p>To restore the partition from the backup, the tablespace must be discarded for that table:</p> <pre><code>mysql&gt; ALTER TABLE name_p4 DISCARD TABLESPACE;\n</code></pre> <p>The next step is to copy the <code>.ibd</code> file from the backup to the MySQL data directory:</p> <pre><code>cp /mnt/backup/2012-08-28_10-29-09/imdb/name#P#p4.ibd /var/lib/mysql/imdb/name_p4.ibd\n</code></pre> <p>Note</p> <p>Make sure that the copied files can be accessed by the user running MySQL. </p> <p>The last step is to import the tablespace:</p> <pre><code>mysql&gt; ALTER TABLE name_p4 IMPORT TABLESPACE;\n</code></pre>"},{"location":"restore-individual-partitions.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"restore-individual-tables.html","title":"Restore individual tables","text":"<p>Percona XtraBackup can export a table that is contained in its own .ibd file. With Percona XtraBackup, you can export individual tables from any InnoDB database, and import them into Percona Server for MySQL with XtraDB or MySQL {{vers}}. The source doesn\u2019t have to be XtraDB or MySQL {{vers}}, but the destination does. This method only works on individual .ibd files.</p> <p>The following example exports and imports the following table:</p> <pre><code>CREATE TABLE export_test (\na int(11) DEFAULT NULL\n) ENGINE=InnoDB DEFAULT CHARSET=latin1;\n</code></pre>"},{"location":"restore-individual-tables.html#export-the-table","title":"Export the table","text":"<p>To generate an .ibd file in the target directory, create the table using the <code>innodb_file_per_table</code> mode:</p> <pre><code>$ find /data/backups/mysql/ -name export_test.*\n/data/backups/mysql/test/export_test.ibd\n</code></pre> <p>During the <code>--prepare</code> step, add the <code>--export</code> option to the command. For example:</p> <pre><code>$ xtrabackup --prepare --export --target-dir=/data/backups/mysql/\n</code></pre> <p>When restoring an encrypted InnoDB tablespace table, add the keyring file:</p> <pre><code>$ xtrabackup --prepare --export --target-dir=/tmp/table \\\n--keyring-file-data=/var/lib/mysql-keyring/keyring\n</code></pre> <p>The following files are the only files required to import the table into a server running Percona Server for MySQL with XtraDB or MySQL {{vers}}. If the server uses InnoDB Tablespace Encryption, add the .cfp file, which contains the transfer key and an encrypted tablespace key.</p> <p>The files are located in the target directory:</p> <pre><code>/data/backups/mysql/test/export_test.ibd\n/data/backups/mysql/test/export_test.cfg\n</code></pre>"},{"location":"restore-individual-tables.html#import-the-table","title":"Import the table","text":"<p>On the destination server running Percona Server for MySQL with XtraDB or MySQL {{vers}}, create a table with the same structure, and then perform the following steps:</p> <ol> <li> <p>Run the <code>ALTER TABLE test.export_test DISCARD TABLESPACE;</code> command. If you see the following error message:</p> Error message <pre><code>ERROR 1809 (HY000): Table 'test/export_test' in system tablespace\n</code></pre> <p>enable <code>innodb_file_per_table</code> option on the server and create the table again.</p> <pre><code>$ set global innodb_file_per_table=ON;\n</code></pre> </li> <li> <p>Copy the exported files to the <code>test/</code> subdirectory of the destination server\u2019s data directory.</p> </li> <li> <p>Run <code>ALTER TABLE test.export_test IMPORT TABLESPACE;</code></p> <p>The table is imported, and you can run a <code>SELECT</code> to see the imported data.</p> </li> </ol>"},{"location":"restore-individual-tables.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"restore-partial-backup.html","title":"Restore a partial backup","text":"<p>Restoring should be done by restoring individual tables in the partial backup to the server.</p> <p>It can also be done by copying back the prepared backup to a \u201cclean\u201d datadir (in that case, make sure to include the <code>mysql</code> database) to the datadir you are moving the backup to. A system database can be created with the following:</p> <pre><code>$ sudo mysql --initialize --user=mysql\n</code></pre> <p>Once you start the server, you may see mysql complaining about missing tablespaces:</p> Expected output <pre><code>2021-07-19T12:42:11.077200Z 1 [Warning] [MY-012351] [InnoDB] Tablespace 4, name 'test1/t1', file './d2/test1.ibd' is missing!\n2021-07-19T12:42:11.077300Z 1 [Warning] [MY-012351] [InnoDB] Tablespace 4, name 'test1/t1', file './d2/test1.ibd' is missing!\n</code></pre> <p>In order to clean the orphan database from the data dictionary, you must manually create the missing database directory and then <code>DROP</code> this database from the server.</p> <p>Example of creating the missing database:</p> <pre><code>$ mkdir /var/lib/mysql/test1/d2\n</code></pre> <p>Example of dropping the database from the server:</p> <pre><code>mysql&gt; DROP DATABASE d2;\n</code></pre> Expected output <pre><code>Query OK, 2 rows affected (0.5 sec)\n</code></pre>"},{"location":"restore-partial-backup.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"server-backup-version-comparison.html","title":"Server version and backup version comparison","text":"<p>A MySQL change to a feature, such as the structure of a redo log record, can cause older versions of Percona XtraBackup to fail. To ensure that you can back up and restore your data, use a Percona XtraBackup version that is equal to your source server major version. This means if you use Percona XtraBackup {{vers}}.x, you can safely back up the source server from {{vers}}.x to {{vers}}.xx.</p> <p>See also</p> <p>How XtraBackup works</p> <p>The <code>--no-server-version-check</code> option performs the following test. Before the backup/prepare starts, XtraBackup compares the source server version to the Percona XtraBackup version. If the source server version is greater than the XtraBackup major version, XtraBackup stops the backup and returns an error message. This comparison prevents a failed backup or a corrupted backup due to source server changes.</p> <p>The parameter checks for the following scenarios:</p> <ul> <li> <p>The source server and the PXB major version are the same, the backup proceeds</p> </li> <li> <p>The source server is greater than the PXB major version, and the parameter is not overridden, the backup is stopped and returns an error message</p> </li> <li> <p>The source server is less than the PXB major version, and the parameter is not overridden, the backup is stopped and returns an error message</p> </li> <li> <p>The source server is greater than the PXB major version up to the last release in the LTS series, and the parameter is overridden, the backup proceeds</p> </li> </ul> <p>Explicitly adding the <code>--no-server-version-check</code> parameter, like the example, overrides the parameter and the backup proceeds.</p> <pre><code>$ xtrabackup --backup --no-server-version-check --target-dir=$mysql/backup1\n</code></pre> <p>Overriding the <code>--no-server-version-check</code> parameter allows taking backups using a Percona XtraBackup version that is equal to a version of your source server up to the last release in the LTS series. This means if you use Percona XtraBackup {{vers}}.x, you can back up the source server from {{vers}}.x to 8.4.xx.</p> <p>When you override the parameter, the following events can happen:</p> <ul> <li> <p>Backup fails</p> </li> <li> <p>Creates a corrupted backup</p> </li> <li> <p>Backup successful</p> </li> </ul>"},{"location":"server-backup-version-comparison.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"set-up-replication.html","title":"How to set up a replica for replication in 6 simple steps with Percona XtraBackup","text":"<p>Data is, by far, the most valuable part of a system. Having a backup done systematically and available for a rapid recovery in case of failure is admittedly essential to a system. However, it is not common practice because of its costs, infrastructure needed or even the boredom associated to the task. Percona XtraBackup is designed to solve this problem.</p> <p>You can have almost real-time backups in 6 simple steps by setting up a replication environment with Percona XtraBackup.</p>"},{"location":"set-up-replication.html#things-you-need","title":"Things you need","text":"<p>Setting up a replica for replication with Percona XtraBackup is a straightforward procedure. In order to keep it simple, here is a list of the things you need to follow the steps without hassles:</p> <p><code>Source</code></p> <p>A system with a MySQL-based server installed, configured and running. This system is called <code>Source</code>. The <code>Source</code> server stores your data and can be replicated. We assume the following about this system:</p> <ul> <li> <p>the MySQL server is able to communicate with others by the standard TCP/IP port;</p> </li> <li> <p>the SSH server is installed and configured;</p> </li> <li> <p>you have a user account in the system with the appropriate permissions;</p> </li> <li> <p>you have a MySQL\u2019s user account with appropriate privileges.</p> </li> <li> <p>server has binlogs enabled and server-id set up to 1.</p> </li> </ul> <p><code>Replica</code></p> <p>Another system, with a MySQL-based server installed on it. We refer to this machine as <code>Replica</code> and assume the same things we did about <code>Source</code>, except that the server-id on <code>Replica</code> is 2.</p> <p><code>Percona XtraBackup</code></p> <p>We use this backup tool. Install Percona XtraBackup on both computers for convenience.</p> <p>Note</p> <p>It is not recommended to mix MySQL variants (Percona Server, MySQL) in your replication setup. This may produce incorrect <code>xtrabackup_slave_info</code> file when adding a new replica. </p>"},{"location":"set-up-replication.html#1-make-a-backup-on-the-source-and-prepare-it","title":"1. Make a backup on the <code>Source</code> and prepare it","text":"<p>At the <code>Source</code>, issue the following to a shell:</p> <pre><code>$ xtrabackup --backup --user=yourDBuser --password=MaGiCdB1 --target-dir=/path/to/backupdir\n</code></pre> <p>After this is finished you should get:</p> Expected output <pre><code>xtrabackup: completed OK!\n</code></pre> <p>This operation makes a copy of your MySQL data dir to the <code>/path/to/backupdir</code> directory. You have told Percona XtraBackup to connect to the database server using your database user and password, and do a hot backup of all your data in it (all MyISAM, InnoDB tables and indexes in them).</p> <p>In order for snapshot to be consistent, prepare the data on the source:</p> <pre><code>$ xtrabackup --prepare --target-dir=/path/to/backupdir\n</code></pre> <p>Select the path where your snapshot has been taken. Apply the transaction logs to the data files and your data files are ready to be used by the MySQL server.</p> <p>Percona XtraBackup reads the my.cnf file to locate your data. If you have your configuration file in a non-standard place, you should use the flag <code>--defaults-file</code> <code>=/location/of/my.cnf</code>.</p> <p>If you want to skip writing the username and password every time you want to access MySQL, you can set it up in <code>.mylogin.cnf</code> as follows:</p> <pre><code>mysql_config_editor set --login-path=client --host=localhost --user=root --password\n</code></pre> <p>For more information, see MySQL Configuration Utility.</p> <p>This statement provides root access to MySQL.</p>"},{"location":"set-up-replication.html#2-copy-backed-up-data-to-the-replica","title":"2.  Copy backed up data to the Replica","text":"<p>On the Source, use rsync or scp to copy the data from the Source to the Replica. If you are syncing the data directly to replica\u2019s data directory, we recommend that you stop the <code>mysqld</code> there.</p> <pre><code>$ rsync -avpP -e ssh /path/to/backupdir Replica:/path/to/mysql/\n</code></pre> <p>After data is copied, you can back up the original or previously installed MySQL datadir. </p> <p>Note</p> <p>Make sure mysqld is shut down before you move the contents of its datadir, or move the snapshot into its datadir.</p> <p>Run the following commands on the Replica:</p> <pre><code>$ mv /path/to/mysql/datadir /path/to/mysql/datadir_bak\n</code></pre> <p>and move the snapshot from the <code>Source</code> in its place:</p> <pre><code>$ xtrabackup --move-back --target-dir=/path/to/mysql/backupdir\n</code></pre> <p>After you copy data over, make sure the Replica MySQL has the proper permissions to access them.</p> <pre><code>$ chown mysql:mysql /path/to/mysql/datadir\n</code></pre> <p>If the ibdata and iblog files are located in directories outside the datadir, you must put these files in their proper place after the logs have been applied.</p>"},{"location":"set-up-replication.html#3-configure-the-sources-mysql-server","title":"3. Configure the Source\u2019s MySQL server","text":"<p>On the source, run the following command to add the appropriate grant. This grant allows the replica to be able to connect to source:</p> <pre><code>mysql&gt; GRANT REPLICATION SLAVE ON *.*  TO 'repl'@'$replicaip'\nIDENTIFIED BY '$replicapass';\n</code></pre> <p>Also make sure that firewall rules are correct and that the <code>Replica</code> can connect to the <code>Source</code>. Run the following command on the Replica to test that you can run the mysql client on <code>Replica</code>, connect to the <code>Source</code>, and authenticate.</p> <pre><code>mysql&gt; mysql --host=Source --user=repl --password=$replicapass\n</code></pre> <p>Verify the privileges.</p> <pre><code>mysql&gt; SHOW GRANTS;\n</code></pre>"},{"location":"set-up-replication.html#4-configure-the-replicas-mysql-server","title":"4. Configure the Replica\u2019s MySQL server","text":"<p>Copy the <code>my.cnf</code> file from the <code>Source</code> to the <code>Replica</code>:</p> <pre><code>$ scp user@Source:/etc/mysql/my.cnf /etc/mysql/my.cnf\n</code></pre> <p>and change the following options in /etc/mysql/my.cnf:</p> <pre><code>server-id=2\n</code></pre> <p>and start/restart mysqld on the <code>Replica</code>.</p> <p>In case you\u2019re using init script on Debian-based system to start mysqld, be sure that the password for <code>debian-sys-maint</code> user has been updated, and it\u2019s the same as that user\u2019s password on the <code>Source</code>. Password can be seen and updated in <code>/etc/mysql/debian.cnf</code>.</p>"},{"location":"set-up-replication.html#5-start-the-replication","title":"5. Start the replication","text":"<p>On the <code>Replica</code>, review the content of the <code>xtrabackup_binlog_info</code> file:</p> <pre><code>$ cat /var/lib/mysql/xtrabackup_binlog_info\n</code></pre> <p>The results should resemble the following:</p> Expected output <pre><code>Source-bin.000001     481\n</code></pre> <p>Do the following on a MySQL console and use the username and password you\u2019ve set up in STEP 3:</p> <p>Use the <code>CHANGE_REPLICATION_SOURCE_TO</code> statement</p> <pre><code>CHANGE REPLICATION SOURCE TO\n    SOURCE_HOST='$sourceip',\n    SOURCE_USER='repl',\n    SOURCE_PASSWORD='$replicapass',\n    SOURCE_LOG_FILE='Source-bin.000001',\n    SOURCE_LOG_POS=481;\n</code></pre> <p>Start the replica:</p> <pre><code>START REPLICA;\n</code></pre>"},{"location":"set-up-replication.html#6-check","title":"6. Check","text":"<p>On the <code>Replica</code>, check that everything went OK with:</p> <pre><code>SHOW REPLICA STATUS\\G\n</code></pre> <p>The result shows the status:</p> Expected output <pre><code>Slave_IO_Running: Yes\nSlave_SQL_Running: Yes\nSeconds_Behind_Master: 13\n</code></pre> <p>Both <code>IO</code> and <code>SQL</code> threads need to be running. The <code>Seconds_Behind_Master</code> means the <code>SQL</code> currently being executed has a <code>current_timestamp</code> of 13 seconds ago. It is an estimation of the lag between the <code>Source</code> and the <code>Replica</code>. Note that at the beginning, a high value could be shown because the <code>Replica</code> has to \u201ccatch up\u201d with the <code>Source</code>.</p>"},{"location":"set-up-replication.html#adding-more-replicas-to-the-source","title":"Adding more replicas to the Source","text":"<p>You can use this procedure with slight variation to add new replicas to a source. We will use Percona XtraBackup to clone an already configured replica. We will continue using the previous scenario for convenience, but we will add a <code>NewReplica</code> to the plot.</p> <p>At the <code>Replica</code>, do a full backup:</p> <pre><code>$ xtrabackup --user=yourDBuser --password=MaGiCiGaM \\\n   --backup --slave-info --target-dir=/path/to/backupdir\n</code></pre> <p>By using the <code>--slave-info</code> Percona XtraBackup creates additional file called <code>xtrabackup_slave_info</code>.</p> <p>Apply the logs:</p> <pre><code>$ xtrabackup --prepare --use-memory=2G --target-dir=/path/to/backupdir/\n</code></pre> <p>Note</p> <p>In the <code>prepare</code> phase, the <code>--use-memory</code> parameter speeds up the process if the amount of RAM assigned to the option is available. Use the parameter only in the <code>prepare</code> phase. In the other phases the parameter makes the application lazy allocate this memory (reserve) but does not affect database pages.</p> <p>Copy the directory from the <code>Replica</code> to the <code>NewReplica</code>:</p> <p>Note</p> <p>Make sure mysqld is shut down on the <code>NewReplica</code> before you copy the contents the snapshot into its datadir.</p> <pre><code>rsync -avprP -e ssh /path/to/backupdir NewReplica:/path/to/mysql/datadir\n</code></pre> <p>For example, to set up a new user, <code>user2</code>, you add another grant on the Source:</p> <pre><code>&gt; GRANT REPLICATION SLAVE ON *.*  TO 'user2'@'$newreplicaip'\n IDENTIFIED BY '$replicapass';\n</code></pre> <p>On the <code>NewReplica</code>, copy the configuration file from the <code>Replica</code>:</p> <pre><code>$ scp user@Replica:/etc/mysql/my.cnf /etc/mysql/my.cnf\n</code></pre> <p>Make sure you change the server-id variable in <code>/etc/mysql/my.cnf</code> to 3 and disable the replication on start:</p> <pre><code>skip-slave-start\nserver-id=3\n</code></pre> <p>After setting <code>server_id</code>, start mysqld.</p> <p>Fetch the source_log_file and source_log_pos from the file <code>xtrabackup_slave_info</code>, execute the statement for setting up the source and the log file for the NewReplica:</p> <pre><code>CHANGE REPLICATION SOURCE TO\n    SOURCE_HOST='$sourceip',\n    SOURCE_USER='repl',\n    SOURCE_PASSWORD='$replicapass',\n    SOURCE_LOG_FILE='Source-bin.000001',\n    SOURCE_LOG_POS=481;\n</code></pre> <p>Start the replica:</p> <pre><code>&gt; START REPLICA;\n</code></pre> <p>If both IO and SQL threads are running when you check the <code>NewReplica</code>, server is replicating the <code>Source</code>.</p> <p>See also</p> <p>How to create a new (or repair a broken) GTID based slave</p>"},{"location":"set-up-replication.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"smart-memory-estimation.html","title":"Smart memory estimation","text":"<p>The Smart memory estimation is tech preview feature. Before using Smart memory estimation in production, we recommend that you test restoring production from physical backups in your environment and also use the alternative backup method for redundancy.</p> <p>Percona XtraBackup supports the Smart memory estimation feature. With this feature, Percona XtraBackup computes the memory required for <code>prepare</code> phase, while copying redo log entries during the <code>backup</code> phase. Percona XtraBackup also considers the number of InnoDB pages to be fetched from the disk.  </p> <p>Percona XtraBackup performs the backup procedure in two steps: </p> <ul> <li> <p>Creates a backup</p> <p>To create a backup, Percona XtraBackup copies your InnoDB data files. While copying the files, Percona XtraBackup runs a background process that watches the InnoDB redo log, also called the transaction log, and copies changes from it. </p> </li> <li> <p>Prepares a backup</p> <p>During the <code>prepare</code> phase, Percona XtraBackup performs crash recovery against the copied data files using the copied transaction log file. Percona XtraBackup reads all the redo log entries into memory, categorizes them by space id and page id, reads the relevant pages into memory, and checks the log sequence number (LSN) on the page and on the redo log record. If the redo log LSN is more recent than the page LSN, Percona XtraBackup applies the redo log changes to the page.</p> <p>To <code>prepare</code> a backup, Percona Xtrabackup uses InnoDB Buffer Pool memory. Percona Xtrabackup reserves memory to load 256 pages into the buffer pool. The remaining memory is used for hashing/categorizing the redo log entries.</p> <p>The available memory is controlled by the <code>--use-memory</code> option. If the available memory on the buffer pool is insufficient, the work is performed in multiple batches. After the batch is processed, the memory is freed to release space for the next batch. This process greatly impacts performance as an InnoDB page holds data from multiple rows. If a change on a page happens in different batches, that page is fetched and evicted numerous times.</p> </li> </ul>"},{"location":"smart-memory-estimation.html#how-does-smart-memory-estimation-work","title":"How does Smart memory estimation work","text":"<p>To run <code>prepare</code>, Percona XtraBackup checks the server\u2019s available free memory and uses that memory up to the limit specified in the <code>--use-free-memory-pct</code> option. Due to backward compatibility, the default value for the <code>--use-free-memory-pct</code> option is 0 (zero), which defines the option as disabled. For example, if you set <code>--use-free-memory-pct=50</code>, then 50% of the free memory is used to <code>prepare</code> a backup.</p> <p>You can enable or disable the memory estimation during the <code>backup</code> phase with the <code>--estimate-memory</code> option. The default value is <code>OFF</code>. Enable the memory estimation with  <code>--estimate-memory=ON</code>:</p> <pre><code>$ xtrabackup --backup --estimate-memory=ON --target-dir=/data/backups/\n</code></pre> <p>In the <code>prepare</code> phase, enable the <code>--use-free-memory-pct</code> option by specifying the percentage of free memory to be used to <code>prepare</code> a backup. The <code>--use-free-memory-pct</code> value must be larger than 0.</p> <p>For example:</p> <pre><code>$ xtrabackup --prepare --use-free-memory-pct=50 --target-dir=/data/backups/\n</code></pre>"},{"location":"smart-memory-estimation.html#example-of-smart-memory-estimation-usage","title":"Example of Smart memory estimation usage","text":"<p>The examples of how Smart memory estimation can improve the time spent on <code>prepare</code> in Percona XtraBackup:</p> <p>We back up 16, 32, and 64 tables using sysbench. Each set contains 1M rows. In the <code>backup</code> phase, we enable Smart memory estimation with <code>--estimate-memory=ON</code>. In the <code>prepare</code> phase, we set <code>--use-free-memory-pct=50</code>, and Percona XtraBackup uses 50% of the free memory to prepare a backup. The backup is run on an ec2 c4.8xlarge instance (36 vCPUs / 60GB memory / General Purpose SSD (gp2)). </p> <p>During each <code>--backup</code>, the following sysbench is run:</p> <pre><code>sysbench --db-driver=mysql --db-ps-mode=disable --mysql-user=sysbench --mysql-password=sysbench --table_size=1000000 --tables=${NUM_OF_TABLES} --threads=24 --time=0 --report-interval=1 /usr/share/sysbench/oltp_write_only.lua run\n</code></pre> <p>The following table shows the backup details (all measurements are in Gigabytes):</p> Used memory Size of XtraBackup log Size of backup 16 tables 3.375 0.7 4.7 32 tables 8.625 2.6 11 64 tables 18.5 5.6 22 <ul> <li> <p>Used memory - the amount of memory required by Percona XtraBackup with <code>--use-free-memory-pct=50</code></p> </li> <li> <p>Size of XtraBackup log - the size of Percona XtraBackup log file (redo log entries copied during the backup)</p> </li> <li> <p>Size of backup - the size of the resulting backup folder</p> </li> </ul> <p><code>Prepare</code> executed without Smart memory estimation uses the default of 128MB for the buffer pool.</p> <p>The results are the following:</p> <p>Note</p> <p>The following results are based on tests in a specific environment. Your results may vary.</p> <p></p> <ul> <li> <p>16 tables result - prepare time dropped to ~5.7% of the original time. An improvement in recovery time of about 17x.</p> </li> <li> <p>32 tables result - prepare time dropped to ~8,2% of the original time. An improvement in recovery time of about 12x.</p> </li> <li> <p>64 tables result - prepare time dropped to ~9.9% of the original time. An improvement in recovery time of about 10x.</p> </li> </ul>"},{"location":"smart-memory-estimation.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"store-backup-history.html","title":"Store backup history on the server","text":"<p>Percona XtraBackup supports storing the backups history on the server. Storing backup history on the server was implemented to provide users with additional information about backups that are being taken. Backup history information will be stored in the <code>PERCONA_SCHEMA.XTRABACKUP_HISTORY</code> table.</p> <p>To use this feature the following options are available:</p> <ul> <li> <p><code>--history</code> = : This option enables the history feature and allows the user to specify a backup series name that will be placed within the history record. <li> <p><code>--incremental-history-name</code> = : This option allows an incremental backup to be made based on a specific history series by name. xtrabackup will search the history table looking for the most recent (highest <code>to_lsn</code>) backup in the series and take the <code>to_lsn</code> value to use as it\u2019s starting lsn. This is mutually exclusive with <code>--incremental-history-uuid</code>, <code>--incremental-basedir</code> and <code>--incremental-lsn</code> options. If no valid LSN can be found (no series by that name) xtrabackup will return with an error. <li> <p><code>--incremental-history-uuid</code> = : Allows an incremental backup to be made based on a specific history record identified by UUID. xtrabackup will search the history table looking for the record matching UUID and take the <code>to_lsn</code> value to use as it\u2019s starting LSN. This options is mutually exclusive with <code>--incremental-basedir</code>, <code>--incremental-lsn</code> and <code>--incremental-history-name</code> options. If no valid LSN can be found (no record by that UUID or missing <code>to_lsn</code>), xtrabackup will return with an error. <p>Note</p> <p>Backup that\u2019s currently being performed will NOT exist in the xtrabackup_history table within the resulting backup set as the record will not be added to that table until after the backup has been taken.</p> <p>If you want access to backup history outside of your backup set in the case of some catastrophic event, you will need to either perform a <code>mysqldump</code>, partial backup or <code>SELECT</code> * on the history table after xtrabackup completes and store the results with you backup set.</p> <p>For the necessary privileges, see Permissions and Privileges Needed.</p>"},{"location":"store-backup-history.html#percona_schemaxtrabackup_history-table","title":"PERCONA_SCHEMA.XTRABACKUP_HISTORY table","text":"<p>This table contains the information about the previous server backups. Information about the backups will only be written if the backup was taken with <code>--history</code> option.</p> Column Name Description uuid Unique backup id name User provided name of backup series. There may be multiple entries with the same name used to identify related backups in a series. tool_name Name of tool used to take backup tool_command Exact command line given to the tool with \u2013password and \u2013encryption_key obfuscated tool_version Version of tool used to take backup ibbackup_version Version of the xtrabackup binary used to take backup server_version Server version on which backup was taken start_time Time at the start of the backup end_time Time at the end of the backup lock_time Amount of time, in seconds, spent calling and holding locks for <code>FLUSH TABLES WITH READ LOCK</code> binlog_pos Binlog file and position at end of <code>FLUSH TABLES WITH READ LOCK</code> innodb_from_lsn LSN at beginning of backup which can be used to determine prior backups innodb_to_lsn LSN at end of backup which can be used as the starting lsn for the next incremental partial Is this a partial backup, if <code>N</code> that means that it\u2019s the full backup incremental Is this an incremental backup format Description of result format (<code>xbstream</code>) compact Is this a compact backup compressed Is this a compressed backup encrypted Is this an encrypted backup"},{"location":"store-backup-history.html#limitations","title":"Limitations","text":"<ul> <li> <p><code>--history</code> option must be specified only on the command line and not within a configuration file in order to be effective.</p> </li> <li> <p><code>--incremental-history-name</code> and <code>--incremental-history-uuid</code> options must be specified only on the command line and not within a configuration file in order to be effective.</p> </li> </ul>"},{"location":"store-backup-history.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"take-streaming-backup.html","title":"Take a streaming backup","text":"<p>Percona XtraBackup supports streaming mode. Streaming mode sends a backup to <code>STDOUT</code> in the xbstream format instead of copying the files to the backup directory.</p> <p>This method allows you to use other programs to filter the output of the backup, providing greater flexibility for storage of the backup. For example, compression is achieved by piping the output to a compression utility. One of the benefits of streaming backups and using Unix pipes is that the backups can be automatically encrypted.</p> <p>To use the streaming feature, you must use the <code>--stream</code>, providing the format of the stream (<code>xbstream</code> ) and where to store the temporary files:</p> <pre><code>$ xtrabackup --stream=xbstream --target-dir=/tmp\n</code></pre> <p>xtrabackup uses xbstream to stream all of the data files to <code>STDOUT</code>, in a special <code>xbstream</code> format. After it finishes streaming all of the data files to <code>STDOUT</code>, it stops xtrabackup and streams the saved log file too.</p> <p>When compression is enabled, xtrabackup compresses the output data, except for the meta and non-InnoDB files which are not compressed, using the specified compression algorithm. Percona XtraBackup supports the following compression algorithms:</p>"},{"location":"take-streaming-backup.html#zstandard-zstd","title":"Zstandard (ZSTD)","text":"<p>The Zstandard (ZSTD) is a fast lossless compression algorithm that targets real-time compression scenarios and better compression ratios. <code>ZSTD</code> is the default compression algorithm for the <code>--compress</code> option.</p> <p>To compress files using the <code>ZSTD</code> compression algorithm, use the <code>--compress</code> option:</p> <pre><code>$ xtrabackup --backup --compress --target-dir=/data/backup\n</code></pre> <p>The resulting files have the <code>\\*.zst</code> format.</p> <p>You can specify <code>ZSTD</code> compression level with the <code>--compress-zstd-level(=#)</code> option. The default value is <code>1</code>.</p> <pre><code>$ xtrabackup \u2013backup \u2013compress \u2013compress-zstd-level=1 \u2013target-dir=/data/backup\n</code></pre>"},{"location":"take-streaming-backup.html#lz4","title":"lz4","text":"<p>To compress files using the <code>lz4</code> compression algorithm, set the <code>--compress</code> option to <code>lz4</code>:</p> <pre><code>$ xtrabackup --backup --compress=lz4 --target-dir=/data/backup\n</code></pre> <p>The resulting files have the <code>\\*.lz4</code> format. </p> <p>To decompress files, use the <code>--decompress</code> option.</p> <p>Using xbstream as a stream option, backups can be copied and compressed in parallel. This option can significantly improve the speed of the backup process. In case backups were both compressed and encrypted, they must be decrypted before they are uncompressed.</p> Task Command Stream the backup into an archived named <code>backup.xbstream</code> <code>$ xtrabackup --backup --stream=xbstream --target-dir=./ &gt; backup.xbstream</code> Stream the backup into a compressed archive named <code>backup.xbstream</code> <code>$ xtrabackup --backup --stream=xbstream --compress --target-dir=./ &gt; backup.xbstream</code> Encrypt the backup <code>$ xtrabackup --backup --stream=xbstream ./ &gt; backup.xbstream gzip -`` | openssl des3 -salt -k \u201cpassword\u201d backup.xbstream.gz.des3</code> Unpack the backup to the current directory <code>$ xbstream -x &lt;  backup.xbstream</code> Send the backup compressed directly to another host and unpack it <code>$ xtrabackup --backup --compress --stream=xbstream --target-dir=./ | ssh user@otherhost \"xbstream -x\"</code> Send the backup to another server using <code>netcat</code> On the destination host:<code>$ nc -l 9999 | cat - &gt; /data/backups/backup.xbstream</code>On the source host:<code>$ xtrabackup --backup --stream=xbstream ./ | nc desthost 9999</code> Send the backup to another server using a one-liner <code>$ ssh user@desthost \u201c( nc -l 9999 &gt; /data/backups/backup.xbstream &amp; )\u201d &amp;&amp; xtrabackup --backup --stream=xbstream ./ | nc desthost 9999</code> Throttle the throughput to 10MB/sec using the pipe viewer tool <code>$ xtrabackup --backup --stream=xbstream ./ | pv -q -L10m ssh user@desthost \u201ccat - &gt; /data/backups/backup.xbstream\u201d</code> Checksum the backup during the streaming On the destination host:<code>$ nc -l 9999 | tee &gt;(sha1sum &gt; destination_checksum) &gt; /data/backups/backup.xbstream</code>On the source host:<code>$ xtrabackup --backup --stream=xbstream ./ | tee &gt;(sha1sum &gt; source_checksum) | nc desthost 9999</code>Compare the checksums on the source host:<code>$ cat source_checksum 65e4f916a49c1f216e0887ce54cf59bf3934dbad</code>Compare the checksums on the destination host:<code>$ cat destination_checksum 65e4f916a49c1f216e0887ce54cf59bf3934dbad</code> Parallel compression with parallel copying backup <code>$ xtrabackup --backup --compress --compress-threads=8 --stream=xbstream --parallel=4 --target-dir=./ &gt; backup.xbstream</code> <p>Important</p> <p>The streamed backup must be prepared before restoration. Streaming mode does not prepare the backup.</p>"},{"location":"take-streaming-backup.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"throttling-backups.html","title":"Throttling backups","text":"<p>Although xtrabackup does not block your database\u2019s operation, any backup can add load to the system being backed up. On systems that do not have much spare I/O capacity, it might be helpful to throttle the rate at which xtrabackup reads and writes data. You can do this with the <code>--throttle</code> option. This option limits the number of chunks copied per second. The chunk +size is 10 MB.</p> <p>The image below shows how throttling works when <code>--throttle</code> is set to <code>1</code>.</p> <p></p> <p>When specified with the <code>--backup</code> option, this option limits the number of pairs of read-and-write operations per second that xtrabackup will perform. If you are creating an incremental backup, then the limit is the number of read I/O operations per second.</p> <p>By default, there is no throttling, and xtrabackup reads and writes data as quickly as it can. If you set too strict of a limit on the IOPS, the backup might be so slow that it will never catch up with the transaction logs that InnoDB is writing, so the backup might never complete.</p>"},{"location":"throttling-backups.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"toolkit-version-check.html","title":"Percona Toolkit version checking","text":"<p>Some Percona software contains \u201cversion checking\u201d functionality which is a feature that enables Percona software users to be notified of available software updates to improve your environment security and performance. Alongside this, the version check functionality also provides Percona with information relating to which software versions you are running, coupled with the environment confirmation which the software is running within. This helps enable Percona to focus our development effort accordingly based on trends within our customer community.</p> <p>The purpose of this document is to articulate the information that is collected, as well as to provide guidance on how to disable this functionality if desired.</p>"},{"location":"toolkit-version-check.html#usage","title":"Usage","text":"<p>Version Check was implemented in Percona Toolkit 2.1.4, and was enabled by default in version 2.2.1. Currently, it is supported as a <code>--[no]version-check</code> option by a number of tools in Percona Toolkit, Percona XtraBackup, and Percona Monitoring and Management (PMM).</p> <p>When launched with Version Check enabled, the tool that supports this feature connects to a Percona\u2019s version check service via a secure HTTPS channel. It compares the locally installed version for possible updates, and also checks versions of the following software:</p> <ul> <li> <p>Operating System</p> </li> <li> <p>Percona Monitoring and Management (PMM)</p> </li> <li> <p>MySQL</p> </li> <li> <p>Perl</p> </li> <li> <p>MySQL driver for Perl (DBD::mysql)</p> </li> <li> <p>Percona Toolkit</p> </li> </ul> <p>Then it checks for and warns about versions with known problems if they are identified as running in the environment.</p> <p>Each version check request is logged by the server. Stored information consists of the checked system unique ID followed by the software name and version.  The ID is generated either at installation or when the version checking query is submitted for the first time.</p> <p>Note</p> <p>Prior to version 3.0.7 of Percona Toolkit, the system ID was calculated as an MD5 hash of a hostname, and starting from Percona Toolkit 3.0.7 it is generated as an MD5 hash of a random number. Percona XtraBackup continues to use hostname-based MD5 hash.</p> <p>As a result, the content of the sent query is as follows:</p> Expected output <pre><code>85624f3fb5d2af8816178ea1493ed41a;DBD::mysql;4.044\nc2b6d625ef3409164cbf8af4985c48d3;MySQL;MySQL Community Server (GPL) 5.7.22-log\n85624f3fb5d2af8816178ea1493ed41a;OS;Manjaro Linux\n85624f3fb5d2af8816178ea1493ed41a;Percona::Toolkit;3.0.11-dev\n85624f3fb5d2af8816178ea1493ed41a;Perl;5.26.2\n</code></pre>"},{"location":"toolkit-version-check.html#disabling-version-check","title":"Disabling version check","text":"<p>Although the version checking feature does not collect any personal information, you might prefer to disable this feature, either one time or permanently.  To disable it one time, use <code>--no-version-check</code> option when invoking the tool from a Percona product which supports it. Here is a simple example which shows running pt-diskstats tool from the Percona Toolkit with version checking turned off:</p> <pre><code>pt-diskstats --no-version-check\n</code></pre> <p>Disabling version checking permanently can be done by placing <code>no-version-check</code> option into the configuration file of a Percona product (see correspondent documentation for exact file name and syntax). For example, in case of Percona Toolkit this can be done in a global configuration file <code>/etc/percona-toolkit/percona-toolkit.conf</code>:</p> <pre><code># Disable Version Check for all tools:\nno-version-check\n</code></pre> <p>In case of Percona XtraBackup this can be done in its configuration file in a similar way:</p> <pre><code>[xtrabackup]\nno-version-check\n</code></pre>"},{"location":"toolkit-version-check.html#frequently-asked-questions","title":"Frequently asked questions","text":""},{"location":"toolkit-version-check.html#why-is-this-functionality-enabled-by-default","title":"Why is this functionality enabled by default?","text":"<p>We believe having this functionality enabled improves security and performance of environments running Percona Software and it is good choice for majority of the users.</p>"},{"location":"toolkit-version-check.html#why-not-rely-on-operating-systems-built-in-functionality-for-software-updates","title":"Why not rely on Operating System\u2019s built in functionality for software updates?","text":"<p>In many environments the Operating Systems repositories may not carry the latest version of software and newer versions of software often installed manually, so not being covered by operating system wide check for updates.</p>"},{"location":"toolkit-version-check.html#why-do-you-send-more-information-than-just-the-version-of-software-being-run-as-a-part-of-version-check-service","title":"Why do you send more information than just the version of software being run as a part of version check service?","text":"<p>Compatibility problems can be caused by versions of various components in the environment, for example problematic versions of Perl, DBD or MySQL could cause operational problems with Percona Toolkit.</p>"},{"location":"toolkit-version-check.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"trademark-policy.html","title":"Trademark policy","text":"<p>This Trademark Policy is to ensure that users of Percona-branded products or services know that what they receive has really been developed, approved, tested and maintained by Percona. Trademarks help to prevent confusion in the marketplace, by distinguishing one company\u2019s or person\u2019s products and services from another\u2019s.</p> <p>Percona owns a number of marks, including but not limited to Percona, XtraDB, Percona XtraDB, XtraBackup, Percona XtraBackup, Percona Server, and Percona Live, plus the distinctive visual icons and logos associated with these marks. Both the unregistered and registered marks of Percona are protected.</p> <p>Use of any Percona trademark in the name, URL, or other identifying characteristic of any product, service, website, or other use is not permitted without Percona\u2019s written permission with the following three limited exceptions.</p> <p>First, you may use the appropriate Percona mark when making a nominative fair use reference to a bona fide Percona product.</p> <p>Second, when Percona has released a product under a version of the GNU General Public License (\u201cGPL\u201d), you may use the appropriate Percona mark when distributing a verbatim copy of that product in accordance with the terms and conditions of the GPL.</p> <p>Third, you may use the appropriate Percona mark to refer to a distribution of GPL-released  Percona software that has been modified with minor changes for the sole purpose of allowing the software to operate on an operating system or hardware platform for which Percona has not yet released the software, provided that those third party changes do not affect the behavior, functionality, features, design or performance of the software. Users who acquire this Percona-branded software receive substantially exact implementations of the Percona software.</p> <p>Percona reserves the right to revoke this authorization at any time in its sole discretion. For example, if Percona believes that your modification is beyond the scope of the limited license granted in this Policy or that your use of the Percona mark is detrimental to Percona, Percona will revoke this authorization. Upon revocation, you must immediately cease using the applicable Percona mark. If you do not immediately cease using the Percona mark upon revocation, Percona may take action to protect its rights and interests in the Percona mark. Percona does not grant any license to use any Percona mark for any other modified versions of Percona software; such use will require our prior written permission.</p> <p>Neither trademark law nor any of the exceptions set forth in this Trademark Policy permit you to truncate, modify or otherwise use any Percona mark as part of your own brand. For example, if XYZ creates a modified version of the Percona Server, XYZ may not brand that modification as \u201cXYZ Percona Server\u201d or \u201cPercona XYZ Server\u201d, even if that modification otherwise complies with the third exception noted above.</p> <p>In all cases, you must comply with applicable law, the underlying license, and this Trademark Policy, as amended from time to time. For instance, any mention of Percona trademarks should include the full trademarked name, with proper spelling and capitalization, along with attribution of ownership to Percona LLC and/or its affiliates. For example, the full proper name for XtraBackup is Percona XtraBackup. However, it is acceptable to omit the word \u201cPercona\u201d for brevity on the second and subsequent uses, where such omission does not cause confusion.</p> <p>In the event of doubt as to any of the conditions or exceptions outlined in this Trademark Policy, please contact trademarks@percona.com for assistance and we will do our very best to be helpful.</p>"},{"location":"trademark-policy.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"update-curl-utility.html","title":"Update curl utility","text":""},{"location":"update-curl-utility.html#update-the-curl-utility-in-debian-10","title":"Update the curl utility in Debian 10","text":"<p>The default curl version, 7.64.0, in Debian 10 has known issues when attempting to reuse an already closed connection. This issue directly affects <code>xbcloud</code> and users may see intermittent backup failures.</p> <p>For more details, see curl #3750 or curl #3763.</p> <p>Follow these steps to upgrade curl to version 7.74.0:</p> <ol> <li> <p>Edit the <code>/etc/apt/sources.list</code> to add the following:</p> <pre><code>deb http://ftp.de.debian.org/debian buster-backports main\n</code></pre> </li> <li> <p>Refresh the <code>apt</code> sources:</p> <pre><code>$ sudo apt update\n</code></pre> </li> <li> <p>Install the version from <code>buster-backports</code>:</p> <pre><code>$ sudo apt install curl/buster-backports\n</code></pre> </li> <li> <p>Verify the version number:</p> <pre><code>$ curl --version\n</code></pre> Expected output <pre><code>curl 7.74.0 (x86_64-pc-linux-gnu) libcurl/7.74.0\n</code></pre> </li> </ol>"},{"location":"update-curl-utility.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"varify-backup.html","title":"Verify backups with replication and pt-checksum","text":"<p>One way to verify if the backup is consistent is by setting up the replication and running pt-table-checksum. This can be used to verify any type of backups, but before setting up replication, backup should be prepared and be able to run (this means that incremental backups should be merged to full backups, encrypted backups decrypted etc.).</p>"},{"location":"varify-backup.html#set-up-the-replication","title":"Set up the replication","text":"<p>How to set up a replica for replication in 6 simple steps with Percona XtraBackup guide provides a detailed instructions on how to take the backup and set up the replication.</p> <p>For checking the backup consistency you can use either the original server where the backup was taken, or another test server created by using a different backup method (such as cold backup, mysqldump or LVM snapshots) as the source server in the replication setup.</p>"},{"location":"varify-backup.html#use-pt-table-checksum","title":"Use pt-table-checksum","text":"<p>This tool is part of the Percona Toolkit. It performs an online replication consistency check by executing checksum queries on the source, which produces different results on replicas that are inconsistent with the source.</p> <p>After you confirmed that replication has been set up successfully, you can install or download pt-table-checksum. This example shows downloading the latest version of pt-table-checksum:</p> <pre><code>$ wget percona.com/get/pt-table-checksum\n</code></pre> <p>Note</p> <p>In order for pt-table-checksum to work correctly <code>libdbd-mysql-perl</code> will need to be installed on Debian/Ubuntu systems or <code>perl-DBD-MySQL</code> on RHEL/CentOS. If you installed the percona-toolkit package from the Percona repositories package manager should install those libraries automatically.</p> <p>After this command has been run, pt-table-checksum will be downloaded to your current working directory.</p> <p>Running the pt-table-checksum on the source will create <code>percona</code> database with the <code>checksums</code> table which will be replicated to the replicas as well. Example of the pt-table-checksum will look like this:</p> <pre><code>$ ./pt-table-checksum\n</code></pre> <p>The results are similar to the following:</p> Expected output <pre><code>TS ERRORS  DIFFS     ROWS  CHUNKS SKIPPED    TIME TABLE\n04-30T11:31:50      0      0   633135       8       0   5.400 exampledb.aka_name\n04-30T11:31:52      0      0   290859       1       0   2.692 exampledb.aka_title\nChecksumming exampledb.user_info:  16% 02:27 remain\nChecksumming exampledb.user_info:  34% 01:58 remain\nChecksumming exampledb.user_info:  50% 01:29 remain\nChecksumming exampledb.user_info:  68% 00:56 remain\nChecksumming exampledb.user_info:  86% 00:24 remain\n04-30T11:34:38      0      0 22187768     126       0 165.216 exampledb.user_info\n04-30T11:38:09      0      0        0       1       0   0.033 mysql.time_zone_name\n04-30T11:38:09      0      0        0       1       0   0.052 mysql.time_zone_transition\n04-30T11:38:09      0      0        0       1       0   0.054 mysql.time_zone_transition_type\n04-30T11:38:09      0      0        8       1       0   0.064 mysql.user\n</code></pre> <p>If all the values in the <code>DIFFS</code> column are 0 that means that backup is consistent with the current setup.</p> <p>In case backup was not consistent  pt-table-checksum should spot the difference and point to the table that does not match. Following example shows adding new user on the backed up replica in order to simulate the inconsistent backup:</p> <pre><code>mysql&gt; grant usage on exampledb.* to exampledb@localhost identified by 'thisisnewpassword';\n</code></pre> <p>If we run the pt-table-checksum now difference should be spotted</p> <pre><code>$ ./pt-table-checksum\n</code></pre> <p>The results are similar to the following:</p> Expected output <pre><code>TS ERRORS  DIFFS     ROWS  CHUNKS SKIPPED    TIME TABLE\n04-30T11:31:50      0      0   633135       8       0   5.400 exampledb.aka_name\n04-30T11:31:52      0      0   290859       1       0   2.692 exampledb.aka_title\nChecksumming exampledb.user_info:  16% 02:27 remain\nChecksumming exampledb.user_info:  34% 01:58 remain\nChecksumming exampledb.user_info:  50% 01:29 remain\nChecksumming exampledb.user_info:  68% 00:56 remain\nChecksumming exampledb.user_info:  86% 00:24 remain\n04-30T11:34:38      0      0 22187768     126       0 165.216 exampledb.user_info\n04-30T11:38:09      0      0        0       1       0   0.033 mysql.time_zone_name\n04-30T11:38:09      0      0        0       1       0   0.052 mysql.time_zone_transition\n04-30T11:38:09      0      0        0       1       0   0.054 mysql.time_zone_transition_type\n04-30T11:38:09      1      0        8       1       0   0.064 mysql.user\n</code></pre> <p>This output shows that source and the replica aren\u2019t in consistent state and that the difference is in the <code>mysql.user</code> table.</p> <p>More information on different options that pt-table-checksum provides can be found in the pt-table-checksum documentation.</p>"},{"location":"varify-backup.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"work-with-apparmor.html","title":"Work with AppArmor","text":"<p>The Linux Security Module implements mandatory access controls (MAC) with AppArmor. Debian and Ubuntu systems install AppArmor by default. AppArmor uses profiles which define which files and permissions are needed for application.</p> <p>Percona XtraBackup does not have a profile and is not confined by AppArmor.</p> <p>For a list of common AppArmor commands, see Percona Server for MySQL - AppArmor.</p>"},{"location":"work-with-apparmor.html#develop-a-profile","title":"Develop a profile","text":"<p>Download the profile from:</p> <p>https://github.com/percona/percona-xtrabackup/tree/trunk/packaging/percona/apparmor/apparmor.d</p> <p>The following profile sections should be updated with your system information, such as location of the backup destination directory.</p> Expected output <pre><code># enable storing backups only in /backups directory\n# /backups/** rwk,\n\n# enable storing backups anywhere in caller user home directory\n/@{HOME}/** rwk,\n\n\n# enable storing backups only in /backups directory\n# /backups/** rwk,\n\n# enable storing backups anywhere in caller user home directory\n/@{HOME}/** rwk,\n}\n\n# enable storing backups only in /backups directory\n# /backups/** rwk,\n\n# enable storing backups anywhere in caller user home directory\n/@{HOME}/** rwk,\n}\n</code></pre> <p>Move the updated file:</p> <pre><code>$ sudo mv usr.sbin.xtrabackup /etc/apparmor.d/\n</code></pre> <p>Install the profile with the following command:</p> <pre><code>$ sudo apparmor_parser -r -T -W /etc/apparmor.d/usr.sbin.xtrabackup\n</code></pre> <p>Run the backup as usual.</p> <p>No additional AppArmor-related actions are required to restore a backup.</p>"},{"location":"work-with-apparmor.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"work-with-selinux.html","title":"Work with SELinux","text":"<p>Percona XtraBackup is installed as an unconfined process running in an undefined domain. SELinux allows unconfined processes almost all access and the processes only use Discretionary Access Control (DAC) rules.</p> <p>You find the current state of the Percona XtraBackup file with the following command:</p> <pre><code>$ ls -Z /usr/bin | grep xtrabackup\n</code></pre> Expected output <pre><code>-rwxr-xr-x. root root   system_u:object_r:bin_t:s0       xtrabackup\n</code></pre> <p>The SELinux context is the following:</p> <ul> <li> <p>user (root)</p> </li> <li> <p>role (object_r)</p> </li> <li> <p>type (bin_t)</p> </li> <li> <p>level (s0)</p> </li> </ul> <p>The unconfined domain supports the network-facing services, which are protected by SELinux. These domains are not exposed. In this configuration, SELinux protects against remote intrusions but local intrusions, which require local access, are not confined.</p> <p>Percona XtraBackup works locally. The service is not network-facing and cannot be exploited externally. The service interacts only with the local user, who provides the parameters. Percona XtraBackup requires access to the <code>target-dir</code> location.</p>"},{"location":"work-with-selinux.html#confine-xtrabackup","title":"Confine XtraBackup","text":"<p>You can modify your security configuration to confine Percona XtraBackup. The first question is where to store the backup files. The service requires read and write access to the selected location.</p> <p>You can use either of the following methods:</p> <ul> <li> <p>Allow Percona XtraBackup to write to any location. The user provides any path to the <code>target-dir</code> parameter.</p> </li> <li> <p>Allow Percona XtraBackup to write to a specific location, such as /backups or the user\u2019s home directory.</p> </li> </ul> <p>The first option opens the entire system to read and write. Select the second option to harden your security.</p>"},{"location":"work-with-selinux.html#install-selinux-tools","title":"Install SELinux tools","text":"<p>To work with policies, you must install the SELinux tools. To find which package provides the <code>semanage</code> command and install the package. The following is an example on CentOS 7.</p> <p><pre><code>$ yum provides *bin/semanage\n</code></pre> The result should list the packages.</p> Expected output <pre><code>...\npolicycoreutils-python-2.5-34.el7.x86_64 : SELinux policy core python utilities\n...\n</code></pre> <p>To install missing packages, run the following:</p> <pre><code>$ sudo yum install -y policycoreutils-python\n</code></pre> <p>The following is an example on CentOS 8:</p> <p><pre><code>$ yum provides *bin/semanage\n</code></pre> The result should list the missing packages.</p> Expected output <pre><code>...\npolicycoreutils-python-utils-2.8-16.1.el8.noarch : SELinux policy core python utilities\n</code></pre> <p>Run the following to install the missing packages: </p> <pre><code>$ sudo yum install -y policycoreutils-python-utils\n</code></pre>"},{"location":"work-with-selinux.html#create-a-policy","title":"Create a policy","text":"<p>Use a modular approach to create an SELinux policy. Create a policy module to manage XtraBackup. You must create a <code>.te</code> file for type enforcement, and an optional <code>.fc</code> file for the file contexts.</p> <p>Use <code>$ ps -efZ | grep xtrabackup</code> to verify the service is not confined by SELinux.</p> <p>Create the <code>xtrabackup.fc</code> file and add content. This file defines the security contexts.</p> <pre><code>/usr/bin/xtrabackup    -- gen_context(system_u:object_r:xtrabackup_exec_t,s0)\n/usr/bin/xbcrypt    -- gen_context(system_u:object_r:xtrabackup_exec_t,s0)\n/usr/bin/xbstream    -- gen_context(system_u:object_r:xtrabackup_exec_t,s0)\n/usr/bin/xbcloud    -- gen_context(system_u:object_r:xtrabackup_exec_t,s0)\n/backups(/.*)?       system_u:object_r:xtrabackup_data_t:s0\n</code></pre> <p>Note</p> <p>If you are using the <code>/backups</code> directory you must have the last line. If you are storing the backups in the user\u2019s home directory, you can omit this line.</p> <p>Download the <code>xtrabackup.te</code> file from the following location:</p> <p>https://github.com/percona/percona-xtrabackup/tree/trunk/packaging/percona/selinx</p> <p>Note</p> <p>In the file, the sections in bold should be modified for your system. The fc file can also be downloaded from the same location.</p> <p>Compile the policy module:</p> <pre><code>$ make -f /usr/share/selinux/devel/Makefile xtrabackup.pp\n</code></pre> <p>Install the module:</p> <pre><code>$ semodule -i xtrabackup.pp\n</code></pre> <p>Tag the PXB binaries with the proper SELinux tags, such as <code>xtrabackup_exec_t</code>.</p> <pre><code>$ restorecon -v /usr/bin/*\n</code></pre> <p>If you store your backups at <code>/backups</code>, restore the tag in that location:</p> <pre><code>$ restorecon -v /backups\n</code></pre> <p>Note</p> <p>Remember to add the standard Linux DAC permissions for this directory.</p> <p>Perform the backup in the standard way.</p>"},{"location":"work-with-selinux.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"working-with-binary-logs.html","title":"Work with binary logs","text":"<p>The <code>xtrabackup</code> binary integrates with the <code>log_status table</code>. This integration enables <code>xtrabackup</code> to print out the backup\u2019s corresponding binary log position, so that you can use this binary log position to provision a new replica or perform point-in-time recovery.</p>"},{"location":"working-with-binary-logs.html#find-the-binary-log-position","title":"Find the binary log position","text":"<p>You can find the binary log position corresponding to a backup after the backup has been taken. If your backup is from a server with binary logging enabled, <code>xtrabackup</code> creates a file named <code>xtrabackup_binlog_info</code> in the target directory. This file contains the binary log file name and position of the exact point when the backup was taken.</p> Expected output during the backup stage <pre><code>210715 14:14:59 Backup created in directory '/backup/'\nMySQL binlog position: filename 'binlog.000002', position '156'\n. . .\n210715 14:15:00 completed OK!\n</code></pre>"},{"location":"working-with-binary-logs.html#point-in-time-recovery","title":"Point-in-time recovery","text":"<p>To perform a point-in-time recovery from an <code>xtrabackup</code> backup, you should prepare and restore the backup, and then replay binary logs from the point shown in the <code>xtrabackup_binlog_info</code> file.</p> <p>Find a more detailed procedure in the Point-in-time recovery document.</p>"},{"location":"working-with-binary-logs.html#set-up-a-new-replication-replica","title":"Set up a new replication replica","text":"<p>To set up a new replica, you should prepare the backup, and restore it to the data directory of your new replication replica. In the CHANGE_REPLICATION_SOURCE_TO with the appropriate options command, use the binary log filename and position shown in the <code>xtrabackup_binlog_info</code> file to start replication.</p> <p>A more detailed procedure is found in  How to setup a replica for replication in 6 simple steps with Percona XtraBackup.</p>"},{"location":"working-with-binary-logs.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"xbcloud-azure.html","title":"Use the xbcloud binary with Microsoft Azure Cloud Storage","text":"<p>The xbcloud binary adds support for the Microsoft Azure Cloud Storage using the REST API.</p>"},{"location":"xbcloud-azure.html#options","title":"Options","text":"<p>The following are the options, environment variables, and descriptions for uploading a backup to Azure using the REST API. The environment variables are recognized by xbcloud, which maps them automatically to the corresponding parameters:</p> Option name Environment variables Description \u2013azure-storage-account=name AZURE_STORAGE_ACCOUNT An Azure storage account is a unique namespace to access and store your Azure data objects. \u2013azure-container-name=name AZURE_CONTAINER_NAME A container name is a valid DNS name that conforms to the Azure naming rules \u2013azure-access-key=name AZURE_ACCESS_KEY A generated key that can be used to authorize access to data in your account using the Shared Key authorization. \u2013azure-endpoint=name AZURE_ENDPOINT The endpoint allows clients to securely access data \u2013azure-tier-class=name AZURE_STORAGE_CLASS Cloud tier can decrease the local storage required while maintaining the performance. When enabled, this feature has the following categories: Hot - Frequently accessed or modified data Cool - Infrequently accessed or modified data Archive - Rarely accessed or modified data <p>Test your Azure applications with the Azurite open-source emulator. For testing purposes, the xbcloud binary adds the <code>--azure-development-storage</code> option that uses the default <code>access_key</code> and <code>storage account</code> of azurite and <code>testcontainer</code> for the container. You can overwrite these options, if needed.</p>"},{"location":"xbcloud-azure.html#usage","title":"Usage","text":"<p>All the available options for xbcloud, such as parallel,  max-retries, and others, can be used. For more information, see the xbcloud binary overview.</p>"},{"location":"xbcloud-azure.html#examples","title":"Examples","text":"<p>An example of an xbcloud backup.</p> <pre><code>$ xtrabackup --backup --stream=xbstream  | \nxbcloud put backup_name --azure-storage-account=pxbtesting --azure-access-key=$AZURE_KEY --azure-container-name=test --storage=azure\n</code></pre> <p>An example of restoring a backup from xbcloud.</p> <pre><code>$ xbcloud get backup_name  --azure-storage-account=pxbtesting \n--azure-access-key=$AZURE_KEY --azure-container-name=test --storage=azure --parallel=10 2&gt;download.log | xbstream -x -C restore\n</code></pre> <p>An example of deleting a backup from xbcloud.</p> <pre><code>$ xbcloud delete backup_name --azure-storage-account=pxbtesting \n--azure-access-key=$AZURE_KEY --azure-container-name=test --storage=azure\n</code></pre> <p>An example of using a shortcut restore.</p> <pre><code>$ xbcloud get azure://operator-testing/bak22 ...\n</code></pre>"},{"location":"xbcloud-azure.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"xbcloud-binary-fifo-datasink.html","title":"FIFO data sink","text":"<p>The feature is in tech preview.</p> <p>Percona XtraBackup implements a data sink that uses the first in, first out (FIFO) method. With the <code>FIFO</code> data sink feature, users with a streaming capacity of 10Gbps (typically on a Local Area Network (LAN)) can benefit from faster backups by streaming data in parallel to an object storage.</p>"},{"location":"xbcloud-binary-fifo-datasink.html#fifo-data-sink-options","title":"FIFO data sink options","text":"<p>Percona XtraBackup implements the following options:</p> <ul> <li><code>--fifo-streams=#</code> - specifies the number of FIFO files to use for parallel data stream. To disable FIFO data sink and send stream to STDOUT, set <code>--fifo-streams=1</code>. The default value is <code>1</code> (STDOUT) to ensure the backward compatibility. The <code>--fifo-streams</code> value must match on both the XtraBackup and xbcloud sides.</li> <li><code>--fifo-dir=name</code> - specifies a directory to write Named Pipe.</li> <li><code>--fifo-timeout=#</code> - specifies the number of seconds to wait for the other end to open the stream for reading. The default value is <code>60</code> seconds.</li> </ul>"},{"location":"xbcloud-binary-fifo-datasink.html#how-to-enable-fifo-data-sink","title":"How to enable FIFO data sink","text":"<p>To use FIFO data sink, you can either run two commands in separate terminal sessions or run xtrabackup in the background.</p> <p>For example, run the following commands in separate terminal sessions:</p> <pre><code>$ xtrabackup --backup --stream --fifo-streams=2 --fifo-dir=/tmp/fifo\n</code></pre> <pre><code>$ xbcloud put --fifo-streams=2 --fifo-dir=/tmp/fifo full\n</code></pre> <p>Run xtrabackup in the background with the following commands:</p> <pre><code>$ xtrabackup --backup --stream --fifo-streams=2 --fifo-dir=/tmp/fifo &amp;\n$ xbcloud put --fifo-streams=2 --fifo-dir=/tmp/fifo full\n</code></pre>"},{"location":"xbcloud-binary-fifo-datasink.html#stream-to-an-object-storage","title":"Stream to an object storage","text":"<p>When taking a backup, you can save the files locally or stream the files to either a different server or an object storage. </p> <p>When you stream backups to Amazon S3 compatible storage using LAN with a streaming capacity of 10Gbps, XtraBackup can use multiple FIFO streams to stream the backups faster. </p> <p>XtraBackup spawns multiple copy threads and each copy thread reads a data chunk from a specific file. Then multiple FIFO files are created to store the data from XtraBackup. Each XtraBackup copy thread writes the data chunks to a specific FIFO file. Xbcloud reads from the FIFO streams and uploads data to an object storage using an async request. The xbcloud event handler executes the callback depending on the response from the object storage (success or failure). </p> <p></p>"},{"location":"xbcloud-binary-fifo-datasink.html#performance-improvement","title":"Performance improvement","text":"<p>Consider an example of using a FIFO data sink compared to the STDOUT method.</p> <p>The database has 1TB of data in multiple tables. The link speed between the source server and destination server using MinIO is ~ 9.2 Gbps.</p> <p>Both STDOUT and FIFO data sink scenarios push 1TB of data from two servers.</p> <p>For the FIFO data sink we configure 8 parallel streams with <code>--fifo-streams=8</code> both for XtraBackup and xbcloud.</p> <p>The results are the following:</p> <ul> <li>The <code>STDOUT</code> method takes 01:25:24 to push 1TB of data using 239 MBps (1.8 Gbps).</li> <li>The <code>FIFO</code> method, using 8 streams, takes 00:16:01 to push 1TB of data using 1.15 GBps (9.2 Gbps).</li> </ul>"},{"location":"xbcloud-binary-fifo-datasink.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"xbcloud-binary-overview.html","title":"The xbcloud binary overview","text":"<p>The purpose of xbcloud is to download from the cloud and upload to  the cloud the full or part of an xbstream archive. xbcloud will not  overwrite the backup with the same name. xbcloud accepts input via a pipe from xbstream so that it can be invoked as a pipeline with xtrabackup to stream directly to the cloud without needing a local storage.</p> <p>Note</p> <p>In a Bash shell, the <code>$?</code> parameter returns the exit code from the last binary. If you use pipes, the ${PIPESTATUS[x]} array parameter returns the exit code for each  binary in the pipe string.</p> <pre><code>$ xtrabackup --backup --stream=xbstream --target-dir=/storage/backups/ | xbcloud put [options] full_backup\n...\n$ ${PIPESTATUS[x]}\n0 0\n$ true | false\n$ echo $?\n1\n\n# with PIPESTATUS\n$ true | false\n$ echo ${PIPESTATUS[0]} ${PIPESTATUS[1]}\n0 1\n</code></pre> <p>The xbcloud binary stores each chunk as a separate object with a name <code>backup_name/database/table.ibd.NNN...</code>, where <code>NNN...</code> is a 0-padded serial number of chunk within a file. The size of chunk produced by xtrabackup and xbstream changed to 10M.</p> <p>To adjust the chunk size use <code>--read-buffer-size</code>. To adjust the chunk size for encrypted files, use <code>--read-buffer-size</code> and <code>--encrypt-chunk-size</code>.</p> <p>xbcloud has three essential operations: put, get, and delete. With these operations, backups are created, stored, retrieved, restored, and deleted. xbcloud operations clearly map to similar operations within  the AWS Amazon S3 API.</p> <p>The Exponential Backoff feature increases the chances for the completion of a backup or a restore operation. When taking a backup, a chunk upload or download may fail if you have an unstable network connection or other network issues. This feature adds an exponential backoff, a sleep time, and retries the operations.</p> <p>With the FIFO data sink feature, users with a streaming capacity of 10Gbps (typically on a Local Area Network (LAN)) can benefit from faster backups by streaming data in parallel to object storage.</p> <p>Important</p> <p>To prevent intermittent backup failures, update the curl utility in Debian 10.</p>"},{"location":"xbcloud-binary-overview.html#supported-cloud-storage-types","title":"Supported cloud storage types","text":"<p>The following cloud storage types are supported:</p> <ul> <li> <p>OpenStack Object Storage (Swift) - see Using the xbcloud binary with Swift</p> </li> <li> <p>Amazon Simple Storage (S3) - see Using the xbcloud binary with Amazon S3</p> </li> <li> <p>Azure Cloud Storage - see Using the xbcloud binary with Microsoft Azure Cloud Storage</p> </li> <li> <p>Google Cloud Storage (gcs) - see Using the xbcloud binary with Google Cloud Storage</p> </li> <li> <p>MinIO - see Using the xbcloud binary with MinIO</p> </li> </ul> <p>In addition to OpenStack Object Storage (Swift), which has been the only option for storing backups in a cloud storage until Percona XtraBackup 2.4.14, xbcloud supports Amazon S3, MinIO, and Google Cloud Storage. Other Amazon S3-compatible storages, such as Wasabi or Digital Ocean Spaces, are also supported.</p> <p>See also</p> <p>OpenStack Object Storage(\u201cSwift\u201d)</p> <p>Amazon Simple Storage Service</p> <p>MinIO</p> <p>Google Cloud Storage</p> <p>Wasabi</p> <p>Digital Ocean Spaces</p>"},{"location":"xbcloud-binary-overview.html#usage","title":"Usage","text":"<p>The following sample command creates a full backup:</p> <pre><code>$ xtrabackup --backup --stream=xbstream --target-dir=/storage/backups/ --extra-lsndirk=/storage/backups/| xbcloud \\\nput [options] full_backup\n</code></pre> <p>An incremental backup only includes the changes since the last backup. The last backup can be either a full or incremental backup.</p> <p>The following sample command creates an incremental backup:</p> <pre><code>$ xtrabackup --backup --stream=xbstream --incremental-basedir=/storage/backups \\\n--target-dir=/storage/inc-backup | xbcloud  put [options] inc_backup\n</code></pre> <p>To prepare an incremental backup, you must first download the full backup with the following command:</p> <pre><code>$ xbcloud get [options] full_backup | xbstream -xv -C /tmp/full-backup\n</code></pre> <p>You must prepare the full backup:</p> <pre><code>$ xtrabackup --prepare --apply-log-only --target-dir=/tmp/full-backup\n</code></pre> <p>After the full backup has been prepared, download the incremental backup:</p> <pre><code>xbcloud get [options] inc_backup | xbstream -xv -C /tmp/inc-backup\n</code></pre> <p>The downloaded backup is prepared by running the following command:</p> <pre><code>$ xtrabackup --prepare --target-dir=/tmp/full-backup --incremental-dir=/tmp/inc-backup\n</code></pre> <p>You do not need the full backup to restore only a specific database. You can specify only the tables to be restored:</p> <p><pre><code>xbcloud get [options] ibdata1 sakila/payment.ibd /tmp/partial/partial.xbs\n</code></pre> An example of the code: </p> <pre><code>xbstream -xv -C /tmp/partial &lt; /tmp/partial/partial.xbs\n</code></pre>"},{"location":"xbcloud-binary-overview.html#supplying-parameters","title":"Supplying parameters","text":"<p>Each storage type has mandatory parameters that you can supply on the command line, in a configuration file, and via environment variables.</p>"},{"location":"xbcloud-binary-overview.html#configuration-files","title":"Configuration files","text":"<p>The parameters the values of which do not change frequently can be stored in <code>my.cnf</code> or in a custom configuration file. The following example is a template of configuration options under the <code>[xbcloud]</code> group:</p> <pre><code>[xbcloud]\nstorage=s3\ns3-endpoint=http://localhost:9000/\ns3-access-key=minio\ns3-secret-key=minio123\ns3-bucket=backupsx\ns3-bucket-lookup=path\ns3-api-version=4\n</code></pre> <p>Note</p> <p>If you explicitly use a parameter on the command line and in a configuration file, xbcloud uses the value provided on the command line.</p>"},{"location":"xbcloud-binary-overview.html#environment-variables","title":"Environment variables","text":"<p>If you explicitly use a parameter on the command line, in a configuration file, and the corresponding environment variable contains a value, xbcloud uses the value provided on the command line or in the configuration file.</p>"},{"location":"xbcloud-binary-overview.html#shortcuts","title":"Shortcuts","text":"<p>For all operations (put, get, and delete), you can use a shortcut to specify the storage type, bucket name, and backup name as one parameter instead of using three distinct parameters (\u2013storage, \u2013s3-bucket, and backup name per se).</p> <p>Note</p> <p>Use the following format: <code>storage-type://bucket-name/backup-name</code></p> <p>In this example s3 refers to a storage type, operator-testing  is a bucket name, and bak22 is the backup name. </p> <pre><code>$ xbcloud get s3://operator-testing/bak22 ...\n</code></pre> <p>This shortcut expands as follows:</p> <pre><code>$ xbcloud get --storage=s3 --s3-bucket=operator-testing bak22 ...\n</code></pre> <p>You can supply the mandatory parameters on the command line, configuration files, and in environment variables.</p>"},{"location":"xbcloud-binary-overview.html#additional-parameters","title":"Additional parameters","text":"<p>xbcloud accepts additional parameters that you can use with any storage type. The <code>--md5</code> parameter computes the MD5 hash value of the backup chunks. The result is stored in files that following the <code>backup_name.md5</code> pattern.</p> <pre><code>$ xtrabackup --backup --stream=xbstream \\\n--parallel=8 2&gt;backup.log | xbcloud put s3://operator-testing/bak22 \\\n--parallel=8 --md5 2&gt;upload.log\n</code></pre> <p>You may use the <code>--header</code> parameter to pass an additional HTTP header with the server side encryption while specifying a customer key.</p> <p>An example of using the <code>--header</code> for AES256 encryption.</p> <pre><code>$ xtrabackup --backup --stream=xbstream --parallel=4 | \\\nxbcloud put s3://operator-testing/bak-enc/ \\\n--header=\"X-Amz-Server-Side-Encryption-Customer-Algorithm: AES256\" \\\n--header=\"X-Amz-Server-Side-Encryption-Customer-Key: CuStoMerKey=\" \\\n--header=\"X-Amz-Server-Side-Encryption-Customer-Key-MD5: CuStoMerKeyMd5==\" \\\n--parallel=8\n</code></pre> <p>The <code>--header</code> parameter is also useful to set the access control list (ACL) permissions: <code>--header=\"x-amz-acl: bucket-owner-full-control</code></p>"},{"location":"xbcloud-binary-overview.html#incremental-backups","title":"Incremental backups","text":"<p>First, you need to make the full backup on which the incremental one is going to be based:</p> <pre><code>$ xtrabackup --backup --stream=xbstream --extra-lsndir=/storage/backups/ \\\n--target-dir=/storage/backups/ | xbcloud put \\\n--storage=swift --swift-container=test_backup \\\n--swift-auth-version=2.0 --swift-user=admin \\\n--swift-tenant=admin --swift-password=xoxoxoxo \\\n--swift-auth-url=http://127.0.0.1:35357/ --parallel=10 \\\nfull_backup\n</code></pre> <p>Then you can make the incremental backup:</p> <pre><code>$ xtrabackup --backup --incremental-basedir=/storage/backups \\\n--stream=xbstream --target-dir=/storage/inc_backup | xbcloud put \\\n--storage=swift --swift-container=test_backup \\\n--swift-auth-version=2.0 --swift-user=admin \\\n--swift-tenant=admin --swift-password=xoxoxoxo \\\n--swift-auth-url=http://127.0.0.1:35357/ --parallel=10 \\\ninc_backup\n</code></pre>"},{"location":"xbcloud-binary-overview.html#preparing-incremental-backups","title":"Preparing incremental backups","text":"<p>To prepare a backup you first need to download the full backup:</p> <pre><code>$ xbcloud get --swift-container=test_backup \\\n--swift-auth-version=2.0 --swift-user=admin \\\n--swift-tenant=admin --swift-password=xoxoxoxo \\\n--swift-auth-url=http://127.0.0.1:35357/ --parallel=10 \\\nfull_backup | xbstream -xv -C /storage/downloaded_full\n</code></pre> <p>Once you download the full backup it should be prepared:</p> <pre><code>$ xtrabackup --prepare --apply-log-only --target-dir=/storage/downloaded_full\n</code></pre> <p>After the full backup has been prepared you can download the incremental backup:</p> <pre><code>$ xbcloud get --swift-container=test_backup \\\n--swift-auth-version=2.0 --swift-user=admin \\\n--swift-tenant=admin --swift-password=xoxoxoxo \\\n--swift-auth-url=http://127.0.0.1:35357/ --parallel=10 \\\ninc_backup | xbstream -xv -C /storage/downloaded_inc\n</code></pre> <p>Once the incremental backup has been downloaded you can prepare it by running:</p> <pre><code>$ xtrabackup --prepare --apply-log-only \\\n--target-dir=/storage/downloaded_full \\\n--incremental-dir=/storage/downloaded_inc\n\n$ xtrabackup --prepare --target-dir=/storage/downloaded_full\n</code></pre>"},{"location":"xbcloud-binary-overview.html#partial-download-of-the-cloud-backup","title":"Partial download of the cloud backup","text":"<p>If you do not want to download the entire backup to restore the specific database you can specify only the tables you want to restore:</p> <pre><code>$ xbcloud get --swift-container=test_backup\n--swift-auth-version=2.0 --swift-user=admin \\\n--swift-tenant=admin --swift-password=xoxoxoxo \\\n--swift-auth-url=http://127.0.0.1:35357/ full_backup \\\nibdata1 sakila/payment.ibd \\\n&gt; /storage/partial/partial.xbs\n\n$ xbstream -xv -C /storage/partial &lt; /storage/partial/partial.xbs\n</code></pre>"},{"location":"xbcloud-binary-overview.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"xbcloud-exbackoff.html","title":"Exponential backoff","text":"<p>Exponential backoff increases the chances for the completion of a backup or a restore operation. For example, a chunk upload or download may fail if you have an unstable network connection or other network issues. This feature adds an exponential backoff, or sleep, time and then retries the upload or download.</p> <p>When a chunk upload or download operation fails, xbcloud checks the reason for the failure. This failure can be a CURL error or an HTTP error, or a client-specific error. If the error is listed in the Retriable errors list, xbcloud pauses for a calculated time before retrying the operation until that time reaches the <code>--max-backoff</code> value.</p> <p>The operation is retried until the <code>--max-retries</code> value is reached. If the chunk operation fails on the last retry, xbcloud aborts the process.</p> <p>The default values are the following:</p> <ul> <li> <p>\u2013max-backoff = 300000 (5 minutes)</p> </li> <li> <p>\u2013max-retries = 10</p> </li> </ul> <p>You can adjust the number of retries by adding the <code>--max-retries</code> parameter and adjust the maximum length of time between retries by adding the <code>--max-backoff</code> parameter to an xbcloud command.</p> <p>Since xbcloud does multiple asynchronous requests in parallel, a calculated value, measured in milliseconds, is used for <code>max-backoff</code>. This algorithm calculates how many milliseconds to sleep before the next retry. A number generated is based on the combining the power of two (2), the number of retries already attempted and adds a random number between 1 and 1000. This number avoids network congestion if multiple chunks have the same backoff value. If the default values are used, the final retry attempt to be approximately 17 minutes after the first try. The number is no longer calculated when the milliseconds reach the <code>--max-backoff</code> setting. At that point, the retries continue by using the <code>--max-backoff</code> setting until the <code>max-retries</code> parameter is reached.</p>"},{"location":"xbcloud-exbackoff.html#retriable-errors","title":"Retriable errors","text":"<p>We retry for the following CURL operations:</p> <ul> <li> <p>CURLE_GOT_NOTHING</p> </li> <li> <p>CURLE_OPERATION_TIMEOUT</p> </li> <li> <p>CURLE_RECV_ERROR</p> </li> <li> <p>CURLE_SEND_ERROR</p> </li> <li> <p>CURLE_SEND_FAIL_REWIND</p> </li> <li> <p>CURLE_PARTIAL_FILE</p> </li> <li> <p>CURLE_SSL_CONNECT_ERROR</p> </li> </ul> <p>We retry for the following HTTP operation status codes:</p> <ul> <li> <p>503</p> </li> <li> <p>500</p> </li> <li> <p>504</p> </li> <li> <p>408</p> </li> </ul> <p>Each cloud provider may return a different CURL error or an HTTP error, depending on the issue. Add new errors by setting the following variables <code>--curl-retriable-errors</code> or <code>--http-retriable-errors</code> on the command line or in <code>my.cnf</code> or in a custom configuration file under the [xbcloud] section. You can add multiple errors using a comma-separated list of codes.</p> <p>The error handling is enhanced when using the <code>--verbose</code> output. This output specifies which error caused xbcloud to fail and what parameter a user must add to retry on this error.</p> <p>The following is an example of a verbose output:</p> Expected output <pre><code>210701 14:34:23 /work/pxb/ins/{{vers}}/bin/xbcloud: Operation failed. Error: Server returned nothing (no headers, no data)\n210701 14:34:23 /work/pxb/ins/{{vers}}/bin/xbcloud: Curl error (52) Server returned nothing (no headers, no data) is not configured as retriable. You can allow it by adding --curl-retriable-errors=52 parameter\n</code></pre>"},{"location":"xbcloud-exbackoff.html#example","title":"Example","text":"<p>The following example adjusts the maximum number of retries and the maximum time between retries.</p> <pre><code>xbcloud [options] --max-retries=5 --max-backoff=10000\n</code></pre> <p>The following list describes the process using <code>--max-backoff=10000</code>:</p> <ul> <li> <p>The chunk <code>xtrabackup_logfile.00000000000000000006</code> fails to upload the first time and sleeps for 2384 milliseconds.</p> </li> <li> <p>The same chunk fails for the second time and the sleep time is increased to 4387 milliseconds.</p> </li> <li> <p>The same chunk fails for the third time and the sleep time is increased to 8691 milliseconds.</p> </li> <li> <p>The same chunk fails for the fourth time. The <code>max-backoff</code> parameter has been reached. All retries sleep the same amount of time after reaching the parameter.</p> </li> <li> <p>The same chunk is successfully uploaded.</p> </li> </ul> An example of the output for this setting <pre><code>210702 10:07:05 /work/pxb/ins/{{vers}}/bin/xbcloud: Operation failed. Error: Server returned nothing (no headers, no data)\n210702 10:07:05 /work/pxb/ins/{{vers}}/bin/xbcloud: Sleeping for 2384 ms before retrying backup3/xtrabackup_logfile.00000000000000000006\n. . .\n210702 10:07:23 /work/pxb/ins/{{vers}}/bin/xbcloud: Operation failed. Error: Server returned nothing (no headers, no data)\n210702 10:07:23 /work/pxb/ins/{{vers}}/bin/xbcloud: Sleeping for 4387 ms before retrying backup3/xtrabackup_logfile.00000000000000000006\n. . .\n210702 10:07:52 /work/pxb/ins/{{vers}}/bin/xbcloud: Operation failed. Error: Failed sending data to the peer\n210702 10:07:52 /work/pxb/ins/{{vers}}/bin/xbcloud: Sleeping for 8691 ms before retrying backup3/xtrabackup_logfile.00000000000000000006\n. . .\n210702 10:08:47 /work/pxb/ins/{{vers}}/bin/xbcloud: Operation failed. Error: Failed sending data to the peer\n210702 10:08:47 /work/pxb/ins/{{vers}}/bin/xbcloud: Sleeping for 10000 ms before retrying backup3/xtrabackup_logfile.00000000000000000006\n. . .\n210702 10:10:12 /work/pxb/ins/{{vers}}/bin/xbcloud: successfully uploaded chunk: backup3/xtrabackup_logfile.00000000000000000006, size: 8388660\n</code></pre>"},{"location":"xbcloud-exbackoff.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"xbcloud-gcs.html","title":"Use the xbcloud binary with Google Cloud Storage","text":""},{"location":"xbcloud-gcs.html#create-a-full-backup-with-google-cloud-storage","title":"Create a full backup with Google Cloud Storage","text":"<p>The support for Google Cloud Storage is implemented using the interoperability mode. This mode was especially designed to interact with cloud services compatible with Amazon S3.</p> <p>See also</p> <p>Cloud Storage Interoperability</p> <pre><code>$ xtrabackup --backup --stream=xbstream --extra-lsndir=/tmp --target-dir=/tmp | \\\nxbcloud put --storage=google \\\n--google-endpoint=`storage.googleapis.com` \\\n--google-access-key='YOUR-ACCESSKEYID' \\\n--google-secret-key='YOUR-SECRETACCESSKEY' \\\n--google-bucket='mysql_backups'\n--parallel=10 \\\n$(date -I)-full_backup\n</code></pre> <p>The following options are available when using Google Cloud Storage:</p> <ul> <li> <p>\u2013google-access-key =  <li> <p>\u2013google-secret-key =  <li> <p>\u2013google-bucket =  <li> <p>\u2013google-storage-class=name</p> </li> <p>Note</p> <p>The Google storage class name options are the following:</p> <ul> <li> <p>STANDARD</p> </li> <li> <p>NEARLINE</p> </li> <li> <p>COLDLINE</p> </li> <li> <p>ARCHIVE</p> </li> </ul> <p>See also</p> <p>Google storage classes - the default Google storage class depends on  the storage class of the bucket</p>"},{"location":"xbcloud-gcs.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"xbcloud-iam-profile.html","title":"Use the xbcloud binary with an IAM instance profile","text":"<p>You can use the IAM instance profile when running xbcloud from an EC2 instance.</p> <p>An authentication system has two elements:</p> <ul> <li>Who am I?</li> <li>What can I do?</li> </ul> <p>A role defines \u201cwhat can I do.\u201d A role provides a method to define a collection of permissions. Roles are assigned to users, services and EC2 instances, the \u201cwho am I\u201d element.</p> <p>The IAM instance profile is the \u201cwho\u201d for an EC2 instance and assumes the IAM role, which has permissions. The instance profile has the same name as the IAM role.</p> <p>An IAM instance profile does not need the <code>--s3-secret-key</code> nor the <code>--s3-access-key</code> if they are running <code>xbcloud</code> from an Amazon EC2 instance. To configure or attach an instance metadata to an EC2 instance, see How can I grant my Amazon EC2 instance access to an Amazon S3 bucket. </p> <p>An example of the command:</p> <pre><code>$ xtrabackup ... | xbcloud put --storage=s3 --s3-bucket=bucket-name backup-name\n</code></pre> <p>The xbcloud binary outputs a connect message when successful.</p> Expected output <pre><code>221121 13:16:26 Using instance metadata for access and secret key\n221121 13:16:26 xbcloud: Successfully connected.\n</code></pre> <p>An important consideration is that the instance metadata has a time to live (TTL) of 6 hours. A backup that takes more than that time contains Expired token errors. Use Exponential Backoff to retry the upload after fetching new keys from the instance metadata.</p> Output when keys have expired <pre><code>221121 13:04:52 xbcloud: S3 error message: The provided token has expired.\n221121 13:04:52 xbcloud: Sleeping for 2384 ms before retrying test/mysql.ibd.00000000000000000002 [1]\n221121 13:04:55 xbcloud: S3 error message: The provided token has expired.\n221121 13:04:55 xbcloud: Sleeping for 2887 ms before retrying test/mysql.ibd.00000000000000000003 [1]\n221121 13:04:58 xbcloud: S3 error message: The provided token has expired.\n221121 13:04:58 xbcloud: Sleeping for 2778 ms before retrying test/undo_002.00000000000000000000 [1]\n221121 13:05:00 xbcloud: S3 error message: The provided token has expired.\n221121 13:05:00 xbcloud: Sleeping for 2916 ms before retrying test/undo_002.00000000000000000001 [1]\n221121 13:05:03 xbcloud: S3 error message: The provided token has expired.\n221121 13:05:03 xbcloud: Sleeping for 2794 ms before retrying test/undo_002.00000000000000000002 [1]\n221121 13:05:06 xbcloud: S3 error message: The provided token has expired.\n221121 13:05:06 xbcloud: Sleeping for 2336 ms before retrying test/undo_001.00000000000000000000 [1]\n221121 13:05:09 xbcloud: successfully uploaded chunk: test/mysql.ibd.00000000000000000002, size: 5242923\n221121 13:05:09 xbcloud: successfully uploaded chunk: test/mysql.ibd.00000000000000000003, size: 23\n221121 13:05:09 xbcloud: successfully uploaded chunk: test/undo_002.00000000000000000000, size: 10485802\n221121 13:05:09 xbcloud: successfully uploaded chunk: test/undo_002.00000000000000000001, size: 6291498\n221121 13:05:09 xbcloud: successfully uploaded chunk: test/undo_002.00000000000000000002, size: 22\n221121 13:05:09 xbcloud: successfully uploaded chunk: test/undo_001.00000000000000000000, size: 10485802\n221121 13:05:10 xbcloud: successfully uploaded chunk: test/undo_001.00000000000000000001, size: 6291498\n221121 13:05:10 xbcloud: successfully uploaded chunk: test/undo_001.00000000000000000002, size: 22\n. . .\n221121 13:05:18 xbcloud: successfully uploaded chunk: test/xtrabackup_tablespaces.00000000000000000001, size: 36\n221121 13:05:19 xbcloud: Upload completed. \n</code></pre>"},{"location":"xbcloud-iam-profile.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"xbcloud-minio.html","title":"Use the xbcloud binary with MinIO","text":""},{"location":"xbcloud-minio.html#create-a-full-backup-with-minio","title":"Create a full backup with MinIO","text":"<pre><code>$ xtrabackup --backup --stream=xbstream --extra-lsndir=/tmp --target-dir=/tmp | \\\nxbcloud put --storage=s3 \\\n--s3-endpoint='play.minio.io:9000' \\\n--s3-access-key='YOUR-ACCESSKEYID' \\\n--s3-secret-key='YOUR-SECRETACCESSKEY' \\\n--s3-bucket='mysql_backups'\n--parallel=10 \\\n$(date -I)-full_backup\n</code></pre>"},{"location":"xbcloud-minio.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"xbcloud-options.html","title":"The xbcloud command-line options","text":"<p>Usage: </p> <pre><code>$ xbcloud put [OPTIONS]\n$ xbcloud get [OPTIONS]\n$ xbcloud delete [OPTIONS]\n</code></pre> <p>This document contains information on general options and the options available when you select the Swift authentication version using <code>swift-auth-version</code>.</p> <p>The xbcloud binary has the following general command line options:</p>"},{"location":"xbcloud-options.html#azure-access-key","title":"azure-access-key","text":"<p>Usage: <code>--azure-access-key=name</code></p> <p>The name of the Azure access-key</p>"},{"location":"xbcloud-options.html#azure-container-name","title":"azure-container-name","text":"<p>Usage: <code>--azure-container-name=name</code></p> <p>The name of the Azure container</p>"},{"location":"xbcloud-options.html#azure-development-storage","title":"azure-development-storage","text":"<p>Usage: <code>--azure-development-storage=name</code></p> <p>If you run the Azurite emulator, use this option, and it works with the default credentials provided by Azurite. You can overwrite these default credentials with other options.</p>"},{"location":"xbcloud-options.html#azure-endpoint","title":"azure-endpoint","text":"<p>Usage: <code>--azure-endpoint=name</code></p> <p>The name of the Azure endpoint</p>"},{"location":"xbcloud-options.html#azure-storage-account","title":"azure-storage-account","text":"<p>Usage: <code>--azure-storage-account=name</code></p> <p>The name of the Azure storage account</p>"},{"location":"xbcloud-options.html#azure-tier-class","title":"azure-tier-class","text":"<p>Usage: <code>--azure-tier-class=name</code></p> <p>The name of the Azure tier-class. The possible values are:</p> <ul> <li> <p>Hot</p> </li> <li> <p>Cool</p> </li> <li> <p>Archive</p> </li> </ul>"},{"location":"xbcloud-options.html#cacert","title":"cacert","text":"<p>Usage: <code>--cacert=name</code></p> <p>The path to the file with Certificate Authority (CA) certificates.</p>"},{"location":"xbcloud-options.html#curl-retriable-errors","title":"curl-retriable-errors","text":"<p>Usage: <code>--curl-retriable-errors=name</code></p> <p>Add a new cURL error code as retriable. For multiple codes, use a comma-separated list.</p>"},{"location":"xbcloud-options.html#fifo-dir","title":"fifo-dir","text":"<p>Usage: <code>--fifo-dir=name</code></p> <p>The directory used to read or write named pipes. In the put mode, xbcloud reads from the named pipes. In the get mode, xbcloud writes to the named pipes.</p>"},{"location":"xbcloud-options.html#fifo-streams","title":"fifo-streams","text":"<p>Usage: <code>--fifo-streams=#</code></p> <p>The number of parallel FIFO stream threads.</p>"},{"location":"xbcloud-options.html#fifo-timeout","title":"fifo-timeout","text":"<p>Usage: <code>--fifo-timeout=#</code></p> <p>The number of seconds to wait for the other end to open the stream. The default value is 60.</p>"},{"location":"xbcloud-options.html#google-access-key","title":"google-access-key","text":"<p>Usage: <code>--google-access-key=name</code></p> <p>The Google Cloud storage access key</p>"},{"location":"xbcloud-options.html#google-bucket-name","title":"google-bucket-name","text":"<p>Usage: <code>--google-bucket-name=name</code></p> <p>The Google Cloud storage bucket name</p>"},{"location":"xbcloud-options.html#google-endpoint","title":"google-endpoint","text":"<p>Usage: <code>--google-endpoint=name</code></p> <p>The Google Cloud storage endpoint</p>"},{"location":"xbcloud-options.html#google-region","title":"google-region","text":"<p>Usage: <code>--google-region=name</code></p> <p>The Google Cloud storage region</p>"},{"location":"xbcloud-options.html#google-secret-key","title":"google-secret-key","text":"<p>Usage: <code>--google-secret-key=name</code></p> <p>The Google Cloud storage secret key</p>"},{"location":"xbcloud-options.html#google-session-token","title":"google-session-token","text":"<p>Usage: <code>--google-session-token=name</code></p> <p>The Google Cloud storage session-token</p>"},{"location":"xbcloud-options.html#google-storage-class","title":"google-storage-class","text":"<p>Usage: <code>--google-storage-class=name</code></p> <p>The Google Cloud storage storage class</p> <p>The possible values are the following:</p> <ul> <li> <p>STANDARD</p> </li> <li> <p>NEARLINE</p> </li> <li> <p>COLDLINE</p> </li> <li> <p>ARCHIVE</p> </li> </ul>"},{"location":"xbcloud-options.html#header","title":"header","text":"<p>Usage: <code>--header=name</code></p> <p>Extra header</p>"},{"location":"xbcloud-options.html#http-retriable-errors","title":"http-retriable-errors","text":"<p>Usage: <code>--http-retriable-errors=name</code></p> <p>Add a new http error code as retriable. For multiple codes, use a comma-separated list.</p>"},{"location":"xbcloud-options.html#insecure","title":"insecure","text":"<p>Usage: <code>--insecure</code></p> <p>Do not verify the certificate of the server.</p>"},{"location":"xbcloud-options.html#max-backoff","title":"max-backoff","text":"<p>Usage: <code>--max-backoff=#</code></p> <p>The maximum backoff delay, in milliseconds, between chunk upload or chunk download retries. The default value is 300000.</p>"},{"location":"xbcloud-options.html#max-retries","title":"max-retries","text":"<p>Usage: <code>--max-retires=#</code></p> <p>The number of retries for chunk uploads or downloads after a failure. The default value is 10.</p>"},{"location":"xbcloud-options.html#md5","title":"md5","text":"<p>Usage: <code>--md5=name</code></p> <p>Uploads an MD5 file into the backup directory.</p>"},{"location":"xbcloud-options.html#parallel","title":"parallel","text":"<p>Usage: <code>--parallel=#</code></p> <p>Defines the maximum number of concurrent upload/download requests. The default value is <code>1</code>.</p>"},{"location":"xbcloud-options.html#s3-access-key","title":"s3-access-key","text":"<p>Usage: <code>--s3-access-key=name</code></p> <p>The name of the s3 access key</p>"},{"location":"xbcloud-options.html#s3-api-version","title":"s3-api-version","text":"<p>Usage: <code>--s3-api-version=name</code></p> <p>The name of the s3 API version</p>"},{"location":"xbcloud-options.html#s3-bucket","title":"s3-bucket","text":"<p>Usage: <code>--s3-bucket=name</code></p> <p>The name of the s3 bucket</p>"},{"location":"xbcloud-options.html#s3-bucket-lookup","title":"s3-bucket-lookup","text":"<p>Usage: <code>--s3-bucket-lookup=name</code></p> <p>The name of the s3 bucket lookup method</p>"},{"location":"xbcloud-options.html#s3-endpoint","title":"s3-endpoint","text":"<p>Usage: <code>--s3-endpoint=name</code></p> <p>The name of the s3 endpoint</p>"},{"location":"xbcloud-options.html#s3-region","title":"s3-region","text":"<p>Usage: <code>--s3-region=name</code></p> <p>The name of the s3 region</p>"},{"location":"xbcloud-options.html#s3-secret-key","title":"s3-secret-key","text":"<p>Usage: <code>--s3-secret-key=name</code></p> <p>The name of the s3 secret key</p>"},{"location":"xbcloud-options.html#s3-session-token","title":"s3-session-token","text":"<p>Usage: <code>--s3-session-token=name</code></p> <p>The name of the s3 session token</p>"},{"location":"xbcloud-options.html#s3-storage-class","title":"s3-storage-class","text":"<p>Usage: <code>--s3-storage-class=name</code></p> <p>The name of the s3 storage class and is used to pass custom storage class names provided by the other s3 implementations, such as MinIO.</p> <p>The possible values are:</p> <ul> <li> <p>STANDARD</p> </li> <li> <p>STANDARD_ID</p> </li> <li> <p>GLACIER</p> </li> </ul>"},{"location":"xbcloud-options.html#storage","title":"storage","text":"<p>Usage: <code>--storage=[S3|SWIFT|GOOGLE|AZURE]</code></p> <p>Defines the Cloud storage option. xbcloud supports Swift, MinIO, Google, Azure, and AWS S3. The default value is <code>swift</code>.</p>"},{"location":"xbcloud-options.html#swift-auth-url","title":"swift-auth-url","text":"<p>Usage: <code>--swift-auth-url=name</code></p> <p>The Base URL of the Swift authentication service.</p>"},{"location":"xbcloud-options.html#swift-container","title":"swift-container","text":"<p>Usage: <code>--swift-container=name</code></p> <p>The Swift container used to store backups.</p>"},{"location":"xbcloud-options.html#swift-key","title":"swift-key","text":"<p>Usage: <code>--swift-key</code></p> <p>The Swift key/password (X-Auth-Key)</p>"},{"location":"xbcloud-options.html#swift-storage-url","title":"swift-storage-url","text":"<p>Usage: <code>--swift-storage-url=name</code></p> <p>If a name is specified, the xbcloud attempts to get the object-store endpoint for a given region from the keystone response. This option overrides that value.</p>"},{"location":"xbcloud-options.html#swift-user","title":"swift-user","text":"<p>Usage: <code>--swift-user=name</code></p> <p>The Swift user name (X-Auth-User).</p>"},{"location":"xbcloud-options.html#timeout","title":"timeout","text":"<p>Usage: <code>--timeout=#</code></p> <p>The number of seconds to wait for activity on the TCP connection. The default value is 120. If the value is 0 (zero), there is no timeout.</p>"},{"location":"xbcloud-options.html#verbose","title":"verbose","text":"<p>Usage: <code>--verbose</code></p> <p>Turns on the cURL tracing.</p>"},{"location":"xbcloud-options.html#swift-authentication-options","title":"Swift authentication options","text":"<p>The Swift specification describes several authentication options. The xbcloud tool can authenticate against keystone with API version 2 and 3.</p>"},{"location":"xbcloud-options.html#swift-auth-version","title":"swift-auth-version","text":"<p>Usage: <code>--swift-auth-version=name</code></p> <p>Defines the swift authentication version used. </p> <p>The possible values are the following: </p> <ul> <li> <p><code>1.0</code> - TempAuth</p> </li> <li> <p><code>2.0</code> - Keystone v2.0</p> </li> <li> <p><code>3</code> - Keystone v3. </p> </li> </ul> <p>The default value is <code>1.0</code>.</p>"},{"location":"xbcloud-options.html#if-swift-auth-version2-the-additional-options-are","title":"If <code>--swift-auth-version=2</code>, the additional options are:","text":""},{"location":"xbcloud-options.html#swift-password","title":"swift-password","text":"<p>Usage: <code>--swift-password=name</code></p> <p>Swift password for the user</p>"},{"location":"xbcloud-options.html#swift-region","title":"swift-region","text":"<p>Usage: <code>--swift-region=name</code></p> <p>Swift region object-store endpoint</p>"},{"location":"xbcloud-options.html#swift-tenant","title":"swift-tenant","text":"<p>Usage: <code>--swift-tenant=name</code></p> <p>The Swift tenant name </p> <p>Either of the <code>--swift-tenant</code> or <code>--swift-tenant-id</code> can be defined, but you should not use both options together. Both of these options are optional.</p>"},{"location":"xbcloud-options.html#swift-tenant-id","title":"swift-tenant-id","text":"<p>Usage: <code>--swift-tenant-id=name</code></p> <p>The Swift tenant ID</p> <p>Either of the <code>--swift-tenant</code> or <code>--swift-tenant-id</code> can be defined, but you should not use both options together. Both of these options are optional.</p>"},{"location":"xbcloud-options.html#if-swift-auth-version3-the-additional-options-are","title":"If <code>--swift-auth-version=3</code>, the  additional options are:","text":""},{"location":"xbcloud-options.html#swift-domain","title":"swift-domain","text":"<p>Usage: <code>--swift-domain=name</code></p> <p>The Swift domain name</p>"},{"location":"xbcloud-options.html#swift-domain-id","title":"swift-domain-id","text":"<p>Usage: <code>--swift-domain-id=name</code></p> <p>The Swift domain ID</p>"},{"location":"xbcloud-options.html#swift-project","title":"swift-project","text":"<p>Usage: <code>--swift-project=name</code></p> <p>The Swift project name</p>"},{"location":"xbcloud-options.html#swift-project-domain","title":"swift-project-domain","text":"<p>Usage: <code>--swift-project-domain=name</code></p> <p>The Swift domain name</p>"},{"location":"xbcloud-options.html#swift-project-domain-id","title":"swift-project-domain-id","text":"<p>Usage: <code>--swift-project-domain-id=name</code></p> <p>The Swift domain ID</p>"},{"location":"xbcloud-options.html#swift-project-id","title":"swift-project-id","text":"<p>Usage: <code>--swift-project-id=name</code></p> <p>The Swift project ID</p>"},{"location":"xbcloud-options.html#swift-user-id","title":"swift-user-id","text":"<p>Usage: <code>--swift-user-id=name</code></p> <p>The Swift user ID</p>"},{"location":"xbcloud-options.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"xbcloud-s3.html","title":"Use the xbcloud binary with Amazon S3","text":""},{"location":"xbcloud-s3.html#create-a-full-backup-with-amazon-s3","title":"Create a full backup with Amazon S3","text":"<pre><code>$ xtrabackup --backup --stream=xbstream --extra-lsndir=/tmp --target-dir=/tmp | \\\nxbcloud put --storage=s3 \\\n--s3-endpoint='s3.amazonaws.com' \\\n--s3-access-key='YOUR-ACCESSKEYID' \\\n--s3-secret-key='YOUR-SECRETACCESSKEY' \\\n--s3-bucket='mysql_backups'\n--parallel=10 \\\n$(date -I)-full_backup\n</code></pre> <p>The following options are available when using Amazon S3:</p> Option Details \u2013s3-access-key Use to supply the AWS access key ID \u2013s3-secret-key Use to supply the AWS secret access key \u2013s3-bucket Use supply the AWS bucket name \u2013s3-region Use to specify the AWS region. The default value is us-east-1 \u2013s3-api-version =  Select the signing algorithm. The default value is AUTO. In this case, xbcloud will probe. \u2013s3-bucket-lookup =  Specify whether to use bucket.endpoint.com or endpoint.com/bucket*style requests. The default value is AUTO. In this case, xbcloud will probe. \u2013s3-storage-class= Specify the S3 storage class. The default storage class depends on the provider. The name options are the following:<ul><li>STANDARD</li><li>STANDARD_IA</li><li>GLACIER</li></ul> NOTE If you use the GLACIER storage class, the object must be restored to S3 before restoring the backup. Also supports using custom S3 implementations such as MinIO or CephRadosGW."},{"location":"xbcloud-s3.html#permissions-setup","title":"Permissions setup","text":"<p>Following the principle of \u201cleast-privilege\u201d, these are the minimum bucket permissions needed for xbcloud to write backups to S3: LIST/PUT/GET/DELETE.</p> <p>The following example shows the policy definition for writing to the <code>xbcloud-testing</code> bucket on the AWS S3 storage.</p> <pre><code>{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"s3:ListBucket\"\n            ],\n            \"Resource\": \"arn:aws:s3:::xbcloud-testing\"\n        },\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"s3:PutObject\",\n                \"s3:PutObjectAcl\",\n                \"s3:GetObject\",\n                \"s3:GetObjectAcl\",\n                \"s3:DeleteObject\"\n            ],\n            \"Resource\": \"arn:aws:s3:::xbcloud-testing/*\"\n        }\n    ]\n}\n</code></pre>"},{"location":"xbcloud-s3.html#environment-variables","title":"Environment variables","text":"<p>The following environment variables are recognized. xbcloud maps them automatically to corresponding parameters applicable to the selected storage.</p> <ul> <li> <p>AWS_ACCESS_KEY_ID (or ACCESS_KEY_ID)</p> </li> <li> <p>AWS_SECRET_ACCESS_KEY (or SECRET_ACCESS_KEY)</p> </li> <li> <p>AWS_DEFAULT_REGION (or DEFAULT_REGION)</p> </li> <li> <p>AWS_ENDPOINT (or ENDPOINT)</p> </li> <li> <p>AWS_CA_BUNDLE</p> </li> </ul>"},{"location":"xbcloud-s3.html#restore-with-s3","title":"Restore with S3","text":"<pre><code>$ xbcloud get s3://operator-testing/bak22 \\\n--s3-endpoint=https://storage.googleapis.com/ \\\n--parallel=10 2&gt;download.log | xbstream -x -C restore --parallel=8\n</code></pre>"},{"location":"xbcloud-s3.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"xbcloud-swift.html","title":"Use the xbcloud binary with Swift","text":""},{"location":"xbcloud-swift.html#create-a-full-backup-with-swift","title":"Create a full backup with Swift","text":"<p>The following example shows how to make a full backup and upload it to Swift.</p> <pre><code>$ xtrabackup --backup --stream=xbstream --extra-lsndir=/tmp --target-dir=/tmp | \\\nxbcloud put --storage=swift \\\n--swift-container=test \\\n--swift-user=test:tester \\\n--swift-auth-url=http://192.168.8.80:8080/ \\\n--swift-key=testing \\\n--parallel=10 \\\nfull_backup\n</code></pre> <p>The following OpenStack environment variables are also recognized and mapped automatically to the corresponding swift parameters (<code>--storage=swift</code>):</p> <ul> <li> <p>OS_AUTH_URL</p> </li> <li> <p>OS_TENANT_NAME</p> </li> <li> <p>OS_TENANT_ID</p> </li> <li> <p>OS_USERNAME</p> </li> <li> <p>OS_PASSWORD</p> </li> <li> <p>OS_USER_DOMAIN</p> </li> <li> <p>OS_USER_DOMAIN_ID</p> </li> <li> <p>OS_PROJECT_DOMAIN</p> </li> <li> <p>OS_PROJECT_DOMAIN_ID</p> </li> <li> <p>OS_REGION_NAME</p> </li> <li> <p>OS_STORAGE_URL</p> </li> <li> <p>OS_CACERT</p> </li> </ul>"},{"location":"xbcloud-swift.html#restore-with-swift","title":"Restore with Swift","text":"<pre><code>$ xbcloud get [options] &lt;name&gt; [&lt;list-of-files&gt;] | xbstream -x\n</code></pre> <p>The following example shows how to fetch and restore the backup from Swift:</p> <pre><code>$ xbcloud get --storage=swift \\\n--swift-container=test \\\n--swift-user=test:tester \\\n--swift-auth-url=http://192.168.8.80:8080/ \\\n--swift-key=testing \\\nfull_backup | xbstream -xv -C /tmp/downloaded_full\n\n$ xbcloud delete --storage=swift --swift-user=xtrabackup \\\n--swift-password=xtrabackup123! --swift-auth-version=3 \\\n--swift-auth-url=http://openstack.ci.percona.com:5000/ \\\n--swift-container=mybackup1 --swift-domain=Default\n</code></pre>"},{"location":"xbcloud-swift.html#command-line-options","title":"Command-line options","text":"<p>xbcloud has the following command line options:</p>"},{"location":"xbcloud-swift.html#storageswifts3google","title":"\u2013storage(=[swift|s3|google])","text":"<p>Cloud storage option. xbcloud supports Swift, MinIO, and AWS S3. The default value is <code>swift</code>.</p>"},{"location":"xbcloud-swift.html#swift-auth-url","title":"\u2013swift-auth-url()","text":"<p>The URL of the Swift cluster</p>"},{"location":"xbcloud-swift.html#swift-storage-url","title":"\u2013swift-storage-url()","text":"<p>The xbcloud tries to get the object-store URL for a given region (if any are specified) from the keystone response. You can override that URL by passing \u2013swift-storage-url=URL argument.</p>"},{"location":"xbcloud-swift.html#swift-user","title":"\u2013swift-user()","text":"<p>The Swift username (X-Auth-User, specific to Swift)</p>"},{"location":"xbcloud-swift.html#swift-key","title":"\u2013swift-key()","text":"<p>The Swift key/password (X-Auth-Key, specific to Swift)</p>"},{"location":"xbcloud-swift.html#swift-container","title":"\u2013swift-container()","text":"<p>The container to back up into (specific to Swift)</p>"},{"location":"xbcloud-swift.html#paralleln","title":"\u2013parallel(=N)","text":"<p>The maximum number of concurrent upload/download requests. The default value is <code>1</code>.</p>"},{"location":"xbcloud-swift.html#cacert","title":"\u2013cacert()","text":"<p>The path to the file with CA certificates</p>"},{"location":"xbcloud-swift.html#insecure","title":"\u2013insecure()","text":"<p>Do not verify server\u2019s certificate</p>"},{"location":"xbcloud-swift.html#swift-authentication-options","title":"Swift authentication options","text":"<p>The Swift specification describes several authentication options. The xbcloud tool can authenticate against keystone with API version 2 and 3.</p>"},{"location":"xbcloud-swift.html#swift-auth-version","title":"\u2013swift-auth-version()","text":"<p>Specifies the swift authentication version. The possible values are: <code>1.0</code> - TempAuth, <code>2.0</code> - Keystone v2.0, and <code>3</code> - Keystone v3. The default value is <code>1.0</code>.</p> <p>For v2 additional options are:</p>"},{"location":"xbcloud-swift.html#swift-tenant","title":"\u2013swift-tenant()","text":"<p>Swift tenant name</p>"},{"location":"xbcloud-swift.html#swift-tenant-id","title":"\u2013swift-tenant-id()","text":"<p>Swift tenant ID</p>"},{"location":"xbcloud-swift.html#swift-region","title":"\u2013swift-region()","text":"<p>Swift endpoint region</p>"},{"location":"xbcloud-swift.html#swift-password","title":"\u2013swift-password()","text":"<p>Swift password for the user</p> <p>For v3 additional options are:</p>"},{"location":"xbcloud-swift.html#swift-user-id","title":"\u2013swift-user-id()","text":"<p>Swift user ID</p>"},{"location":"xbcloud-swift.html#swift-project","title":"\u2013swift-project()","text":"<p>Swift project name</p>"},{"location":"xbcloud-swift.html#swift-project-id","title":"\u2013swift-project-id()","text":"<p>Swift project ID</p>"},{"location":"xbcloud-swift.html#swift-domain","title":"\u2013swift-domain()","text":"<p>Swift domain name</p>"},{"location":"xbcloud-swift.html#swift-domain-id","title":"\u2013swift-domain-id()","text":"<p>Swift domain ID</p>"},{"location":"xbcloud-swift.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"xbcrypt-binary-overview.html","title":"The xbcrypt binary overview","text":"<p>To support encryption and decryption of the backups, a new tool <code>xbcrypt</code> was introduced to Percona XtraBackup.</p> <p>This utility has been modeled after The xbstream binary to perform encryption and decryption outside of Percona XtraBackup.</p> <p>The <code>XBCRYPT_ENCRYPTION_KEY</code> environment variable is only used in place of the <code>--encrypt_key=name</code> option. You can use the environment variable or command line option. If you use both, the command line option takes precedence over the value specified in the environment variable.</p>"},{"location":"xbcrypt-binary-overview.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"xbcrypt-options.html","title":"The xbcrypt command-line options","text":"<p>Usage: </p> <pre><code>$ xbcrypt[OPTIONS]\n</code></pre> <p>The <code>xbcrypt</code> binary has the following command line options:</p>"},{"location":"xbcrypt-options.html#decrypt","title":"decrypt","text":"<p>usage: <code>-d</code> <code>--decrypt</code></p> <p>Decrypt data input to output.</p>"},{"location":"xbcrypt-options.html#encrypt-algo","title":"encrypt-algo","text":"<p>usage: <code>-a=name</code> <code>--encrypt-algo=name</code></p> <p>Defines the name of the encryption algorithm.</p>"},{"location":"xbcrypt-options.html#encrypt-chunk-size","title":"encrypt-chunk-size","text":"<p>usage: <code>-s=#</code> <code>--encrypt-chunk-size=#</code></p> <p>Defines the size of the working buffer for encryption in bytes. The default value is <code>64000</code>.</p>"},{"location":"xbcrypt-options.html#encrypt-key","title":"encrypt-key","text":"<p>usage: <code>-k=name</code> <code>--encrypt-key=name</code></p> <p>The name of the encryption key.</p>"},{"location":"xbcrypt-options.html#encrypt-key-file","title":"encrypt-key-file","text":"<p>usage: <code>-f=name</code> <code>--encrypt-key-file=name</code></p> <p>The name of the file that contains the encryption key.</p>"},{"location":"xbcrypt-options.html#encrypt-threads","title":"encrypt-threads","text":"<p>usage: <code>--encrypt-threads=#</code></p> <p>This option specifies the number of worker threads used for parallel encryption/decryption. The default value is 1.</p>"},{"location":"xbcrypt-options.html#input","title":"input","text":"<p>usage: <code>-i=name</code> <code>--input=name</code></p> <p>Defines the name of the optional input file. If the name is not specified, the input reads from the standard input.</p>"},{"location":"xbcrypt-options.html#output","title":"output","text":"<p>usage: <code>-o=name</code> <code>--output=name</code></p> <p>Defines the name of the optional output file. If this name is not specified, the output is written to the standard output.</p>"},{"location":"xbcrypt-options.html#read-buffer-size","title":"read-buffer-size","text":"<p>usage: <code>--read-buffer-size=#</code></p> <p>Read the buffer size. The default value is 10MB. </p>"},{"location":"xbcrypt-options.html#verbose","title":"verbose","text":"<p>usage: <code>-v</code> <code>--verbose</code></p> <p>Display status in verbose mode.</p>"},{"location":"xbcrypt-options.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"xbstream-binary-overview.html","title":"The xbstream binary overview","text":"<p>To support simultaneous compression and streaming, the xbstream binary was added to Percona XtraBackup, along with the xbstream format and tar format. These additions were required to overcome some limitations of traditional archive formats such as tar, cpio, and others, which did not allow streaming dynamically generated files. </p> <p>Other advantages of xbstream over traditional streaming/archive format include streaming multiple files concurrently (so it is possible to use streaming in the xbstream format together with the \u2013parallel option) and more compact data storage.</p> <p>For details on the command-line options, see xbcloud command-line options. When available, the utility tries to minimize its impact on the OS page cache by using the appropriate <code>posix_fadvise()</code> calls.</p> <p>When compression is enabled with xtrabackup all data is compressed, including the transaction log file and metadata files, using the specified compression algorithm. Read more about supported compression algorithms in the Create a compressed backup document.</p>"},{"location":"xbstream-binary-overview.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"xbstream-options.html","title":"The xbstream command-line options","text":"<pre><code>$ xbstream -c [OPTIONS]\n$ xbstream -x [OPTIONS]\n</code></pre> <p>This utility has a tar-like interface.</p> <p>The xbstream binary has the following options:</p>"},{"location":"xbstream-options.html#absolute-names","title":"absolute-names","text":"<p>Usage: <code>-absolute-names</code></p> <p>Do not strip the leading // (slashes) from the file names when creating archives.</p>"},{"location":"xbstream-options.html#c","title":"c","text":"<p>Usage: <code>-c</code></p> <p>Streams files specified on the command line to its standard output.</p>"},{"location":"xbstream-options.html#decompress","title":"decompress","text":"<p>Usage: <code>--decompress</code></p> <p>Decompress the individual backup files</p>"},{"location":"xbstream-options.html#decompress-threads","title":"decompress-threads","text":"<p>Usage: <code>--decompress-threads=#</code></p> <p>The number of threads for parallel data decompression. The default value is 1.</p>"},{"location":"xbstream-options.html#decrypt","title":"decrypt","text":"<p>Usage: <code>--decrypt=name</code></p> <p>Specifies that xbstream automatically decrypts encrypted files when extracting input stream. The supported values are: <code>AES128</code>, <code>AES192</code>, and <code>AES256</code>. </p> <p>You can specify either <code>--encrypt-key</code> or <code>--encrypt-key-file</code> to provide the encryption key, but do not use both options. </p>"},{"location":"xbstream-options.html#directory","title":"directory","text":"<p>Usage: <code>--directory=name</code></p> <p>Change the current directory to this named directory before streaming or extracting.</p>"},{"location":"xbstream-options.html#encrypt-key","title":"encrypt-key","text":"<p>Usage: <code>--encrypt-key=name</code></p> <p>Specify the encryption key used. Do not use this option with <code>--encrypt-key-file</code>; these options are mutually exclusive.</p>"},{"location":"xbstream-options.html#encrypt-key-file","title":"encrypt-key-file","text":"<p>Usage: <code>--encrypt-key-file=name</code></p> <p>Specify the file that contains the encryption key. Do not use this option with <code>--encrypt-key</code>; these options are mutually exclusive.</p>"},{"location":"xbstream-options.html#encrypt-threads","title":"encrypt-threads","text":"<p>Usage: <code>--encrypt-threads-=#</code></p> <p>Specify the number of threads for parallel data encryption. The default value is <code>1</code>. </p>"},{"location":"xbstream-options.html#extract","title":"extract","text":"<p>Usage: <code>--extract</code></p> <p>Extract to disk the files from the stream to the standard input.</p>"},{"location":"xbstream-options.html#fifo-dir","title":"fifo-dir","text":"<p>Usage: <code>--fifo-dir=name</code></p> <p>The directory used to read or write named pipes.</p>"},{"location":"xbstream-options.html#fifo-streams","title":"fifo-streams","text":"<p>Usage: <code>--fifo-streams=#</code></p> <p>The number of FIFO files (named pipes) to use for parallel data file streaming. To disable the option and send the stream to STDOUT, set the value to 1. </p>"},{"location":"xbstream-options.html#fifo-timeout","title":"fifo-timeout","text":"<p>Usage: <code>--fifo-timeout=#</code></p> <p>The number of seconds to wait for the other end to open the stream. The default value is 60.</p>"},{"location":"xbstream-options.html#parallel","title":"parallel","text":"<p>Usage: <code>--parallel=#</code></p> <p>Defines the number of worker threads for reading or writing.</p>"},{"location":"xbstream-options.html#x","title":"x","text":"<p>Usage: <code>-x</code></p> <p>Extracts files from the stream read from its standard input to the current directory unless specified otherwise with the <code>-c</code> option. Support for parallel extraction with the <code>--parallel</code> option</p>"},{"location":"xbstream-options.html#verbose","title":"verbose","text":"<p>Usage: <code>--verbose</code></p> <p>Print verbose output</p>"},{"location":"xbstream-options.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"xtrabackup-binary-overview.html","title":"The xtrabackup binary overview","text":"<p>The xtrabackup binary is a compiled C program that is linked with the InnoDB libraries and the standard MySQL client libraries.</p> <p>xtrabackup enables point-in-time backups of InnoDB / XtraDB tables together with the schema definitions, MyISAM tables, and other portions of the server.</p> <p>The InnoDB libraries provide the functionality to apply a log to data files. The MySQL client libraries are used to parse command-line options and configuration file.</p> <p>The tool runs in either <code>--backup</code> or <code>--prepare</code> mode, corresponding to the two main functions it performs. There are several variations on these functions to accomplish different tasks, and there is one less commonly used mode, <code>--print-param</code>.</p>"},{"location":"xtrabackup-binary-overview.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"xtrabackup-exit-codes.html","title":"xtrabackup exit codes","text":"<p>The xtrabackup binary exits with the traditional success value of 0 after a backup when no error occurs. If an error occurs during the backup, the exit value is 1.</p> <p>In certain cases, the exit value can be something other than 0 or 1, due to the command-line option code included from the MySQL libraries. An unknown command-line option, for example, will cause an exit code of 255.</p>"},{"location":"xtrabackup-exit-codes.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"xtrabackup-files.html","title":"Index of files created by Percona XtraBackup","text":"<ul> <li>Information related to the backup and the server</li> </ul> File Name Description <code>backup-my.cnf</code>  This file contains information to start the mini instance  of InnoDB during the <code>--prepare</code>.  This  **not** a  backup of the original <code>my.cnf</code>. The  InnoDB configuration is  read from  the file <code>backup-my.cnf</code> created by  xtrabackup when the backup was made. The <code>--prepare</code> uses InnoDB  configuration from <code>backup-my.cnf</code>  by default, or from <code>--defaults-file</code>, if specified. The InnoDB's configuration in this context means server variables that affect dataformat, i.e., <code>innodb_page_size</code> option, <code>innodb_log_block_size</code>, etc. Location-related variables, like <code>innodb_log_group_home_dir</code> or <code>innodb_data_file_path</code> are always ignored by <code>--prepare</code>, so preparing a backup always works with data files from the back directory, rather than any external ones.     <code>xtrabackup_checkpoints</code><p>The type of the backup (for example, full or incremental),  its state (for example, prepared) and the LSN range contained in it.  This information is used for incremental backups. Example of the  <code>xtrabackup_checkpoints</code> after  taking a full backup:</p><pre>backup_type = full-backuped\nfrom lsn= 0\nto_lsn = 15188961605\nlast_lsn = 15188961605\n</pre>  Example of the <code>xtrabackup_checkpoints</code> after taking an  incremental backup: <pre>backup_type = incremental\nfrom_lsn = 15188961605\nto_lsn = 15189350111\nlast_lsn = 15189350111\n</pre> <code>xtrabackup_binlog_info</code> <p>The binary log file used by the server and its position at the moment of the backup. A result of the following query:</p> <pre>SELECT server_uuid, local, replication, storage_engines FROM performance_schema.log_status;\n</pre> <code>xtrabackup_binlog</code> The xtrabackup binary used in the process.  <code>xtrabackup_logfile</code> Contains data needed for running the: <code>--prepare</code>.      The bigger this file is the <code>--prepare</code> process      will take longer to finish.  <code>&lt;table_name&gt;.delta.meta</code> <p>This file is going to be created when performing the incremental  backup.      It contains the per-table delta metadata: page size, size of compressed      page (if the value is 0 it means the tablespace isn\u2019t compressed) and      space id. Example of this file:</p> <pre>page_size = 16384\nzip_size = 0\nspace_id = 0\n</pre> <ul> <li> <p>Information related to the replication environment (if using the<code>--slave-info</code> option):</p> <p><code>xtrabackup_slave_info</code></p> <p>The <code>CHANGE MASTER</code> statement needed for setting up a replica.</p> </li> <li> <p>Information related to the Galera and Percona XtraDB Cluster (if using the <code>--galera-info</code> option):</p> <p><code>xtrabackup_galera_info</code></p> <p>Contains the values of <code>wsrep_local_state_uuid</code> and<code>wsrep_last_committed</code> status variables</p> </li> </ul>"},{"location":"xtrabackup-files.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"xtrabackup-implementation-details.html","title":"xtrabackup implementation details","text":"<p>This page contains notes on various internal aspects of the xtrabackup tool\u2019s operation.</p>"},{"location":"xtrabackup-implementation-details.html#file-permissions","title":"File permissions","text":"<p>xtrabackup opens the source data files in read-write mode, although it does not modify the files. This means that you must run xtrabackup as a user who has permission to write the data files. The reason for opening the files in read-write mode is that xtrabackup uses the embedded InnoDB libraries to open and read the files, and InnoDB opens them in read-write mode because it normally assumes it is going to write to them.</p>"},{"location":"xtrabackup-implementation-details.html#tune-the-os-buffers","title":"Tune the OS buffers","text":"<p>Because xtrabackup reads large amounts of data from the filesystem, it uses <code>posix_fadvise()</code> where possible, to instruct the operating system not to try to cache the blocks it reads from disk. Without this hint, the operating system would prefer to cache the blocks, assuming that <code>xtrabackup</code> is likely to need them again, which is not the case. Caching such large files can place pressure on the operating system\u2019s virtual memory and cause other processes, such as the database server, to be swapped out. The <code>xtrabackup</code> tool avoids this with the following hint on both the source and destination files:</p> <pre><code>posix_fadvise(file, 0, 0, POSIX_FADV_DONTNEED)\n</code></pre> <p>In addition, xtrabackup asks the operating system to perform more aggressive read-ahead optimizations on the source files:</p> <pre><code>posix_fadvise(file, 0, 0, POSIX_FADV_SEQUENTIAL)\n</code></pre>"},{"location":"xtrabackup-implementation-details.html#copy-data-files","title":"Copy data files","text":"<p>When copying the data files to the target directory, xtrabackup reads and writes 1 MB of data at a time. This is not configurable. When copying the log file, xtrabackup reads and writes 512 bytes at a time. This is also not possible to configure, and matches InnoDB\u2019s behavior (workaround exists in Percona Server for MySQL because it has an option to tune <code>innodb_log_block_size</code> for XtraDB, and in that case Percona XtraBackup will match the tuning).</p> <p>After reading from the files, <code>xtrabackup</code> iterates over the 1MB buffer a page at a time, and checks for page corruption on each page with InnoDB\u2019s <code>buf_page_is_corrupted()</code> function. If the page is corrupt, it re-reads and retries up to 10 times for each page. It skips this check on the doublewrite buffer.</p>"},{"location":"xtrabackup-implementation-details.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"xtrabackup-option-reference.html","title":"The xtrabackup command-line options","text":"<p>Here you can find all of the command-line options for the xtrabackup binary.</p>"},{"location":"xtrabackup-option-reference.html#modes-of-operation","title":"Modes of operation","text":"<p>You invoke xtrabackup in one of the following modes:</p> <ul> <li> <p><code>--backup</code> mode to make a backup in a target directory</p> </li> <li> <p><code>--prepare</code> mode to restore data from a backup (created in <code>--backup</code> mode)</p> </li> <li> <p><code>--copy-back</code> to copy data from a backup to the original location; to move the data instead of copying the data, use the alternate <code>--move-back</code> mode.</p> </li> </ul> <p>When you intend to run xtrabackup in any of these modes, use the following syntax:</p> <pre><code>$ xtrabackup [--defaults-file=#] --backup|--prepare|--copy-back| [OPTIONS]\n</code></pre> <p>For example, the <code>--prepare</code> mode is applied as follows:</p> <pre><code>$ xtrabackup --prepare --target-dir=/data/backup/mysql/\n</code></pre> <p>For all modes, the default options are read from the xtrabackup and mysqld configuration groups from the following files in the given order:</p> <ol> <li> <p><code>/etc/my.cnf</code></p> </li> <li> <p><code>/etc/mysql/my.cnf</code></p> </li> <li> <p><code>/usr/etc/my.cnf</code></p> </li> <li> <p><code>~/.my.cnf</code>.</p> </li> </ol> <p>As the first parameter to xtrabackup in place of the <code>--defaults-file</code>, you may supply one of the following:</p> <ul> <li> <p><code>--print-defaults</code> - prints the argument list and exit.</p> </li> <li> <p><code>--no-defaults</code> - forbids reading options from any file but the login file.</p> </li> <li> <p><code>--defaults-file</code> -  reads the default options from the given file.</p> </li> <li> <p><code>--defaults-extra-file</code> - reads the specified additional file after the global files.</p> </li> <li> <p><code>--defaults-group-suffix</code> -  reads the configuration groups with the given suffix. The effective group name is constructed by concatenating the default configuration groups (xtrabackup and mysqld) with the given suffix.</p> </li> <li> <p><code>--login-path</code> - reads the given path from the login file.</p> </li> </ul>"},{"location":"xtrabackup-option-reference.html#innodb-options","title":"InnoDB options","text":"<p>A large group of InnoDB options is usually read from the <code>my.cnf</code> configuration file, so xtrabackup boots up its embedded InnoDB in the same configuration as your current server. You typically do not need to specify them explicitly. These options have the same behavior in InnoDB and XtraDB. See <code>--innodb-miscellaneous</code> for more information.</p>"},{"location":"xtrabackup-option-reference.html#options","title":"Options","text":""},{"location":"xtrabackup-option-reference.html#apply-log-only","title":"apply-log-only","text":"<p>Usage: <code>--apply-log-only</code></p> <p>This option causes only the redo stage to be performed when preparing a backup. It is essential for incremental backups.</p>"},{"location":"xtrabackup-option-reference.html#backup","title":"backup","text":"<p>Usage: <code>--backup</code></p> <p>Make a backup and place it in <code>--target-dir</code>. See Create a full backup</p>"},{"location":"xtrabackup-option-reference.html#backup-lock-timeout","title":"backup-lock-timeout","text":"<p>Usage: <code>--backup-lock-timeout</code></p> <p>The timeout in seconds for attempts to acquire metadata locks.</p>"},{"location":"xtrabackup-option-reference.html#backup-lock-retry-count","title":"backup-lock-retry-count","text":"<p>Usage: <code>--backup-lock-retry-count</code></p> <p>The number of attempts to acquire metadata locks.</p>"},{"location":"xtrabackup-option-reference.html#backup-locks","title":"backup-locks","text":"<p>Usage: <code>--backup-locks</code></p> <p>This option controls if Backup locks are used instead of <code>FLUSH TABLES WITH READ LOCK</code> on the backup stage. The option has no effect when the server does not support backup locks. This option is enabled by default, disable with <code>--no-backup-locks</code>.</p>"},{"location":"xtrabackup-option-reference.html#check-privileges","title":"check-privileges","text":"<p>Usage: <code>check-privileges</code></p> <p>This option checks if Percona XtraBackup has all the required privileges. If a required privilege is missing for the current operation, the operation terminates and prints an error message. If a privilege is not needed for the current operation but is missing and may be necessary for another XtraBackup operation, the operation is not aborted, and a warning is printed.</p> Example output <pre><code>```{.text .no-copy}\nxtrabackup: Error: missing required privilege LOCK TABLES on *.*\nxtrabackup: Warning: missing required privilege REPLICATION CLIENT on *.*\n```\n</code></pre>"},{"location":"xtrabackup-option-reference.html#close-files","title":"close-files","text":"<p>Usage: <code>--close-files</code></p> <p>Do not keep files opened. When xtrabackup opens a tablespace, xtrabackup normally doesn\u2019t close its file handle. This operation allows xtrabackup to handle the DDL operations correctly. However, if the number of tablespaces is huge and can not fit into any limit, there is an option to close file handles once they are no longer accessed. Percona XtraBackup can produce inconsistent backups with this option enabled. Use at your own risk.</p>"},{"location":"xtrabackup-option-reference.html#compress","title":"compress","text":"<p>Usage: <code>--compress</code></p> <p>This option tells xtrabackup to compress all output data, including the transaction log and metadata files, using either the <code>ZSTD</code> or the <code>lz4</code> compression algorithm. <code>ZSTD</code> is the default compression algorithm.</p> <p><code>--compress</code> produces <code>\\*.zst</code> files. You can extract the contents of these files using the <code>--decompress</code> option. You can specify the <code>ZSTD</code> compression level with the <code>--compress-zstd-level</code> option.</p> <p><code>--compress=lz4</code> produces <code>\\*.lz4</code> files. You can extract the contents of these files by using the <code>lz4</code> program.</p>"},{"location":"xtrabackup-option-reference.html#compress-chunk-size","title":"compress-chunk-size","text":"<p>Usage: <code>--compress-chunk-size=#</code></p> <p>Size of working buffer(s) for compression threads in bytes. The default value is 64K.</p>"},{"location":"xtrabackup-option-reference.html#compress-threads","title":"compress-threads","text":"<p>Usage: <code>--compress-threads=#</code></p> <p>This option specifies the number of worker threads xtrabackup uses for parallel data compression. This option defaults to <code>1</code> and can be used with parallel file copying.</p> <p>For example, <code>--parallel=4 --compress --compress-threads=2</code> creates four I/O threads that read and pipe the data to two compression threads.</p>"},{"location":"xtrabackup-option-reference.html#compress-zstd-level","title":"compress-zstd-level","text":"<p>Usage: <code>--compress-zstd-level=#</code></p> <p>This option specifies <code>ZSTD</code> compression level. Compression levels provide a trade-off between the compression speed and the compressed files\u2019 size. A lower compression level provides faster compression speed but larger file sizes. A higher compression level provides lower compression speed but smaller file sizes. For example, set level 1 if the compression speed is the most important for you. Set level 19 if the size of the compressed files is the most important.</p> <p>The default value is 1. Allowed range of values is from 1 to 19.</p>"},{"location":"xtrabackup-option-reference.html#copy-back","title":"copy-back","text":"<p>Usage: <code>--copy-back</code></p> <p>Copy all the files in a previously made backup from the backup directory to their original locations. This option will not copy over existing files unless the <code>--force-non-empty-directories</code> option is specified.</p>"},{"location":"xtrabackup-option-reference.html#core-file","title":"core-file","text":"<p>Usage: <code>--core-file</code></p> <p>Write core on fatal signals.</p>"},{"location":"xtrabackup-option-reference.html#databases","title":"databases","text":"<p>Usage: <code>--databases=#</code></p> <p>This option specifies a list of databases and tables that should be backed up. The option accepts the list of the form <code>\"databasename1[.table_name1] databasename2[.table_name2] . . .\"</code>.</p>"},{"location":"xtrabackup-option-reference.html#databases-exclude","title":"databases-exclude","text":"<p>Usage: <code>--databases-exclude=name</code></p> <p>Databases are excluded based on name. This option operates the same way as <code>--databases</code> but excludes the matched names from the backup.</p> <p>This option has a higher priority than <code>--databases</code>.</p>"},{"location":"xtrabackup-option-reference.html#databases-file","title":"databases-file","text":"<p>Usage: <code>--databases-file=#</code></p> <p>This option specifies the path to the file containing the list of databases and tables that should be backed up. The file can contain the list elements of the form <code>databasename1[.table_name1]</code>, one element per line.</p>"},{"location":"xtrabackup-option-reference.html#datadir","title":"datadir","text":"<p>Usage: <code>--datadir=DIRECTORY</code></p> <p>The source directory for the backup. This should be the same as the datadir for your server, so it should be read from <code>my.cnf</code> if that exists; otherwise, specify the directory on the command line.</p> <p>When combined with the <code>--copy-back</code> or the <code>--move-back</code> option, this option refers to the destination directory.</p> <p>To perform a backup, you must have the <code>READ</code> and <code>EXECUTE</code> permissions at a filesystem level in the server\u2019s datadir.</p>"},{"location":"xtrabackup-option-reference.html#debug-sleep-before-unlock","title":"debug-sleep-before-unlock","text":"<p>Usage: <code>--debug-sleep-before-unlock=#</code></p> <p>This option is only used by the xtrabackup test suite.</p>"},{"location":"xtrabackup-option-reference.html#debug-sync","title":"debug-sync","text":"<p>Usage: <code>--debug-sync=name</code></p> <p>This option is only used by the xtrabackup test suite.</p>"},{"location":"xtrabackup-option-reference.html#decompress","title":"decompress","text":"<p>Usage: <code>--decompress</code></p> <p>Decompresses all files in a backup previously made with the <code>--compress</code> option. The <code>--parallel</code> option lets multiple files be decrypted simultaneously.</p> <p>Percona XtraBackup does not automatically remove the compressed files. Users should use the <code>--remove-original</code> option to clean up the backup directory.</p>"},{"location":"xtrabackup-option-reference.html#decompress-threads","title":"decompress-threads","text":"<p>Usage: <code>--decompress-threads=#</code></p> <p>Force xbstream to use the specified number of threads for decompressing.</p>"},{"location":"xtrabackup-option-reference.html#decrypt","title":"decrypt","text":"<p>Usage: <code>--decrypt=ENCRYPTION-ALGORITHM</code></p> <p>Decrypts all files with the <code>xbcrypt</code> extension in a backup previously made with <code>--encrypt</code> option. The <code>--parallel</code> option lets multiple files be decrypted simultaneously. Percona XtraBackup doesn\u2019t automatically remove the encrypted files; use <code>--</code>remove-original`](#remove-original) option.</p>"},{"location":"xtrabackup-option-reference.html#defaults-extra-file","title":"defaults-extra-file","text":"<p>Usage: <code>--defaults-extra-file=[MY.CNF]</code></p> <p>Read this file after the global files are read. The option must be the first option on the command line.</p>"},{"location":"xtrabackup-option-reference.html#defaults-file","title":"defaults-file","text":"<p>Usage: <code>--defaults-file=[MY.CNF]</code></p> <p>Only read default options from the given file. The value must be the first option on the command line and cannot be a symbolic link.</p>"},{"location":"xtrabackup-option-reference.html#defaults-group","title":"defaults-group","text":"<p>Usage: <code>--defaults-group=GROUP-NAME</code></p> <p>This option sets the group that should be read from the configuration file and is needed for <code>mysqld_multi</code> deployments.</p>"},{"location":"xtrabackup-option-reference.html#defaults-group-suffix","title":"defaults-group-suffix","text":"<p>Usage: <code>--defaults-group-suffix=#</code></p> <p>Also reads groups with concat(group, suffix).</p>"},{"location":"xtrabackup-option-reference.html#dump-innodb-buffer-pool","title":"dump-innodb-buffer-pool","text":"<p>Usage: <code>--dump-innodb-buffer-pool</code></p> <p>This option controls creating a new dump of the buffer pool content.</p> <p>The xtrabackup binary requests the server to start the buffer pool dump. This operation may take time to complete and is done in the background. The beginning of a backup with the option reports that the dump has been completed.</p> <pre><code>$ xtrabackup --backup --dump-innodb-buffer-pool --target-dir=/home/user/backup\n</code></pre> <p>By default, this option is set to OFF.</p> <p>If <code>innodb_buffer_pool_dump_status</code> reports that there is a running dump of the buffer pool, xtrabackup waits for the dump to complete using the value of <code>--dump-innodb-buffer-pool-timeout</code></p> <p>The file <code>ib_buffer_pool</code> stores the tablespace ID and page ID data used to warm up the buffer pool sooner.</p>"},{"location":"xtrabackup-option-reference.html#dump-innodb-buffer-pool-pct","title":"dump-innodb-buffer-pool-pct","text":"<p>Usage: <code>--dump-innodb-buffer-pool-pct</code></p> <p>This option contains the percentage of the most recently used buffer pool pages to dump.</p> <p>This option is effective if <code>--dump-innodb-buffer-pool</code> option is set to ON. If this option contains a value, xtrabackup sets the MySQL system variable <code>innodb_buffer_pool_dump_pct</code>. As soon as the buffer pool dump completes or is stopped (see <code>--dump-innodb-buffer-pool-timeout</code>), the value of the MySQL system variable is restored.</p>"},{"location":"xtrabackup-option-reference.html#dump-innodb-buffer-pool-timeout","title":"dump-innodb-buffer-pool-timeout","text":"<p>Usage: <code>--dump-innodb-buffer-pool-timeout</code></p> <p>This option contains the number of seconds that xtrabackup should monitor the value of <code>innodb_buffer_pool_dump_status</code> to determine if the buffer pool dump has been completed.</p> <p>This option is used in combination with <code>--dump-innodb-buffer-pool</code>. By default, it is set to 10 seconds.</p>"},{"location":"xtrabackup-option-reference.html#encrypt","title":"encrypt","text":"<p>Usage: <code>--encrypt=ENCRYPTION_ALGORITHM</code></p> <p>This option instructs xtrabackup to encrypt backup copies of InnoDB data files using the algorithm specified in the ENCRYPTION_ALGORITHM. Currently supported algorithms are: <code>AES128</code>, <code>AES192</code> and <code>AES256</code></p>"},{"location":"xtrabackup-option-reference.html#encrypt-key","title":"encrypt-key","text":"<p>Usage: <code>--encrypt-key=ENCRYPTION_KEY</code></p> <p>A proper length encryption key to use. This key can be viewed as part of the process info. We do not recommend using this option with uncontrolled access to the machine.</p>"},{"location":"xtrabackup-option-reference.html#encrypt-key-file","title":"encrypt-key-file","text":"<p>Usage: <code>--encrypt-key-file=ENCRYPTION_KEY_FILE</code></p> <p>The name of a file where the raw key of the appropriate length can be read from. The file must be a simple binary (or text) file that contains exactly the key to be used.</p> <p>It is passed directly to the xtrabackup child process. See the xtrabackup documentation for more details.</p>"},{"location":"xtrabackup-option-reference.html#encrypt-threads","title":"encrypt-threads","text":"<p>Usage: <code>--encrypt-threads=#</code></p> <p>This option specifies the number of worker threads that will be used for parallel encryption/decryption. See the xtrabackup documentation for more details.</p>"},{"location":"xtrabackup-option-reference.html#encrypt-chunk-size","title":"encrypt-chunk-size","text":"<p>Usage: <code>--encrypt-chunk-size=#</code></p> <p>This option specifies the size of the internal working buffer for each encryption thread, measured in bytes. It is passed directly to the xtrabackup child process.</p> <p>To adjust the chunk size for encrypted files, use <code>--read-buffer-size</code> and this option.</p>"},{"location":"xtrabackup-option-reference.html#estimate-memory","title":"estimate-memory","text":"<p>Usage: <code>--estimate-memory=#</code></p> <p>This option is in tech preview.</p> <p>The option lets you enable or disable the Smart memory estimation feature. The default value is OFF. Enable the feature by setting <code>--estimate-memory=ON</code> in the backup phase and setting the <code>--use-free-memory-pct</code> option in the <code>--prepare</code> phase. If the <code>--estimate-memory</code> setting is disabled, the <code>--use-free-memory-pct</code> setting is ignored.</p> <p>An example of how to enable the Smart memory estimation feature:</p> <pre><code>$ xtrabackup --backup --estimate-memory=ON --target-dir=/data/backups/\n</code></pre> <pre><code>$ xtrabackup --prepare --use-free-memory-pct=50 --target-dir=/data/backups/\n</code></pre>"},{"location":"xtrabackup-option-reference.html#export","title":"export","text":"<p>Usage: <code>--export</code></p> <p>Create files necessary for exporting tables. For more details, see Restore individual tables.</p>"},{"location":"xtrabackup-option-reference.html#extra-lsndir","title":"extra-lsndir","text":"<p>Usage: <code>--extra-lsndir=DIRECTORY</code></p> <p>(for \u2013backup): save an extra copy of the <code>xtrabackup_checkpoints</code> and <code>xtrabackup_info</code> files in the specified directory.</p>"},{"location":"xtrabackup-option-reference.html#force-non-empty-directories","title":"force-non-empty-directories","text":"<p>Usage: <code>--force-non-empty-directories</code></p> <p>When specified, the <code>-</code>-copy-back<code>and</code>\u2013move-back` options transfer files to non-empty directories. No existing files are overwritten. If files that need to be copied/moved from the backup directory already exist in the destination directory, the operation fails with an error.</p>"},{"location":"xtrabackup-option-reference.html#ftwrl-wait-timeout","title":"ftwrl-wait-timeout","text":"<p>Usage: <code>--ftwrl-wait-timeout=SECONDS</code></p> <p>This option specifies the time in seconds that xtrabackup should wait for queries that would block <code>FLUSH TABLES WITH READ LOCK</code> before running it. If there are still such queries when the timeout expires, xtrabackup terminates with an error.</p> <p>The default value is <code>0</code>, xtrabackup does not wait for queries to complete and starts <code>FLUSH TABLES WITH READ LOCK</code> immediately. Where supported, xtrabackup automatically uses the Backup locks as a lightweight alternative to <code>FLUSH TABLES WITH READ LOCK</code> to copy non-InnoDB data to avoid blocking DML queries that modify the InnoDB tables.</p>"},{"location":"xtrabackup-option-reference.html#ftwrl-wait-threshold","title":"ftwrl-wait-threshold","text":"<p>Usage: <code>--ftwrl-wait-threshold=SECONDS</code></p> <p>This option specifies the query run time threshold which is used by xtrabackup to detect long-running queries with a non-zero value of <code>--ftwrl-wait-timeout</code>. <code>FLUSH TABLES WITH READ LOCK</code> is not started until such long-running queries exist.</p> <p>This option has no effect if <code>--ftwrl-wait-timeout</code> is <code>0</code>. The default value is <code>60</code> seconds. The xtrabackup binary automatically uses Backup locks as a lightweight alternative to <code>FLUSH TABLES WITH READ LOCK</code> to copy non-InnoDB data to avoid blocking DML queries that modify InnoDB tables when backup locks are supported.</p>"},{"location":"xtrabackup-option-reference.html#ftwrl-wait-query-type","title":"ftwrl-wait-query-type","text":"<p>Usage: <code>--ftwrl-wait-query-type=all|update</code>This option specifies which queries can be completed before xtrabackup issues the global lock. The default value is <code>all</code>.</p>"},{"location":"xtrabackup-option-reference.html#galera-info","title":"galera-info","text":"<p>Usage: <code>--galera-info</code></p> <p>This option creates the <code>xtrabackup_galera_info</code> file, which contains the local node state at the backup time. This option should be used when performing the backup of a Percona XtraDB Cluster. The option has no effect when Backup locks are used to create the backup.</p>"},{"location":"xtrabackup-option-reference.html#generate-new-master-key","title":"generate-new-master-key","text":"<p>Usage: <code>--generate-new-master-key</code></p> <p>Generate a new master key when doing a copy-back.</p>"},{"location":"xtrabackup-option-reference.html#generate-transition-key","title":"generate-transition-key","text":"<p>Usage: <code>--generate-transition-key</code></p> <p>xtrabackup needs to access the same keyring file or vault server during prepare and copy-back operations but it should not depend on whether the server keys have been purged.</p> <p><code>--generate-transition-key</code> creates and adds to the keyring a transition key for xtrabackup to use if the master key used for encryption is not found because that key has been rotated and purged.</p>"},{"location":"xtrabackup-option-reference.html#get-server-public-key","title":"get-server-public-key","text":"<p>Usage: <code>--get-server-public-key</code></p> <p>Get the server public key</p>"},{"location":"xtrabackup-option-reference.html#help","title":"help","text":"<p>Usage: <code>--help</code></p> <p>This option displays information about how to run the program along with supported options and variables with the default values, where appropriate.</p>"},{"location":"xtrabackup-option-reference.html#history","title":"history","text":"<p>Usage: <code>--history=NAME</code></p> <p>This option enables the tracking of backup history in the <code>PERCONA_SCHEMA.xtrabackup_history</code> table. You can specify a history series name placed with the current backup\u2019s history record.</p>"},{"location":"xtrabackup-option-reference.html#host","title":"host","text":"<p>Usage: <code>--host=HOST</code></p> <p>This option accepts a string argument that specifies the host to use when connecting to the database server with TCP/IP. It is passed to the mysql child process without alteration. See mysql \u2013help for details.</p>"},{"location":"xtrabackup-option-reference.html#incremental-basedir","title":"incremental-basedir","text":"<p>Usage: <code>--incremental-basedir=DIRECTORY</code></p> <p>This is the directory that contains the full backup, which is the base dataset for the incremental backups.</p>"},{"location":"xtrabackup-option-reference.html#incremental-dir","title":"incremental-dir","text":"<p>Usage: <code>--incremental-dir=DIRECTORY</code></p> <p>This is the directory where the incremental backup is combined with the full backup to make a new full backup.</p>"},{"location":"xtrabackup-option-reference.html#incremental-force-scan","title":"incremental-force-scan","text":"<p>Usage: <code>--incremental-force-scan</code></p> <p>When creating an incremental backup, force a full scan of the data pages in that instance.</p>"},{"location":"xtrabackup-option-reference.html#incremental-history-name","title":"incremental-history-name","text":"<p>Usage: <code>--incremental-history-name=name</code></p> <p>This option specifies the name of the backup series stored in the <code>PERCONA_SCHEMA.xtrabackup_history</code> used as a base for an incremental backup. xtrabackup searches the history table looking for the most recent (highest <code>innodb_to_lsn</code>), successful backup in the series and takes the <code>to_lsn`` value to use as the starting</code>lsn` for the incremental backup.</p> <p>This options is mutually exclusive with <code>--incremental-history-uuid</code>, <code>--incremental-basedir</code>, and <code>--incremental-lsn</code>.</p> <p>If no valid lsn can be found, either no series by that name or no successful backups by that name, xtrabackup returns an error.</p> <p>The option is used with the <code>--incremental</code> option.</p>"},{"location":"xtrabackup-option-reference.html#incremental-history-uuid","title":"incremental-history-uuid","text":"<p>Usage: <code>--incremental-history-uuid=name</code></p> <p>This option specifies the Universal Unique Identifier (UUID) of the history record in <code>PERCONA_SCHEMA.xtrabackup_history</code> used as the base for an incremental backup.</p> <p>This options is mutually exclusive with <code>--incremental-history-name</code>, <code>--incremental-basedir</code>, and <code>--incremental-lsn</code>.</p> <p>If there is no success record with that UUID, xtrabackup returns an error.</p> <p>The option is used with the <code>-\u2013incremental</code> option.</p>"},{"location":"xtrabackup-option-reference.html#incremental-lsn","title":"incremental-lsn","text":"<p>Usage: <code>--incremental-lsn=LSN</code></p> <p>When creating an incremental backup, you can specify the log sequence number (LSN), a single 64-bit integer, instead of the  <code>--incremental-basedir</code>.</p> <p>Important</p> <p>Percona XtraBackup does not detect if an incorrect LSN value is specified; the backup is unusable. Be careful!</p>"},{"location":"xtrabackup-option-reference.html#innodb","title":"innodb","text":"<p>Usage: <code>--innodb=name</code></p> <p>This option is ignored for MySQL option compatibility.</p>"},{"location":"xtrabackup-option-reference.html#innodb-miscellaneous","title":"innodb-miscellaneous","text":"<p>Usage: <code>--innodb-miscellaneous xtrabackup boots up its embedded InnoDB with the same configuration as your current server using the InnoDB options read from that server's</code>my.cnf` file. You do not need to specify these options explicitly.</p> <p>These options behave the same in either InnoDB or XtraDB.</p>"},{"location":"xtrabackup-option-reference.html#keyring-file-data","title":"keyring-file-data","text":"<p>Usage: <code>--keyring-file-data=FILENAME</code></p> <p>Defines the path to the keyring file. You can combine this option with <code>--xtrabackup-plugin-dir</code>.</p>"},{"location":"xtrabackup-option-reference.html#kill-long-queries-timeout","title":"kill-long-queries-timeout","text":"<p>Usage: <code>--kill-long-queries-timeout=SECONDS</code></p> <p>This option specifies the number of seconds xtrabackup waits between starting <code>FLUSH TABLES WITH READ LOCK</code> and killing those queries that block it. The default value is 0 (zero) seconds, which means xtrabackup does not kill any queries.</p> <p>To use this option xtrabackup user should have the <code>PROCESS</code> and <code>SUPER</code> privileges.</p> <p>Where supported, xtrabackup automatically uses Backup locks as a lightweight alternative to <code>FLUSH TABLES WITH READ LOCK</code> to copy non-InnoDB data to avoid blocking DML queries that modify InnoDB tables.</p>"},{"location":"xtrabackup-option-reference.html#kill-long-query-type","title":"kill-long-query-type","text":"<p>Usage: <code>--kill-long-query-type=all|select</code></p> <p>This option specifies which queries should be killed to unblock the global lock. The default value is \u201cselect\u201d.</p>"},{"location":"xtrabackup-option-reference.html#lock-ddl","title":"lock-ddl","text":"<p>Usage: <code>--lock-ddl</code></p> <p>Enabled by default to ensure that any DDL event does not corrupt the backup. Any DML events continue to occur. A DDL lock protects table and view definitions.</p> <p>If the option is disabled, a backup continues while concurrent DDL events are executed. These backups are invalid and fail in the Prepare step.</p> <p>Use a safe-slave-backup option to stop a SQL replica thread before copying the InnoDB files.</p>"},{"location":"xtrabackup-option-reference.html#lock-ddl-per-table","title":"lock-ddl-per-table","text":"<p>Usage: <code>--lock-ddl-per-table</code></p> <p>Deprecated. Use the <code>\u2013lock-ddl</code> option instead</p> <p>Lock DDL for each table before xtrabackup starts to copy it and until the backup is completed.</p>"},{"location":"xtrabackup-option-reference.html#lock-ddl-timeout","title":"lock-ddl-timeout","text":"<p>Usage: <code>--lock-ddl-timeout</code></p> <p>If <code>LOCK TABLES FOR BACKUP</code> or <code>LOCK INSTANCE FOR BACKUP</code> does not return within a given time, abort the backup.</p>"},{"location":"xtrabackup-option-reference.html#log","title":"log","text":"<p>Usage: <code>--log</code></p> <p>This option is ignored for MySQL</p>"},{"location":"xtrabackup-option-reference.html#log-bin","title":"log-bin","text":"<p>Usage: <code>--log-bin</code></p> <p>The base name for the log sequence.</p>"},{"location":"xtrabackup-option-reference.html#log-bin-index","title":"log-bin-index","text":"<p>Usage: <code>--log-bin-index=name</code></p> <p>The file that stores the names for binary log files.</p>"},{"location":"xtrabackup-option-reference.html#log-copy-interval","title":"log-copy-interval","text":"<p>Usage: <code>--log-copy-interval=#</code></p> <p>This option specifies the time interval between checks done by the log copying thread in milliseconds. The default value is 1 second.</p>"},{"location":"xtrabackup-option-reference.html#login-path","title":"login-path","text":"<p>Usage: <code>--login-path</code></p> <p>Read the given path from the login file.</p>"},{"location":"xtrabackup-option-reference.html#move-back","title":"move-back","text":"<p>Usage: <code>--move-back</code></p> <p>Move all files in a previous backup from the backup directory to their original locations.</p> <p>Use this option with caution since the operation removes backup files.</p>"},{"location":"xtrabackup-option-reference.html#no-backup-locks","title":"no-backup-locks","text":"<p>Usage: <code>--no-backup-locks</code></p> <p>Explicity disables the <code>--backup-locks</code> option which is enabled by default.</p>"},{"location":"xtrabackup-option-reference.html#no-defaults","title":"no-defaults","text":"<p>Usage: <code>--no-defaults</code></p> <p>The default options are only read from the login file.</p>"},{"location":"xtrabackup-option-reference.html#no-lock","title":"no-lock","text":"<p>Usage: <code>--no-lock</code></p> <p>Disables the table lock with <code>FLUSH TABLES WITH READ LOCK</code>. Use it only if all your tables are InnoDB and you do not care about the binary log position of the backup. This option shouldn\u2019t be used if any DDL statements are being executed or updates are happening on non-InnoDB tables; this includes the system MyISAM tables in the mysql database. Otherwise, those operations could lead to an inconsistent backup.</p> <p>Where supported, xtrabackup will automatically use Backup locks as a lightweight alternative to <code>FLUSH TABLES WITH READ LOCK</code> to copy non-InnoDB data to avoid blocking DML queries that modify InnoDB tables.</p> <p>If you consider using this option because your backups fail to acquire the lock, maybe incoming replication events prevent the lock from succeeding. Try the <code>--safe-slave-backup</code> option to stop the replication replica thread momentarily. The <code>--safe-slave-backup</code> option may help the backup to succeed and avoid using this option.</p>"},{"location":"xtrabackup-option-reference.html#no-server-version-check","title":"no-server-version-check","text":"<p>Usage: <code>--no-server-version-check</code></p> <p>The <code>--no-server-version-check</code> option disables the server version check.</p> <p>The default behavior runs a check that compares the source system version to the Percona XtraBackup version. If the source system version is higher than the XtraBackup version, the backup is aborted with a message.</p> <p>Adding the option overrides this check, and the backup proceeds, but there may be issues with the backup.</p> <p>See Server Version and Backup Version Comparison for more information.</p>"},{"location":"xtrabackup-option-reference.html#no-version-check","title":"no-version-check","text":"<p>Usage: <code>--no-version-check</code></p> <p>This option disables the version check. </p> <p>If you do not pass this option, xtrabackup implicitly enables the automatic version check in the <code>--backup</code> mode. </p> <p>To disable the version check, invoke xtrabackup and explicitly pass this option.</p> <p>When the automatic version check is enabled, xtrabackup performs a version check against the server on the backup stage after creating a server connection. xtrabackup sends the following information to the server:</p> <ul> <li> <p>MySQL flavour and version</p> </li> <li> <p>Operating system name</p> </li> <li> <p>Percona Toolkit version</p> </li> <li> <p>Perl version</p> </li> </ul> <p>Each piece of information has a unique identifier. This identifier is a MD5 hash value that Percona Toolkit uses to obtain statistics about its use. This information is a random UUID; no client information is collected or stored.</p>"},{"location":"xtrabackup-option-reference.html#open-files-limit","title":"open-files-limit","text":"<p>Usage: <code>--open-files-limit=#</code></p> <p>The maximum number of file descriptors to reserve with setrlimitgit .</p>"},{"location":"xtrabackup-option-reference.html#parallel","title":"parallel","text":"<p>Usage: <code>--parallel=#</code></p> <p>This option specifies the number of threads to use to copy multiple data files concurrently when creating a backup. The default value is 1, there is no concurrent transfer. This option can be used with the <code>--copy-back</code> option to copy the user data files in parallel. The redo logs and system tablespaces are copied in the main thread.</p>"},{"location":"xtrabackup-option-reference.html#password","title":"password","text":"<p>Usage: <code>--password=PASSWORD</code></p> <p>This option accepts a string argument that specifies the password used when connecting to the database.</p>"},{"location":"xtrabackup-option-reference.html#plugin-load","title":"plugin-load","text":"<p>Usage: <code>--plugin-load</code></p> <p>A list of plugins to load.</p>"},{"location":"xtrabackup-option-reference.html#port","title":"port","text":"<p>Usage: <code>--port=PORT</code></p> <p>This option accepts a string argument specifying the TCP/IP port used to connect to the database server. This option is passed to the mysql child process without alteration.</p>"},{"location":"xtrabackup-option-reference.html#prepare","title":"prepare","text":"<p>Usage: <code>--prepare</code></p> <p>Makes xtrabackup perform a recovery on a backup created with <code>--backup</code>, so that the backup data is ready to use.</p> <p>For details, see Prepare a full backup.</p>"},{"location":"xtrabackup-option-reference.html#print-defaults","title":"print-defaults","text":"<p>Usage: <code>--print-defaults</code></p> <p>Prints the program argument list and exit and must be the first option on the command line.</p>"},{"location":"xtrabackup-option-reference.html#print-param","title":"print-param","text":"<p>Usage: <code>--print-param</code></p> <p>Prints the parameters that can be used for copying the data files back to their original locations to restore them.</p>"},{"location":"xtrabackup-option-reference.html#read-buffer-size","title":"read-buffer-size","text":"<p>Usage: <code>--read-buffer-size</code></p> <p>Set the read buffer size. The given value is scaled up to page size. The default size is 10MB. Use this option to increase the xbcloud/xbstream chunk size from the default size.</p> <p>To adjust the chunk size for encrypted files, use <code>--read-buffer-size</code> and <code>--encrypt-chunk-size</code>.</p>"},{"location":"xtrabackup-option-reference.html#rebuild-indexes","title":"rebuild-indexes","text":"<p>Usage: <code>--rebuild-indexes</code></p> <p>Rebuilds indexes in a compact backup.</p> <p>This option only has effect when the <code>--prepare</code> and <code>--rebuild-threads</code> options are provided.</p>"},{"location":"xtrabackup-option-reference.html#rebuild-threads","title":"rebuild-threads","text":"<p>Usage: <code>--rebuild-threads=#</code></p> <p>Uses the given number of threads to rebuild indexes in a compact backup. This option only affects the <code>-</code>-prepare<code>](#prepare) and [</code>\u2013rebuild-indexes`](#rebuild-threads) options.</p>"},{"location":"xtrabackup-option-reference.html#register-redo-log-consumer","title":"register-redo-log-consumer","text":"<p>Usage: <code>--register-redo-log-consumer</code></p> <p>This option is disabled by default.</p> <p>When enabled, this options lets Percona XtraBackup register as a redo log consumer at the start of the backup. The server does not remove a redo log that Percona XtraBackup (the consumer) has not yet copied. The consumer reads the redo log and manually advances the log sequence number (LSN). The server blocks the writes during the process. The server determines when to purge the log based on the redo log consumption.</p>"},{"location":"xtrabackup-option-reference.html#remove-original","title":"remove-original","text":"<p>Usage: <code>--remove-original</code></p> <p>This option removes <code>.qp</code>, <code>.xbcrypt</code> and <code>.qp.xbcrypt</code> files after decryption and decompression.</p>"},{"location":"xtrabackup-option-reference.html#rocksdb-datadir","title":"rocksdb-datadir","text":"<p>Usage: <code>--rocksdb-datadir</code></p> <p>Names the RocksDB data directory</p>"},{"location":"xtrabackup-option-reference.html#rocksdb-wal-dir","title":"rocksdb-wal-dir","text":"<p>Usage: <code>--rocksdb-wal-dir</code></p> <p>RocksDB WAL directory.</p>"},{"location":"xtrabackup-option-reference.html#rocksdb-checkpoint-max-age","title":"rocksdb-checkpoint-max-age","text":"<p>Usage: <code>--rocksdb-checkpoint-max-age</code></p> <p>The checkpoint cannot be older than this number of seconds when the backup is complete.</p>"},{"location":"xtrabackup-option-reference.html#rocksdb-checkpoint-max-count","title":"rocksdb-checkpoint-max-count","text":"<p>Usage: <code>--rocksdb-checkpoint-max-count</code></p> <p>Complete the backup even if the checkpoint age requirement has not been met after this number of checkpoints.</p>"},{"location":"xtrabackup-option-reference.html#rollback-prepared-trx","title":"rollback-prepared-trx","text":"<p>Usage: <code>--rollback-prepared-trx</code></p> <p>Force rollback prepared InnoDB transactions.</p>"},{"location":"xtrabackup-option-reference.html#rsync","title":"rsync","text":"<p>Usage: <code>--rsync</code></p> <p>Uses the rsync utility to optimize local file transfers. The xtrabackup binary uses rsync to copy all non-InnoDB files instead of spawning a separate cp for each file, which can be much faster for servers with many databases or tables.</p> <p>You cannot use this option with <code>--stream</code>.</p>"},{"location":"xtrabackup-option-reference.html#safe-slave-backup","title":"safe-slave-backup","text":"<p>Usage: <code>--safe-slave-backup</code></p> <p>When specified, xtrabackup stops the replica SQL thread just before running <code>FLUSH TABLES WITH READ LOCK</code> and waits to start the backup operation until <code>Slave_open_temp_tables`` in</code>SHOW STATUS` is zero.</p> <p>If there are no open temporary tables, the backup takes place, otherwise the SQL thread is started and stopped until there are no open temporary tables. The backup fails if <code>Slave_open_temp_tables</code> does not become zero after <code>--safe-slave-backup-timeout</code> seconds. The replication SQL thread is restarted when the backup is complete. This option is implemented to deal with replication and temporary tables and isn\u2019t necessary with row-based replication.</p> <p>Using a safe-slave-backup option stops the SQL replica thread before copying the InnoDB files.</p>"},{"location":"xtrabackup-option-reference.html#safe-slave-backup-timeout","title":"safe-slave-backup-timeout","text":"<p>Usage: <code>--safe-slave-backup-timeout=SECONDS</code></p> <p>How many seconds the <code>--safe-slave-backup</code> option waits for the <code>Slave_open_temp_tables</code> to become zero. The default value is 300 seconds.</p>"},{"location":"xtrabackup-option-reference.html#secure-auth","title":"secure-auth","text":"<p>Usage: <code>--secure-auth</code></p> <p>Refuse the client from connecting to the server if it uses the old protocol. This option is enabled by default. Disable this options with <code>\u2013skip-secure-auth</code>.</p>"},{"location":"xtrabackup-option-reference.html#server-id","title":"server-id","text":"<p>Usage: <code>--server-id=#</code></p> <p>The server instance being backed up.</p>"},{"location":"xtrabackup-option-reference.html#server-public-key-path","title":"server-public-key-path","text":"<p>Usage: <code>--server-public-key-path</code></p> <p>The file path to the server public RSA key in the PEM format.</p>"},{"location":"xtrabackup-option-reference.html#skip-tables-compatibility-check","title":"skip-tables-compatibility-check","text":"<p>Usage: <code>--skip-tables-compatibility-check</code></p> <p>See <code>--tables-compatibility-check</code>.</p>"},{"location":"xtrabackup-option-reference.html#slave-info","title":"slave-info","text":"<p>Usage: <code>--slave-info</code></p> <p>This option is useful when backing up a replication replica server. It prints the binary log position of the source server. It also writes the binary log coordinates to the <code>xtrabackup_slave_info</code> file as a <code>CHANGE MASTER</code> command.</p> <p>A new replica for this source can be set up by starting a replica server on this backup and issuing a <code>CHANGE MASTER</code> command with the binary log position saved in the <code>xtrabackup_slave_info</code> file.</p>"},{"location":"xtrabackup-option-reference.html#socket","title":"socket","text":"<p>Usage: <code>--socket</code></p> <p>This option accepts a string argument that specifies the socket to use when connecting to the local database server with a UNIX domain socket. It is passed to the MySQL child process without alteration. See mysql \u2013help for details.</p>"},{"location":"xtrabackup-option-reference.html#ssl","title":"ssl","text":"<p>Usage: <code>--ssl</code></p> <p>Enable secure connection.</p>"},{"location":"xtrabackup-option-reference.html#ssl-ca","title":"ssl-ca","text":"<p>Usage: <code>--ssl-ca</code></p> <p>The path of the file contains a list of trusted SSL CAs.</p>"},{"location":"xtrabackup-option-reference.html#ssl-capath","title":"ssl-capath","text":"<p>Usage: <code>--ssl-capath</code></p> <p>The directory path that contains trusted SSL CA files in PEM format.</p>"},{"location":"xtrabackup-option-reference.html#ssl-cert","title":"ssl-cert","text":"<p>Usage: <code>--ssl-cert</code></p> <p>The path of the file contains the X509 certificate in PEM format.</p>"},{"location":"xtrabackup-option-reference.html#ssl-cipher","title":"ssl-cipher","text":"<p>Usage: <code>--ssl-cipher</code></p> <p>The list of the permitted ciphers to use for connection encryption.</p>"},{"location":"xtrabackup-option-reference.html#ssl-crl","title":"ssl-crl","text":"<p>Usage: <code>--ssl-crl</code></p> <p>The path of the file that contains certificate revocation lists.</p>"},{"location":"xtrabackup-option-reference.html#ssl-crlpath","title":"ssl-crlpath","text":"<p>Usage: <code>--ssl-crlpath</code></p> <p>The path of the directory that contains the certificate revocation list files.</p>"},{"location":"xtrabackup-option-reference.html#ssl-fips-mode","title":"ssl-fips-mode","text":"<p>Usage: <code>--ssl-fips-mode</code></p> <p>The SSL FIPS mode applies only for OpenSSL; permitted values are OFF, ON, and STRICT.</p>"},{"location":"xtrabackup-option-reference.html#ssl-key","title":"ssl-key","text":"<p>Usage: <code>--ssl-key</code></p> <p>The path of the file that contains the X509 key in PEM format.</p>"},{"location":"xtrabackup-option-reference.html#ssl-mode","title":"ssl-mode","text":"<p>Usage: <code>--ssl-mode</code></p> <p>The security state of connection to the server.</p>"},{"location":"xtrabackup-option-reference.html#ssl-verify-server-cert","title":"ssl-verify-server-cert","text":"<p>Usage: <code>--ssl-verify-server-cert</code></p> <p>Verify the server certificate Common Name value against the hostname used when connecting to the server.</p>"},{"location":"xtrabackup-option-reference.html#stream","title":"stream","text":"<p>Usage: <code>--stream=FORMAT</code></p> <p>Stream all backup files to the standard output in the specified format. Currently, this option only supports the xbstream format.</p>"},{"location":"xtrabackup-option-reference.html#strict","title":"strict","text":"<p>Usage: <code>--strict</code></p> <p>If this option is specified, xtrabackup fails with an error when invalid parameters are passed.</p>"},{"location":"xtrabackup-option-reference.html#tables","title":"tables","text":"<p>Usage: <code>--tables=name</code></p> <p>A regular expression against which the full table name in the <code>databasename.tablename</code> format is matched. If the name matches, the table is backed up. See Create a partial backup.</p>"},{"location":"xtrabackup-option-reference.html#tables-compatibility-check","title":"tables-compatibility-check","text":"<p>Usage: <code>--tables-compatibility-check</code></p> <p>Enables the engine compatibility warning. The default value is <code>ON</code>. To disable the engine compatibility warning, use <code>--</code>skip-tables-compatibility-check`](#skip-tables-compatibility-check).</p>"},{"location":"xtrabackup-option-reference.html#tables-exclude","title":"tables-exclude","text":"<p>Usage: <code>--tables-exclude=name</code></p> <p>Filtering by regexp for table names. Operates the same way as <code>--tables</code>, but matched names are excluded from backup. Note that this option has a higher priority than <code>--tables</code>.</p>"},{"location":"xtrabackup-option-reference.html#tables-file","title":"tables-file","text":"<p>Usage: <code>--tables-file=name</code></p> <p>A file containing one table name per line in <code>databasename.tablename</code> format. The backup will be limited to the specified tables.</p>"},{"location":"xtrabackup-option-reference.html#target-dir","title":"target-dir","text":"<p>Usage: <code>--target-dir=DIRECTORY</code></p> <p>This option specifies the destination directory for the backup. If the directory does not exist, xtrabackup creates it. If the directory does exist and is empty, xtrabackup will succeed. xtrabackup does not overwrite existing files, however, the operation fails with the operating system error 17, <code>file exists</code>.</p> <p>If this option is a relative path, it is interpreted as relative to the current working directory from which xtrabackup is executed.</p> <p>To perform a backup, you need <code>READ</code>, <code>WRITE</code>, and <code>EXECUTE</code> permissions at a filesystem level for the directory that you supply as the value of <code>--target-dir</code>.</p>"},{"location":"xtrabackup-option-reference.html#innodb-temp-tablespaces-dir","title":"innodb-temp-tablespaces-dir","text":"<p>Usage: <code>--innodb-temp-tablespaces-dir=DIRECTORY</code></p> <p>The location of the directory for the temp tablespace files. This path can be absolute.</p>"},{"location":"xtrabackup-option-reference.html#throttle","title":"throttle","text":"<p>Usage: <code>--throttle=#</code></p> <p>This option limits the number of chunks copied per second. The chunk size is 10 MB.</p> <p>To limit the bandwidth to 10 MB/s, set the option to 1.</p>"},{"location":"xtrabackup-option-reference.html#tls-ciphersuites","title":"tls-ciphersuites","text":"<p>Usage: <code>--tls-ciphersuites</code></p> <p>The TLS v1.3 cipher to use.</p>"},{"location":"xtrabackup-option-reference.html#tls-version","title":"tls-version","text":"<p>Usage: <code>--tls-version</code></p> <p>Defines which TLS version to use. The permitted values are: TLSv1, TLSv1.1, TLSv1.2, TLSv1.3.</p>"},{"location":"xtrabackup-option-reference.html#tmpdir","title":"tmpdir","text":"<p>Usage: <code>--tmpdir=name</code></p> <p>Specify the directory used to store temporary files during the backup</p>"},{"location":"xtrabackup-option-reference.html#transition-key","title":"transition-key","text":"<p>Usage: <code>--transition-key=name</code></p> <p>This option is used to enable processing the backup without accessing the keyring vault server. In this case, xtrabackup derives the AES encryption key from the specified passphrase and uses it to encrypt the tablespace keys of tablespaces being backed up.</p> <p>If <code>--transition-key</code> does not have any value, xtrabackup will ask for it. The same passphrase should be specified for the <code>--prepare</code> command.</p>"},{"location":"xtrabackup-option-reference.html#use-free-memory-pct","title":"use-free-memory-pct","text":"<p>Usage: <code>--use-free-memory-pct</code></p> <p>The <code>--use-free-memory-pct</code> is a tech preview option.</p> <p>This option lets you configure the Smart memory estimation feature. The option controls the amount of free memory that can be used to <code>--prepare</code> a backup. The default value is 0 (zero), which defines the option as disabled. For example, if you set <code>--use-free-memory-pct=50</code>, then 50% of the free memory is used to <code>prepare</code> a backup. The maximum allowed value is 100.</p> <p>This option works only if <code>--estimate-memory</code> option is enabled. If the <code>--estimate-memory</code> option is disabled, the <code>--use-free-memory-pct</code> setting is ignored.</p> <p>An example of how to enable the Smart memory estimation feature:</p> <pre><code>$ xtrabackup --backup --estimate-memory=ON --target-dir=/data/backups/\n</code></pre> <pre><code>$ xtrabackup --prepare --use-free-memory-pct=50 --target-dir=/data/backups/\n</code></pre>"},{"location":"xtrabackup-option-reference.html#use-memory","title":"use-memory","text":"<p>Usage: <code>--use-memory</code></p> <p>This option affects how much memory is allocated and is similar to <code>innodb_buffer_pool_size</code>. This option is only relevant in the <code>--prepare</code> phase. The default value is 100MB. The recommended value is between 1GB to 2GB. Multiple values are supported if you provide the unit (1MB, 1M, 1GB, 1G).</p>"},{"location":"xtrabackup-option-reference.html#user","title":"user","text":"<p>Usage: <code>--user=USERNAME</code></p> <p>This option specifies the MySQL username used when connecting to the server if that\u2019s not the current user. The option accepts a string argument. See mysql \u2013help for details.</p>"},{"location":"xtrabackup-option-reference.html#version","title":"version","text":"<p>Usage: <code>--version</code></p> <p>This option prints xtrabackup version and exits.</p>"},{"location":"xtrabackup-option-reference.html#xtrabackup-plugin-dir","title":"xtrabackup-plugin-dir","text":"<p>Usage: <code>--xtrabackup-plugin-dir=DIRNAME</code></p> <p>The absolute path to the directory that contains the <code>keyring</code> plugin.</p>"},{"location":"xtrabackup-option-reference.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"xtrabackup-version-numbers.html","title":"Understand version numbers","text":"<p>A version number identifies the innovtion product release. The product contains the latest features, improvements, and bug fixes at the time of that release.</p> {{vers}}.0 -1 Base version Minor build version <p>Percona uses semantic version numbering, which follows the pattern of base version and build version. Percona assigns unique, non-negative integers in increasing order for each version release. The version number combines the base MySQL {{vers}} version number and the minor build version.</p> <p>The version numbers for Percona XtraBackup {{release}} define the following information:</p> <ul> <li> <p>Base version - the leftmost numbers indicate the MySQL {{vers}} version used as a base. An increase in base version resets the minor build version to 0.  </p> </li> <li> <p>Minor build version - an internal number that denotes the version of the software. A build version increases by one each time the Percona XtraBackup is released.</p> </li> </ul>"},{"location":"xtrabackup-version-numbers.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"yum-download-rpm.html","title":"Install Percona XtraBackup {{vers}} using downloaded RPM packages","text":"<p>Download <code>RPM</code> packages of the desired series for your architecture from the download page. </p> <p>The following example downloads Percona XtraBackup {{release}} release package for CentOS 7:</p> <pre><code>$ wget https://www.percona.com/downloads/XtraBackup/Percona-XtraBackup-{{release}}/binary/redhat/7/x86_64/percona-xtrabackup-{{pkg}}-{{release}}.el7.x86_64.rpm\n</code></pre> <p>Install Percona XtraBackup by running:</p> <pre><code>$ yum localinstall percona-xtrabackup-{{pkg}}-{{release}}.el7.x86_64.rpm\n</code></pre> <p>When installing packages manually like this, you\u2019ll need to make sure to resolve all the dependencies and install missing packages yourself.</p>"},{"location":"yum-download-rpm.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"yum-files.html","title":"Files in the RPM package built for Percona XtraBackup {{vers}}","text":"<p>The following tables show what data each <code>RPM</code> package contains:</p> Package Contains percona-xtrabackup-{{pkg}} The latest Percona XtraBackup GA binaries and associated files percona-xtrabackup-{{pkg}}-debuginfo The debug symbols for binaries in percona-xtrabackup-{{pkg}} percona-xtrabackup-test-{{pkg}} The test suite for Percona XtraBackup percona-xtrabackup The older version of the Percona XtraBackup"},{"location":"yum-files.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"yum-repo.html","title":"Use a YUM repository to install Percona XtraBackup","text":"<p>Ready-to-use packages are available from the Percona XtraBackup software repositories and the download page. The Percona yum repository supports popular <code>RPM</code>-based operating systems, including the <code>Amazon Linux AMI</code>.</p> <p>The easiest way to install the Percona Yum repository is to install an <code>RPM</code> that configures yum and installs the Percona GPG key.</p> <p>Specific information on the supported platforms, products, and versions is described in Percona Software and Platform Lifecycle.</p>"},{"location":"yum-repo.html#install-percona-xtrabackup-from-percona-yum-repository","title":"Install Percona XtraBackup from Percona <code>yum</code> repository","text":"<p>To install Percona XtraBackup from Percona <code>yum</code> repository, do the following steps:</p> <ol> <li> <p>Install the Percona yum repository by running the following command as the <code>root</code> user or with sudo: </p> <pre><code>$ sudo yum install \\\nhttps://repo.percona.com/yum/percona-release-latest.\\\nnoarch.rpm\n</code></pre> </li> <li> <p>Enable the repository: </p> <pre><code>$ sudo percona-release enable-only tools release\n</code></pre> <p>If Percona XtraBackup is intended to be used in combination with the upstream MySQL Server, you only need to enable the `tools repository: </p> <pre><code>$ sudo percona-release enable-only tools\n</code></pre> </li> <li> <p>Install Percona XtraBackup by running:</p> <pre><code>$ sudo yum install percona-xtrabackup-{{pkg}}\n</code></pre> <p>Warning</p> <p>Make sure that you have the <code>libev</code> package installed before installing Percona XtraBackup on CentOS 6. For this operating system, the <code>libev</code> package is available from the EPEL repositories.</p> </li> <li> <p>To decompress backups made using <code>LZ4</code> or <code>ZSTD</code> compression algorithm, install the corresponding package:</p> Install the <code>lz4</code> packageInstall the <code>zstd</code> package <pre><code>$ sudo yum install lz4\n</code></pre> <pre><code>$ sudo yum install zstd\n</code></pre> </li> </ol> <p>See also</p> <p>To install Percona XtraBackup using downloaded rpm packages, see Install with package manager.</p> <p>To uninstall Percona XtraBackup, see Uninstall Percona XtraBackup </p>"},{"location":"yum-repo.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"yum-uninstall-xtrabackup.html","title":"Uninstall Percona XtraBackup {{vers}} on Red Hat Enterprise Linux and CentOS","text":"<p>To completely uninstall Percona XtraBackup, remove all the installed packages:</p> <pre><code>$ yum remove percona-xtrabackup\n</code></pre>"},{"location":"yum-uninstall-xtrabackup.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"release-notes/8.1.0-1.html","title":"Percona XtraBackup 8.1.0-1 (2023-11-02)","text":"<p>Get started with Quickstart Guide for Percona XtraBackup.</p> <p>Percona XtraBackup (PXB) is a 100% open source backup solution for all versions of Percona Server for MySQL and MySQL\u00ae that performs online non-blocking, tightly compressed, highly secure full backups on transactional systems. Maintain fully available applications during planned maintenance windows with Percona XtraBackup.</p> <p>This is an Innovation release. This type of release is only supported for a short time and is designed to be used in an environment with fast upgrade cycles. Developers and DBAs are exposed to the latest features and improvements.</p>"},{"location":"release-notes/8.1.0-1.html#release-highlights","title":"Release highlights","text":"<p>Percona XtraBackup 8.1.0-1 is based on MySQL 8.1 and fully supports the Percona Server for MySQL 8.1 Innovation series and the MySQL 8.1 Innovation series. This release allows taking backups of Percona Server 8.1.0-1 and MySQL 8.1.</p> <p>Use the Percona XtraBackup 8.0 series to take backups of Percona Server for MySQL 8.0.x or MySQL 8.0.x. Percona XtraBackup 8.1.0-1 does not take a backup of the Percona Server for MySQL 8.0 or the MySQL 8.0.x series.</p>"},{"location":"release-notes/8.1.0-1.html#improvement","title":"Improvement","text":"<ul> <li>PXB-3155 : The Percona Server for MySQL 8.0 series implemented the keyring_vault plugin. In the Innovation series, the server shifts to a component infrastructure, the keyring\u2019s functionality remains the same. Percona XtraBackup 8.1.0-1 supports the component keyring_vault. Users can back up their encrypted data after they convert from the keyring_vault plugin to the keyring_vault component.</li> </ul>"},{"location":"release-notes/8.1.0-1.html#deprecated-or-removed","title":"Deprecated or removed","text":"<p>The <code>--stats</code> mode of operation for the xtrabackup binary has been removed.</p> <p>Only the keyring_vault component, the KMIP component, and the AWS KMS component versions are supported.</p> <p>For the <code>keyring_file</code> both the plugin and component are supported. The <code>keyring_file</code> plugin is deprecated and may be removed in the future.</p>"},{"location":"release-notes/8.1.0-1.html#useful-links","title":"Useful links","text":"<p>Install Percona XtraBackup 8.1</p> <p>The Percona XtraBackup GitHub location</p> <p>Download product binaries, packages, and tarballs at Percona Product Downloads</p>"},{"location":"release-notes/8.1.0-1.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"release-notes/8.2.0-1.html","title":"Percona XtraBackup 8.2.0-1 (2023-12-11)","text":"<p>Get started with Quickstart Guide for Percona XtraBackup.</p> <p>Percona XtraBackup (PXB) is a 100% open source backup solution for all versions of Percona Server for MySQL and MySQL\u00ae that performs online non-blocking, tightly compressed, highly secure full backups on transactional systems. Maintain fully available applications during planned maintenance windows with Percona XtraBackup.</p> <p>This is an Innovation release. This type of release is only supported for a short time and is designed to be used in an environment with fast upgrade cycles. Developers and DBAs are exposed to the latest features and improvements. Patches and security fixes are included in the next Innovation release instead of a patch release or fix release within an Innovation release. To keep your environment current with the latest patches or security fixes, upgrade to the latest release.</p>"},{"location":"release-notes/8.2.0-1.html#release-highlights","title":"Release highlights","text":"<p>Percona XtraBackup 8.2.0-1 is based on MySQL 8.2 and fully supports the Percona Server for MySQL 8.2 Innovation series and the MySQL 8.2 Innovation series. This release allows taking backups of Percona Server 8.2.0-1 and MySQL 8.2.</p> <p>Use the Percona XtraBackup 8.0 series to take backups of Percona Server for MySQL 8.0.x or MySQL 8.0.x. Percona XtraBackup 8.2.0-1 does not take a backup of the Percona Server for MySQL 8.0 or the MySQL 8.0.x series.</p>"},{"location":"release-notes/8.2.0-1.html#bug-fixes","title":"Bug fixes","text":"<ul> <li> <p>PXB-3003: Percona XtraBackup discovering redo logs to parse and the server purging redo logs at the same time could cause a race condition.</p> </li> <li> <p>PXB-3147: XtraBackup failed to execute the <code>DO innodb_redo_log_consumer_register(\"PXB\");</code> query.</p> </li> <li> <p>PXB-3168: Under high write load, the backup might fail with the \u201clog block numbers mismatch\u201d error.</p> </li> <li> <p>PXB-3173: The xbcloud binary was refactored to use multiple threads with a global list of files. This list did not allow users to download a subset of files.</p> </li> <li> <p>PXB-3181: The use of the <code>innodb-use-native-aio=true</code> option resulted in printing duplicate timestamps.</p> </li> </ul>"},{"location":"release-notes/8.2.0-1.html#useful-links","title":"Useful links","text":"<p>Install Percona XtraBackup 8.2</p> <p>The Percona XtraBackup GitHub repository</p> <p>Download product binaries, packages, and tarballs at Percona Product Downloads</p>"},{"location":"release-notes/8.2.0-1.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"release-notes/release-notes.html","title":"Percona XtraBackup {{vers}} release notes index","text":"<ul> <li> <p>Percona XtraBackup 8.2.0-1 (2023-12-11)</p> </li> <li> <p>Percona XtraBackup 8.1.0-1 (2023-11-02)</p> </li> </ul>"},{"location":"release-notes/release-notes.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"}]}